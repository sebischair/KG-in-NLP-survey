document type;title;keywords;abstract;source db;year;doi;authors;url;affiliation countries;task facet;research facet;contribution facet;domain;entity extraction;relation extraction;attribute extraction;entity linking;entity alignment;relation linking;ontology construction;entity classification;relation classification;link prediction;triple classification;error detection;augmented language models;conversational interfaces;knowledge graph embedding;data-to-text generation;question generation;semantic search;machine translation;text analysis;text generation;question answering;natural language inference;semantic parsing;semantic similarity;text classification;text summarization;validation research;solution proposal;evaluation research;secondary research;opinion paper;technique;method;tool;resource;guidelines;health;scholarly domain;engineering;business;law;education;natural science;energy;social media;entertainment media;information technology;tourism;culture;news;agriculture;public sector;history;sports;food;social science;United States;Canada;Australia;Austria;Brazil;Bulgaria;China;Croatia;Denmark;Ecuador;Egypt;France;Georgia;Germany;Greece;Hong Kong;India;Iran;Ireland;Israel;Italy;Japan;South Korea;Lebanon;Mexico;Mongolia;Morocco;Netherlands;New Zealand;Niger;Nigeria;Norway;Portugal;Russian Federation;Singapore;Slovenia;Spain;Sweden;Switzerland;Taiwan;Thailand;United Kingdom;Vietnam;Europe
Conference Paper;artificial intelligence for the early design phases of space missions;"Concurrent engineering; Data handling; Economic and social effects; Engines; Expert systems; Knowledge management; Knowledge representation; Learning algorithms; Learning systems; Life cycle; Natural language processing systems; Network architecture; Ontology; Space flight; User interfaces; European Space Agency; Human-machine interaction; Knowledge representation and reasoning; Model-based system engineerings; Multi word extraction; NAtural language processing; Searching for informations; Word Sense Disambiguation; Data mining";Recent introduction of data mining methods has led to a paradigm shift in the way we can analyze space data. This paper demonstrates that Artificial Intelligence (AI), and especially the field of Knowledge Representation and Reasoning (KRR), could also be successfully employed at the start of the space mission life cycle via an Expert System (ES) used as a Design Engineering Assistant (DEA). An ES is an AI-based agent used to solve complex problems in particular fields. There are many examples of ES being successfully implemented in the aeronautical, agricultural, legal or medical fields. Applied to space mission design, and in particular, in the context of concurrent engineering sessions, an ES could serve as a knowledge engine and support the generation of the initial design inputs, provide easy and quick access to previous design decisions or push to explore new design options. Integrated to the User design environment, the DEA could become an active assistant following the design iterations and flagging model inconsistencies. Today, for space missions design, experts apply methods of concurrent engineering and Model-Based System Engineering, relying both on their implicit knowledge (i.e., past experiences, network) and on available explicit knowledge (i.e., past reports, publications, data sheets). The former knowledge type represents still the most significant amount of data, mostly unstructured, non-digital or digital data of various legacy formats. Searching for information through this data is highly time-consuming. A solution is to convert this data into structured data to be stored into a Knowledge Graph (KG) that can be traversed by an inference engine to provide reasoning and deductions on its nodes. Knowledge is extracted from the KG via a User Interface (UI) and a query engine providing reliable and relevant knowledge summaries to the Human experts. The DEA project aims to enhance the productivity of experts by providing them with new insights into a large amount of data accumulated in the field of space mission design. Natural Language Processing (NLP), Machine Learning (ML), Knowledge Management (KM) and Human-Machine Interaction (HMI) methods are leveraged to develop the DEA. Building the knowledge base manually is subjective, time-consuming, laborious and error bound. This is why the knowledge base generation and population rely on Ontology Learning (OL) methods. This OL approach follows a modified model of the Ontology Layer Cake. This paper describes the approach and the parameters used for the qualitative trade-off for the selection of the software to be adopted in the architecture of the ES. The study also displays the first results of the multi-word extraction and highlights the importance of Word Sense Disambiguation for the identification of synonyms in the context. This paper includes the detailed software architecture of both front and back-ends, as well as the tool requirements. Both architectures and requirements were refined after a set of interviews with experts from the European Space Agency. The paper finally presents the preliminary strategy to quantify and mitigate uncertainties within the ES. © 2019 IEEE.;IEEE;2019;10.1109/aero.2019.8742082;Berquand A., Murdaca F., Riccardi A., Soares T., Generé S., Brauer N., Kumar K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068345246&doi=10.1109%2fAERO.2019.8742082&partnerID=40&md5=d2f4d8a6525558a62ed49c0c8931a394;Germany, United Kingdom, Netherlands;"entity extraction; relation extraction; ontology construction";solution proposal;tool;engineering;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;unscripted conversation through knowledge graph;"Conversational AI; Knowledge Graph; Natural Language Processing";"In this paper, we introduce ""unscripted conversation"" - free form dialog over a domain knowledge graph. We describe a use case around Luggage handling for a commercial airline where we answer users queries regarding various policies such as luggage dimensions, restrictions on carry-on items, travel routes etc. We have encoded the domain entities, relationships, processes and polices in the knowledge graph and created a generic semantic natural language processing engine to process user queries and retrieve the correct results from a knowledge graph. © 2020 CEUR-WS. All rights reserved.";Scopus;2020;;Ramnani R.R., Sengupta S., Gakhar A., Maheshwari S., Mitra S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096232985&partnerID=40&md5=2798bb051049b396493c4f360e1d17f8;;"conversational interfaces; question answering";solution proposal;method;business;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;agrikg: an agricultural knowledge graph and its applications;"Character recognition; Database systems; Deep learning; Agricultural productions; Downstream applications; Intelligent technology; ITS applications; Knowledge graphs; Learning techniques; Question Answering; Unstructured texts; Agriculture";Recently, with the development of information and intelligent technology, agricultural production and management have been significantly boosted. But it still faces considerable challenges on how to effectively integrate large amounts of fragmented information for downstream applications. To this end, in this paper, we propose an agricultural knowledge graph, namely AgriKG, to automatically integrate the massive agricultural data from internet. By applying the NLP and deep learning techniques, AgriKG can automatically recognize agricultural entities from unstructured text, and link them to form a knowledge graph. Moreover, we illustrate typical scenarios of our AgriKG and validate it by real-world applications, such as agricultural entity retrieval, and agricultural question answering, etc. © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-18590-9_81;Chen Y., Kuang J., Cheng D., Zheng J., Gao M., Zhou A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065399556&doi=10.1007%2f978-3-030-18590-9_81&partnerID=40&md5=4b5bb7807a3da3097fe375249ed03125;China;"entity extraction; relation extraction; semantic search";solution proposal;tool;agriculture;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;research on ontology non-taxonomic relations extraction in plant domain knowledge graph construction;"Baidu Encyclopedia; Knowledge graph; Non-taxonomic relation; Ontology learning; Plant domain ontology";In order to provide more specific knowledge and technology of plant field, the main task of KG (knowledge graph) is to extract a wealth of concepts and relationships. Due to the relation extraction is the most difficult in KG construction, this paper makes use of ontology learning, and proposes a non-taxonomic relation learning method to obtain representative concepts and their relations from unstructured and semi-structured texts of Baidu Encyclopedia entry content by using lexicon-syntactic patterns based on dependency grammar analysis. Moreover, the methods of adding constraint models and words filtering were adopted to build heavy weight ontology automatically based on a lightweight ontology and greatly improved the precision of the relation extraction. The approach established a concept structure from the plant domain corpus, ameliorated the discovery of the most representative non-taxonomic relation, and formalized them in the standardized OWL 2.0. A set of experiments was performed using the approach implemented in the plant domain. The results indicated that extraction by patterns should be performed directly after natural language processing, which has a comparatively high accuracy compared to the former algorithms, and this approach can extract non-taxonomic relations with high effectiveness, which lays the foundation for KG construction of plant field. © 2016, Chinese Society of Agricultural Machinery. All right reserved.;Scopus;2016;10.6041/j.issn.1000-1298.2016.09.038;Zhao M., Du Y., Du H., Zhang J., Wang H., Chen Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988660563&doi=10.6041%2fj.issn.1000-1298.2016.09.038&partnerID=40&md5=f578bbb0a9afd1a77fbfa35c2e6698ee;China;"entity extraction; relation extraction; ontology construction";validation research;method;agriculture;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;semantic publication of agricultural scientific literature using property graphs;"Digital publishing; Knowledge graph; Literature search; Property graph; Semantic web";"During the last decades, there have been significant changes in science that have provoked a big increase in the number of articles published every year. This increment implies a new difficulty for scientists, who have to do an extra effort for selecting literature relevant for their activity. In this work, we present a pipeline for the generation of scientific literature knowledge graphs in the agriculture domain. The pipeline combines SemanticWeb and natural language processing technologies, which make data understandable by computer agents, empowering the development of final user applications for literature searches. This workflow consists of (1) RDF generation, including metadata and contents; (2) semantic annotation of the content; and (3) property graph population by adding domain knowledge from ontologies, in addition to the previously generated RDF data describing the articles. This pipeline was applied to a set of 127 agriculture articles, generating a knowledge graph implemented in Neo4j, publicly available on Docker. The potential of our model is illustrated through a series of queries and use cases, which not only include queries about authors or references but also deal with article similarity or clustering based on semantic annotation, which is facilitated by the inclusion of domain ontologies in the graph. © 2019 by the authors.";Scopus;2020;10.3390/app10030861;Abad-Navarro F., Bernabé-Diaz J.A., García-Castro A., Fernandez-Breis J.T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081533013&doi=10.3390%2fapp10030861&partnerID=40&md5=154297ed2705465af62db64c08e57165;Germany, Spain;"entity extraction; relation extraction; ontology construction; semantic search";solution proposal;method;agriculture;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;autokg - an automotive domain knowledge graph for software testing: a position paper;"Automotive Domain Knowledge Graph; Natural Language Processing; Software Testing";Industries have a significant amount of data in semi-structured and unstructured formats which are typically captured in text documents, spreadsheets, images, etc. This is especially the case with the software description documents used by domain experts in the automotive domain to perform tasks at various phases of the Software Development Life Cycle (SDLC). In this paper, we propose an end-to-end pipeline to extract an Automotive Knowledge Graph (AutoKG) from textual data using Natural Language Processing (NLP) techniques with the application of automatic test case generation. The proposed pipeline primarily consists of the following components: 1) AutoOntology, an ontology that has been derived by analyzing several industry scale automotive domain software systems, 2) AutoRE, a Relation Extraction (RE) model to extract triplets from various sentence types typically found in the automotive domain, and 3) AutoVec, a neural embedding based algorithm for triplet matching and context-based search. We demonstrate the pipeline with an application of automatic test case generation from requirements using AutoKG. © 2021 IEEE.;IEEE;2021;10.1109/icstw52544.2021.00047;Kesri V., Nayak A., Ponnalagu K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108021658&doi=10.1109%2fICSTW52544.2021.00047&partnerID=40&md5=1ca3f1540a1e7c0912803defe84e593d;India;semantic search;opinion paper;method;engineering;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a framework for modeling knowledge graphs via processing natural descriptions of vehicle-pedestrian interactions;"Knowledge graph; Natural language processing; Pedestrian behavior";The full-scale deployment of autonomous driving demands successful interaction with pedestrians and other vulnerable road users, which requires an understanding of their dynamic behavior and intention. Current research achieves this by estimating pedestrian’s trajectory mainly based on the gait and movement information in the past as well as other relevant scene information. However, the autonomous vehicles still struggle with such interactions since the visual features alone may not supply subtle details required to attain a superior understanding. The decision-making ability of the system can improve by incorporating human knowledge to guide the vision-based algorithms. In this paper, we adopt a novel approach to retrieve human knowledge from the natural text descriptions about the pedestrian-vehicle encounters, which is crucial to anticipate the pedestrian intention and is difficult for computer vision (CV) algorithms to capture automatically. We applied natural language processing (NLP) techniques on the aggregated description from different annotators to generate a temporal knowledge graph, which can achieve the changes of intention and the corresponding reasoning processes in a better resolution. In future work, we plan to show that in combination with video processing algorithms, the knowledge graph has the potential to aid the decision-making process to be more accurate by passively integrating the reasoning ability of humans. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-59987-4_4;Elahi M.F., Luo X., Tian R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097241483&doi=10.1007%2f978-3-030-59987-4_4&partnerID=40&md5=2c9010bbacc169f5efb4b0475662670d;India, United States;"entity extraction; relation extraction";solution proposal;method;engineering;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;construction of an industrial knowledge graph for unstructured chinese text learning;"Deep learning; Industrial big data; Industrial knowledge graph; Industry 4.0; Intellectualization of industrial information; Social network";"The industrial 4.0 era is the fourth industrial revolution and is characterized by network penetration; therefore, traditional manufacturing and value creation will undergo revolutionary changes. Artificial intelligence will drive the next industrial technology revolution, and knowledge graphs comprise the main foundation of this revolution. The intellectualization of industrial information is an important part of industry 4.0, and we can efficiently integrate multisource heterogeneous industrial data and realize the intellectualization of information through the powerful semantic association of knowledge graphs. Knowledge graphs have been increasingly applied in the fields of deep learning, social network, intelligent control and other artificial intelligence areas. The objective of this present study is to combine traditional NLP (natural language processing) and deep learning methods to automatically extract triples from large unstructured Chinese text and construct an industrial knowledge graph in the automobile field. © 2019 by the authors.";Scopus;2019;10.3390/app9132720;Zhao M., Wang H., Guo J., Liu D., Xie C., Liu Q., Cheng Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072242633&doi=10.3390%2fAPP9132720&partnerID=40&md5=6d0643c1ddf245c6c8c1dcfe7cb02a4f;China;"entity extraction; relation extraction";validation research;method;engineering;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph of mergers and acquisitions;"Knowledge Graphs; Natural Language Processing";Context driven decision making is a key factor to make critical decisions in business applications. We present the design and application of a knowledge graph to aid the context driven decision making for studying the patterns in Mergers and Acquisitions (MA) activities in the industry. Using text data from news articles we make use of a Natural Language Processing pipeline to extract entities and relations to build a knowledge graph. The entity recognition model was 90.97% accurate in detecting the entities. The graph is further enriched with metadata from Wikipedia. We finally demonstrate two use cases to showcase the utility of the knowledge graph for making business decisions. © 2021 IEEE.;IEEE;2021;10.1109/esci50559.2021.9397038;Bhoomkar Y., Vernekar S., Kulkarni A., Kulkarni P., Aniyan A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104583816&doi=10.1109%2fESCI50559.2021.9397038&partnerID=40&md5=a46f6e917d4b231c8202a0d0af384078;India;"entity extraction; relation extraction";solution proposal;method;business;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;ai-supported innovation monitoring;"Human-machine interaction; Hybrid AI; Innovation; Knowledge graph; Natural Language Processing; Policy-making";Small and medium enterprises (SMEs) are a driving force for innovation. Stimulation of innovation in these SMEs is often the target of policy interventions, both regionally and nationally. Which technical areas should be in the focus and how to identify and monitor them? In this position paper, we propose hybrid AI methods for innovation monitoring, using natural language processing (NLP) and a dynamic knowledge graph that combines learning, reasoning and knowledge sharing in collaboration with innovation experts. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-73959-1_20;Braaksma B., Daas P., Raaijmakers S., Geurts A., Meyer-Vitali A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105908818&doi=10.1007%2f978-3-030-73959-1_20&partnerID=40&md5=808f6a86b179c6c1bbdae9c424e72581;Netherlands;semantic search;opinion paper;method;business;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;knadia: enterprise knowledge assisted dialogue systems using deep learning;"AI chatbots; chatbot; conversational agents; Conversational Dialogue System; Conversational Systems; Deep Learning; digital persona; Intent Identification; knowledge graph; knowledge synthesis; natural language processing; virtual assistance";"In this paper we present the design, architecture and implementation of KNADIA, a conversational dialogue system for intra-enterprise use, providing knowledge-Assisted question answering and transactional assistance to employees of a large organization. KNADIA has been deployed in production in TCS, a large organization with over 380,000 employees distributed globally; the system is currently supporting a few thousand active users making hundreds of queries per day. We identify, define and distinguish two distinct classes of use-cases: virtual assistance and knowledge synthesis, which we have found to cover a variety of enterprise needs. KNADIA supports both types of conversational agents, with multiple instances of each, while presenting a common digital persona. KNADIA disambiguates which agent should respond to each query. Further, since individual components use deep learning algorithms giving probabilistic outputs, the confidence with which different components answer is often required before answering or acting. The user's dialogue context also needs to be maintained judiciously. Due to these and many other challenges, the overall architecture of KNADIA is non-Trivial. We present instances of HR-Assistance and technical knowledge synthesis that are in production use in TCS along with accuracy figures and key performance metrics. Finally, we suggest that many elements of our architecture are also generally applicable to other complex deep learning systems. © 2018 IEEE.";IEEE;2018;10.1109/icde.2018.00161;Singh M., Agarwal P., Chaudhary A., Shroff G., Khurana P., Patidar M., Bisht V., Bansal R., Sachan P., Kumar R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057107255&doi=10.1109%2fICDE.2018.00161&partnerID=40&md5=de77865f9876ed63936b94bb540cd284;India;"conversational interfaces; question answering";evaluation research;"tool; guidelines";business;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph: semantic representation and assessment of innovation ecosystems;"Competence analysis; Competence assessment; Competence detection; Computational linguistics; Corporate strategy; Data mining; Decision making; Expert matching; Expert mining; Information extraction; Information retrieval; Innovation ecosystem; Knowledge graph; Knowledge representation; Machine learning; Name disambiguation; Name normalization; Natural language processing; Ontology; Patent analysis; Question-answering; Reasoning; Semantic analysis; Semantic technologies";Innovative capacity is highly dependent upon knowledge and the possession of unique competences can be an important source of enduring strategic advantage. Hence, being able to identify, locate, measure, and assess competence occupants can be a decisive competitive edge. In this work, we introduce a framework that assists with performing such tasks. To achieve this, NLP-, rule-based, and machine learning techniques are employed to process raw data such as academic publications or patents. The framework gains normalized person and organization profiles and compiles identified entities (such as persons, organizations, or locations) into dedicated objects disambiguating and unifying where needed. The objects are then mapped with conceptual systems and stored along with identified semantic relations in a Knowledge Graph, which is constituted by RDF triples. An OWL reasoner allows for answering complex business queries, and in particular, to analyze and evaluate competences on multiple aggregation levels (i.e., single vs. collective) and dimensions (e.g., region, technological field of interest, time). In order to prove the general applicability of the framework and to illustrate how to solve concrete business cases from the automotive domain, it is evaluated with different datasets. © 2017, Springer International Publishing AG.;Scopus;2017;10.1007/978-3-319-69548-8_15;Ulmschneider K., Glimm B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034227560&doi=10.1007%2f978-3-319-69548-8_15&partnerID=40&md5=e3e7ac8e9d38de71c02d73b255d1fd7b;Germany;"entity extraction; relation extraction; semantic search";solution proposal;method;business;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;the semantic knowledge graph: a compact, auto-generated model for real-time traversal and ranking of any relationship within a domain;"Anomaly Detection; Graph Compression; Information Retrieval; Knowledge Graph; Natural Language Processing; Ontology Learning; Relationship Extraction; Semantic Search; Text Analytics";This paper describes a new kind of knowledge representation and mining system which we are calling the Semantic Knowledge Graph. At its heart, the Semantic Knowledge Graph leverages an inverted index, along with a complementary uninverted index, to represent nodes (terms) and edges (the documents within intersecting postings lists for multiple terms/nodes). This provides a layer of indirection between each pair of nodes and their corresponding edge, enabling edges to materialize dynamically from underlying corpus statistics. As a result, any combination of nodes can have edges to any other nodes materialize and be scored to reveal latent relationships between the nodes. This provides numerous benefits: The knowledge graph can be built automatically from a real-world corpus of data, new nodes-Along with their combined edges-can be instantly materialized from any arbitrary combination of preexisting nodes (using set operations), and a full model of the semantic relationships between all entities within a domain can be represented and dynamically traversed using a highly compact representation of the graph. Such a system has widespread applications in areas as diverse as knowledge modeling and reasoning, natural language processing, anomaly detection, data cleansing, semantic search, analytics, data classification, root cause analysis, and recommendations systems. The main contribution of this paper is the introduction of a novel system-The Semantic Knowledge Graph-which is able to dynamically discover and score interesting relationships between any arbitrary combination of entities (words, phrases, or extracted concepts) through dynamically materializing nodes and edges from a compact graphical representation built automatically from a corpus of data representative of a knowledge domain. The source code for our Semantic Knowledge Graph implementation is being published along with this paper to facilitate further research and extensions of this work. © 2016 IEEE.;IEEE;2016;10.1109/dsaa.2016.51;Grainger T., Aljadda K., Korayem M., Smith A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011264001&doi=10.1109%2fDSAA.2016.51&partnerID=40&md5=fd4a3c8640ff6b4594e55e9455ac9bdc;United States;"entity extraction; relation extraction; ontology construction; semantic search";validation research;tool;business;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;voice of the customer oriented new product synthesis over knowledge graphs;"Electronic commerce; Manufacture; Natural language processing systems; Sales; Communication gaps; Hierarchical product; Ontological models; Product manufacturers; Product synthesis; Reasoning techniques; Voice of customer; Voice of the customer; Product design";"The online shopping has been much easier and popular, and meanwhile brings new challenges and opportunities to the field of product design and marketing sale. On one hand, product manufacturers find it challenging to produce new popularly accepted products to meet the customers’ needs; on the other hand, end customers usually feel it difficult to buy ideal goods that they really want, even if navigating a huge amount of commodities. There are indeed a’communication gap’ between the customers and manufacturers. As an effort to partially resolve the issue, this paper proposes a novel product synthesis approach from’voice of the customer’ over product knowledge graphs. Here the voice of customers mainly refer to the buyers’ product reviews from online shopping platforms or blogs, while the product knowledge graph is constructed containing professional hierarchical product knowledge on its properties based on ontological models. Using the technologies of natural language processing, we first extract the customs’ polarities on each specific aspect of a product, which are then transited to design requirements on the product’s design components. Based on the requirement extractions, and the pre-built product knowledge, semantic web and reasoning techniques are utilized to synthesize a novel product that meets more customer needs. Typical case studies on mobile phones from raw online data demonstrate the proposed approach’s performance. Copyright © 2018 ASME.";Scopus;2018;10.1115/detc201885909;Qin F., Xu H., Zhang W., Yuan L., Li M., Liu Y., Liu Y., Chen Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056885168&doi=10.1115%2fDETC201885909&partnerID=40&md5=4609180e34b615dc17144397aa4a787f;China, United Kingdom;semantic search;solution proposal;method;business;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Journal Article;constructing knowledge graph with public resumes;"Characters Knowledge Graph; Knowledge Graph; NER; Rusume Analyse";[Objective] This paper constructs knowledge graph based on the public resume data with natural language processing technology, which provides new tool for traditional data analysis. [Context] The proposed method could automatically extract profesional backgrounds and job information from resumes, and then obtain the relationship of working experience and colleagues in the organizations. The visualized knowledge graph could provide decision support for talent selection, personnel appointment and removal tasks of enterprises and institutions. [Methods] First, we used crawler to obtain the resume data and used the BERT-BiLSTM-CRF model to recognize entities. Then, we established the relationship between entities by defining rules and integrating the external domain knowledge. Finally, we used neo4j graph database to store and visualize data. [Results] The accuracy of the BERT-BiLSTM-CRF model with the entity recognition task was 84.85%. The constructed knowledge graph, which included resumes of 561 people, 8,174 entities in 3 categories, and 20,162 relationships in 5 categories, could support multi-angle queries and data mining. [Conclusions] This proposed model explores the internal relationships among resumes and provides a novel way to analyze resumes. However, there are few precise entity alignment processing and the establishment of relationships among institution entities. © 2021, Chinese Academy of Sciences. All rights reserved.;Scopus;2021;10.11925/infotech.2096-3467.2021.0145;Kejie S., Huanting H., Bolin H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115321022&doi=10.11925%2finfotech.2096-3467.2021.0145&partnerID=40&md5=fac212c8e1382c4b3b5ef733349723e6;China;"entity extraction; relation extraction; entity linking";solution proposal;tool;business;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;con2kg-a large-scale domain-specific knowledge graph;knowledge graph, recruitment domain, natural language processing;This paper presents Con2KG, a large-scale recruitment domain Knowledge Graph that describes 4 million triples as facts from 250 thousands of unstructured data of job postings. We propose a novel framework for Knowledge Graph construction from unstructured text and an unsupervised, dynamically evolving ontology that helps Con2KG to capture hierarchical links between the entities missed by explicit relational facts in the triples. To enrich our graph, we include entity context and its polarity. Towards this end, we discuss Con2KG applications that may benefit the recruitment domain.;ACM;2019;10.1145/3342220.3344931;Goyal, Nidhi and Sachdeva, Niharika and Choudhary, Vijay and Kar, Rijula and Kumaraguru, Ponnurangam and Rajput, Nitendra;https://doi.org/10.1145/3342220.3344931;India;"entity extraction; relation extraction";solution proposal;tool;business;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a knowledge graph-aided concept-knowledge approach for evolutionary smart product-service system development;"Concept generation; Conceptual design; Concept–knowledge model; Creativity; Knowledge evolution; Knowledge graph; Smart product–service system";In order to meet user expectations and to optimize user experience with a higher degree of flexibility and sustainability, the Smart product–service system (Smart PSS), as a novel value proposition paradigm considering both online and offline smartness, was proposed. However, conventional manners for developing PSS require many professional consultations and still cannot meet with the new features of Smart PSS, such as user context-awareness and ever-evolving knowledge management. Therefore, aiming to assist Smart PSS development cost-effectively, this paper adopted the knowledge graph (KG) technique and concept–knowledge (C-K) model to propose an evolutionary design approach. Two knowledge graphs are firstly established with open-source knowledge, prototype specifications, and user-generated textual data. Then, triggered by personalized requirements, four KG-aided C-K operators are conducted based on graph-based query patterns and computational linguistics algorithms, thus generating innovative solutions for evolving Smart PSS. To validate the performance of the proposed approach, a case study of a smart nursing bed fulfilling multiple personalized requirements is conducted, and the evaluation result of its knowledge evolution is acceptable. It hopes that this work can offer insightful guidance to industrial organizations in their development of Smart PSS. Copyright © 2020 by ASME.;Scopus;2020;10.1115/1.4046807;Li X., Chen C.-H., Zheng P., Wang Z., Jiang Z., Jiang Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089729213&doi=10.1115%2f1.4046807&partnerID=40&md5=abaec16b11d639f166214b6b1d1beff3;China, Hong Kong, Singapore;"entity extraction; relation extraction; ontology construction; semantic search";solution proposal;"method; guidelines";business;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph mining for realty domain using dependency parsing and qat models;"dependency parsing; knowledge-graph; neural network; ontology; QAT; real estates";The real estate business has a lot of risks, and in order to minimize them, you need a lot of information from different sources. Systems based on natural language processing can help customers find this information more easily: question answering, information retrieval, etc. The existing method of question answering requires data aligned with possible questions, which are not easy to obtain, in contrast, the knowledge-graph provides structured information. In this paper, we propose semi-automated ontology generation for the realty domain and a subsequent method for information retrieval related to the knowledge-graph of this ontology. The first contribution is the method for relation extraction method based on dependency-parsing and semantic similarity evaluation, which allows us to form ontology for a particular domain. The second contribution is knowledge-graph completion method based on question answering over text neural network. Our experimental analysis shows the efficiency of the proposed approaches. © 2021 The Author(s).;ScienceDirect;2021;10.1016/j.procs.2021.10.004;Zamiralov A., Sohin T., Butakov N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120552308&doi=10.1016%2fj.procs.2021.10.004&partnerID=40&md5=64d84c5f07096c24a5aa1b14e03bb744;Russian Federation;"ontology construction; semantic search; relation extraction; question answering";solution proposal;method;business;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1
Journal Article;conversation concepts: understanding topics and building taxonomies for financial services;"Financial services; FinTech; Knowledge graphs; Natural language processing; Relation extraction; Taxonomies; Term extraction";Knowledge graphs are proving to be an increasingly important part of modern enterprises, and new applications of such enterprise knowledge graphs are still being found. In this paper, we report on the experience with the use of an automatic knowledge graph system called Saffron in the context of a large financial enterprise and show how this has found applications within this enterprise as part of the “Conversation Concepts Artificial Intelligence” tool. In particular, we analyse the use cases for knowledge graphs within this enterprise, and this led us to a new extension to the knowledge graph system. We present the results of these adaptations, including the introduction of a semi-supervised taxonomy extraction system, which includes analysts in-the-loop. Further, we extend the kinds of relations extracted by the system and show how the use of the BERTand ELMomodels can produce high-quality results. Thus, we show how this tool can help realize a smart enterprise and how requirements in the financial industry can be realised by state-of-the-art natural language processing technologies. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Scopus;2021;10.3390/info12040160;McCrae J.P., Mohanty P., Narayanan S., Pereira B., Buitelaar P., Karmakar S., Sarkar R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105002983&doi=10.3390%2finfo12040160&partnerID=40&md5=d1f30ceca340849e8c78ea0b669768c3;Ireland, United States;"conversational interfaces; semantic search";evaluation research;tool;business;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;knowledge graph enhanced event extraction in financial documents;"Event Extraction; Financial Documents; Financial Events; Graph Neural Network; Knowledge Graph";Event extraction is a classic task in natural language processing with wide use in handling large amount of yet rapidly growing financial, legal, medical, and government documents which often contain multiple events with their elements scattered and mixed across the documents, making the problem much more difficult. Though the underlying relations between event elements to be extracted provide helpful contextual information, they are somehow overlooked in prior studies.We showcase the enhancement to this task brought by utilizing the knowledge graph that captures entity relations and their attributes. Beyond straightforward feature engineering attempts, we propose a first event extraction framework that embeds a knowledge graph through a Graph Neural Network and integrates the embedding with regular features, all at document-level. Specifically, for extracting events from Chinese financial announcements, our method outperforms the state-of-the-art method by 5.3% in F1-score. Specifically, our method demonstrates its effectiveness in improving the performance of multiple events extraction. Besides, we make the lawsuit event dataset public to facilitate relevant research. © 2020 IEEE.;IEEE;2020;10.1109/bigdata50022.2020.9378471;Guo K., Jiang T., Zhang H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103832676&doi=10.1109%2fBigData50022.2020.9378471&partnerID=40&md5=05210f4c3c232f2d219d9fdfde8b04ed;China;"entity extraction; relation extraction";validation research;technique;business;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge-driven event embedding for stock prediction;"Commerce; Computational linguistics; Financial markets; Forecasting; Natural language processing systems; Semantics; Vector spaces; Accurate prediction; Back-ground knowledge; Continuous spaces; Event representations; Objective functions; Semantic information; Stock market prediction; Stock market volatility; Knowledge management";Representing structured events as vectors in continuous space offers a new way for defining dense features for natural language processing (NLP) applications. Prior work has proposed effective methods to learn event representations that can capture syntactic and semantic information over text corpus, demonstrating their effectiveness for downstream tasks such as event-driven stock prediction. On the other hand, events extracted from raw texts do not contain background knowledge on entities and relations that they are mentioned. To address this issue, this paper proposes to leverage extra information from knowledge graph, which provides ground truth such as attributes and properties of entities and encodes valuable relations between entities. Specifically, we propose a joint model to combine knowledge graph information into the objective function of an event embedding learning model. Experiments on event similarity and stock market prediction show that our model is more capable of obtaining better event embeddings and making more accurate prediction on stock market volatilities. © 1963-2018 ACL.;ACL;2016;;Ding X., Zhang Y., Liu T., Duan J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051146159&partnerID=40&md5=b392aa1f2bf3a29ea48ad7df6175ff10;China, Singapore;knowledge graph embedding;validation research;technique;business;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;a question answering system of ethnic minorities based on knowledge graph;"Knowledge graph; Named entity recognition; Question answering system; Question classification; Similarity calculation";In recent years, Question Answering System has become a main focus of human machine interaction. Using the question answering system for information retrieval is convenient and efficient. Traditional question answering systems mostly use template matching. The question and answer data sets usually rely on manual design. The question and answer system implemented by this method has a quick query response and can answer relatively complex questions. But manually defining templates and rules is time-consuming and laborious. Therefore, this paper introduces the knowledge graph in the process of constructing the question answering system. The proposed method combines knowledge graph with question answering systems to realize an intelligent question answering system in the field of ethnic minorities, so as to spread ethnic minority knowledge and promote ethnic minority culture. The construction of a question answering system is mainly divided into two modules: question analysis and answer generation. The question analysis module includes named entity recognition, similarity calculation and question classification. The answer generation module includes entity mapping and graph retrieval. The experimental results show that our approach by combined with natural language processing technology and domain knowledge graph can well accurately feedback the answers to user queries. And the answer accuracy of the question answering system can reach about 81%. © 2020 IEEE.;IEEE;2020;10.1109/pic50277.2020.9350829;Li J., Liu S., Yang H., Kolmanic S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101675772&doi=10.1109%2fPIC50277.2020.9350829&partnerID=40&md5=1990665c6785dfc49ea6c55a0fa8e93b;China, Slovenia;question answering;validation research;tool;culture;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1
Conference Paper;question answering system based on knowledge graph of film culture;"Film Culture; Knowledge Graph; Natural Language Processing; Question Answering System";The research and development of intelligent question answering system in today's society is more and more fierce, and it has more and more extensive application prospects. Different from the traditional question answering system which is more biased towards document retrieval, the question answering system based on knowledge graph can accurately identify the user's intention and give accurate answers. This article builds an intelligent Chinese question and answering system for the field of film culture, which can help users quickly and accurately query related issues in film culture. First of all, the knowledge graph of film culture is constructed, and Neo4j graph database is used to store data. Next, the naive Bayes model is used to classify user's problems. Finally, according to the user's intention and keywords, the questions are converted into knowledge graph query statements and the answers are returned after the database query. © 2020 IEEE.;IEEE;2020;10.1109/iccst50977.2020.00035;Shuai Q., Zhang C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099686809&doi=10.1109%2fICCST50977.2020.00035&partnerID=40&md5=5826077c8e82b01afa68e33d8e96ff83;China;"entity extraction; relation extraction; question answering";solution proposal;tool;culture;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;knowledge graph based on domain ontology and natural language processing technology for chinese intangible cultural heritage;"Deep learning; Domain ontology; Intangible cultural heritage; Knowledge graph; Natural language processing; The 24 solar terms";Intangible cultural heritage (ICH) is a precious historical and cultural resource of a country. Protection and inheritance of ICH is important to the sustainable development of national culture. There are many different intangible cultural heritage items in China. With the development of information technology, ICH database resources were built by government departments or public cultural services institutions, but most databases were widely dispersed. Certain traditional database systems are disadvantageous to storage, management and analysis of massive data. At the same time, a large quantity of data has been produced, accompanied by digital intangible cultural heritage development. The public is unable to grasp key knowledge quickly because of the massive and fragmented nature of the data. To solve these problems, we proposed the intangible cultural heritage knowledge graph to assist knowledge management and provide a service to the public. ICH domain ontology was defined with the help of intangible cultural heritage experts and knowledge engineers to regulate the concept, attribute and relationship of ICH knowledge. In this study, massive ICH data were obtained, and domain knowledge was extracted from ICH text data using the Natural Language Processing (NLP) technology. A knowledge base based on domain ontology and instances for Chinese intangible cultural heritage was constructed, and the knowledge graph was developed. The pattern and characteristics behind the intangible cultural heritage were presented based on the ICH knowledge graph. The knowledge graph for ICH could foster support for organization, management and protection of the intangible cultural heritage knowledge. The public can also obtain the ICH knowledge quickly and discover the linked knowledge. The knowledge graph is helpful for the protection and inheritance of intangible cultural heritage. © 2018;ScienceDirect;2018;10.1016/j.jvlc.2018.06.005;Dou J., Qin J., Jin Z., Li Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050818908&doi=10.1016%2fj.jvlc.2018.06.005&partnerID=40&md5=55f351fc9593735ccd67714e8291520f;China;"entity extraction; relation extraction; ontology construction";solution proposal;method;culture;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an ai chatbot for the museum based on user interaction over a knowledge base;"Knowledge Graph; Multi Round Human-Machine Interaction; NLP; Voice Search";"Recently, with the advancement of technologies in AI and Knowledge Base, several museums are using chatbots for visitors. One of the problems with these technologies, however is that gradually tends to be of no real interest to visitors owing to the lack of significant interaction, this eventually distracts visitors from experiencing the exhibits. In the demo, we present AIMuBot, an interactive system for searching the information from the museum's knowledge base with natural language. The system has the following characteristics: (1) It supports natural language voice-based interaction with the visitors to ask questions; (2) It provides a voice-based graphical interface to help visitors refine the questions. (3) It retrieves information from the knowledge base for the visitors. © 2020 ACM.";ACM;2020;10.1145/3421766.3421888;Zhou C., Sinha B., Liu M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095817900&doi=10.1145%2f3421766.3421888&partnerID=40&md5=35d6ec02f94f35b54eddba83b8ae3f08;China;conversational interfaces;solution proposal;tool;culture;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;research and implementation of qa system based on the knowledge graph of chinese classic poetry;"Chinese classical poetry; Knowledge graph; Natural language processing; QA system";With the rapid development of the Internet, intelligent QA (Question Answering) system has been widely used in telecom operators, financial services, e-commerce shopping and other industries, but there are few researches and applications of intelligent QA system in the field of Chinese classical poetry. In view of the above situation, this paper aims to implement an automatic QA system based on the knowledge graph of Chinese classical poetry by combining natural language processing technology. In terms of the construction of knowledge graph, the common triads of Chinese classical poetry knowledge was extracted from the classical poetry websites and the knowledge graph of Chinese classical poetry stored with Neo4j was constructed. In the aspect of question recognition and multi-round dialogue, the Rasa framework was adopted to extract the entity and identify the intention of the user's questions in Chinese classical poetry, so as to realize multi-round dialogue. © 2020 IEEE.;IEEE;2020;10.1109/icccbda49378.2020.9095587;Chen Z., Yin S., Zhu X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085735617&doi=10.1109%2fICCCBDA49378.2020.9095587&partnerID=40&md5=d2f42283770bc3625fbd5d9e6916928d;China;"question answering; conversational interfaces";solution proposal;tool;culture;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;qna system on educational textbooks: digital library doubt support system;"Entity Extraction; Knowledge Graph; Natural Language Processing; Parsing; Question";The domain of content and knowledge on any particular topic of someone's interest is ever - growing. This broadening of the knowledge base of a subject combined with the easy accessibility to the Internet through various devices has resulted in easy access to the loads of content when a search related to the topic is made. But this gigantic collection of data also possesses a challenge. One needs to make some efforts to find the desired information. For this purpose, an individual might be required to go through a number of documents until he/she finds the answer that they craved for.This paper centers around a model to deal with this issue and helps in finding the relevant and precise answer to a query raised. To fulfill this purpose the model uses Natural Language Processing methods combined with knowledge graphs. The paper comes to a conclusion by presenting the performance of the model built. © 2021 IEEE.;IEEE;2021;10.1109/incet51464.2021.9456357;Gupta R., Dabas G., Yadav H., Hasnain N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113312722&doi=10.1109%2fINCET51464.2021.9456357&partnerID=40&md5=f4a723bc2684c2136075a1c36932e79f;India;question answering;solution proposal;tool;education;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph construction of high-performance computing learning platform;"Clustering algorithms; Computational linguistics; Deep learning; Knowledge acquisition; Knowledge based systems; Knowledge representation; Learning systems; Natural language processing systems; Semantics; Clipping algorithms; Efficient learning; High performance computing; Intelligent educations; Statistical language models; Structured graphs; Unstructured texts; Unsupervised extraction; Engineering education";With the development of intelligent education, it has become one of the more efficient learning schemes to construct the knowledge graph which can excavate the knowledge base. People generally use RDF triples and use languages such as OWL to construct knowledge graphs, but this method has problems such as limited expression ability and too much manual annotation. In this paper, we propose a framework that combines statistical language models, neural network language models, and clustering and clipping algorithms. When processing unstructured text data, unsupervised extraction of representative key words as features of the structured graphs' entities, so that the processed entity information has more accurate semantics and human learning relevance, and the method of clustering and calculating the learning rate is used to further clarify the learning order and mastery of knowledge points. We have conducted extensive experiments to collect data from the two major modules of HPC high-performance computing courses and domains as datasets, and used this framework to build many knowledge graphs which can provide practical learning. The knowledge graph of this paper can be obtained from: Https://v2.easyhpc.net:10000/knowledge Knowledge Graph Module. © Published under licence by IOP Publishing Ltd.;Scopus;2021;10.1088/1742-6596/1748/2/022035;Dong T., Tang L., Peng J., Zhong S., Luo H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102367527&doi=10.1088%2f1742-6596%2f1748%2f2%2f022035&partnerID=40&md5=a0a8d953fcdaf14a7eeb8d6d4d467aa6;China;"entity extraction; relation extraction";solution proposal;tool;education;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;motoria: automatic e-learning course generation system;"Automatic course generation systems; e-learning course content; graph; Machine Learning; natural language processing";Recently, through the availability of open data sources and the existence of advanced techniques of Natural Language Processing (NLP) and Artificial Intelligence, several tools have emerged to support the educational learning process of students and lecturers (experts in different knowledge domains). However, there are very few works which propose tools that automate the e-learning course content development process. Hence, experts in the field of educational training have shown great interest in the emergence of applications that ease this type of process. This paper presents MotorIA, a system which uses NLP and Machine Learning techniques as a means to automate online course content generation from different domains (e.g., computer science, biology, mathematic, etc.). MotorIA is supplied with unstructured information extracted from both Wikipedia services and PDF documents. During the e-learning course content generation process, textual information is pre-processed and structured in a knowledge graph, which must satisfy a set of constraints predefined by experts in the field. In a posterior phase, MotorIA was validated by expert users obtaining good evaluation results. © 2020 ACM.;ACM;2020;10.1145/3397125.3397128;Del Carmen Rodríguez-Hernández M., De La Vega Rodrigálvarez-Chamarro M., Vea-Murguia Merck J.I., Ballano Á.E., Lafuente M.A., Del Hoyo-Alonso R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086182575&doi=10.1145%2f3397125.3397128&partnerID=40&md5=48d39603fe19331b3ad5dccc9614db1e;Spain;"entity extraction; relation extraction; semantic search";validation research;tool;education;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;construction of knowledge graphs for video lectures;"Artificial Intelligence; Knowledge Graph; Linked Open Data; Natural Language Processing; video lectures";Knowledge Graphs (KG) have become very important in representing both structured and unstructured data. Knowledge graphs are penetrating our daily lives, be it intelligent voice assistants or Facebook friend search. In this research paper, we are focusing on how Knowledge Graphs can be constructed for a video lecture and list down the various important steps that are involved in the process of construction of the graph. Knowledge Graphs are a way of modelling a knowledge domain programmatically with the aid of tools and techniques like machine-learning algorithms, packages like NLTK, subject experts etc. A knowledge graph representation combines data both in structured and unstructured format. Moreover, the knowledge graphs are commonly built on top of existing databases like Wikipedia, Yago[1] to name a few. Video lectures are the most sought-after form of learning in this current scenario. With the rise in demand for video lectures, people have started to make a lot of videos lectures and made them available in YouTube or as online courses. Knowledge graphs offer a way to streamline workflows, automate responses and scale intelligent decisions. By representing the video lecture as a graph, we will be able to represent the content and the knowledge of the video as a graph. Knowledge Graph thus obtained from the video lectures will become a knowledge cloud that can be used for developing various intelligent applications like domain specific chat-bots, recommender engines and so on. © 2020 IEEE.;IEEE;2020;10.1109/icaccs48705.2020.9074320;Shanmukhaa G.S., Nandita S.K., Kiran M.V.K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084682474&doi=10.1109%2fICACCS48705.2020.9074320&partnerID=40&md5=bc18fafd6ca8c429eb3a8d292793bec2;India;"entity extraction; relation extraction; semantic search";solution proposal;method;education;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;study on framework of intelligent analysis of chinese preview homework in primary schools;"Artificial Intelligence; Personalized Teaching; Semantic Analysis; Text Recognition";Aiming at relieving heavy workloads of primary school Chinese teachers to revise students' preview homework every day, an AI-based intelligent analysis framework is put forward to revise, analyze and generate statistic and individual reports for teachers to carry out personalized teaching and assign personalized homework to each student. After combing related technologies such as optical character recognition, natural language processing, semantic analysis and knowledge graph, feasibility of this work is analyzed. Then a three-step framework including text recognition, Chinese learning knowledge graph construction, reports generation on words, vocabularies and article understanding is proposed to conduct intelligent analysis for discussion. © 2019 IEEE.;IEEE;2019;10.1109/cac48633.2019.8996356;Gong X., Liu X., Jing S., Li Q., Zhang N., Luo J., Yan Y., Lu H., Guan Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080101471&doi=10.1109%2fCAC48633.2019.8996356&partnerID=40&md5=977747c941582385bf81c23b82142d5b;China;semantic search;solution proposal;method;education;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a task-oriented dialogue system for moral education;"Dialogue system; Knowledge graph; Moral education";We present a novel and practical dialogue system specifically designed for teachers and parents to solve students’ problems in moral education. Guided by the case-based reasoning theory, we collect the high-quality cases and teaching strategies from heterogeneous sources, and then construct the dedicated knowledge graph to manage the large volume of information in this domain. By leveraging on the latest natural language processing techniques, we finally implement a task-oriented dialogue system to precisely understand user’s problem and subsequently recommend possible solutions. We show the great promise of the system for K-12 education and demonstrate how the system solves the problem raised by the teacher for moral education. © Springer Nature Switzerland AG 2019.;Scopus;2019;10.1007/978-3-030-23207-8_72;Peng Y., Chen P., Lu Y., Meng Q., Xu Q., Yu S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068332818&doi=10.1007%2f978-3-030-23207-8_72&partnerID=40&md5=4278f8da26912363efe7b220b4848093;China;conversational interfaces;solution proposal;tool;education;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;gre: an adaptive and personalized exercise model for k-12 online education;"Ebbinghaus Forgetting Curve; K-12 Online Education; Knowledge Graph; Personalized Exercise; Speech Recognition";In this paper, we propose an adaptive and personalized exercise model for K-12 online education. It consists of knowledge Graph, knowledge components(KCs) Recognition and Exercises generation. The model builds up knowledge graph of students by processing and analyzing their exercise behaviors, recognizes knowledge components from audio recordings of online tutoring automated by utilizing speech recognition and natural language processing, and generates a list of exercises based on Ebbinghaus forgetting curve theory and knowledge graph of the student. The model can realize what knowledge component she learned just online and know what KC should be review and how to learn a new knowledge component. Two test experiments are conducted on online education platform. The results show that average performance of the students employed GRE model has a significant improvement of 10.08% relative increase than those not used GRE model. Our model can not only improve the efficiency and effect of students' learning, but also reduce the labor cost of online education service. The model has been deployed on online education platform. © 2018 Association for Computing Machinery.;ACM;2018;10.1145/3291078.3291118;Gong T.-J., Yao X.-X., Ma W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061285555&doi=10.1145%2f3291078.3291118&partnerID=40&md5=62f5b9a544dd473bac2684d493c96271;China;"entity extraction; semantic search";evaluation research;tool;education;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;constructing curriculum ontology and dynamic learning path based on resource description framework;"Curriculum; Education; Knowledge graph; Learning path; Linked data; Natural language processing; Ontology; Resource description framework";Curriculum for school is generated based on the academic year. Be-cause students have to study several subjects each and every year, the relative topics are put into curricula in discrete. In this study, we propose a method to construct a dynamic learning path which enables us to learn the relative topics continuously. In this process, we define two kinds of similarity score, inher-itance score and context similarity score to connect the learning path of relative topics. We also construct curriculum ontology with Resource Description Framework (RDF) to make the dynamic learning path accessible and to make education materials integrated with a suitable learning step. Using the curricu-lum ontology, we develop a learning system for school which shows a dynamic learning path with broadcasted video clips.;Scopus;2016;;Urakawa M., Miyazaki M., Fujisawa H., Naemura M., Yamada I.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992431083&partnerID=40&md5=2c828c4d4074e157a5bdbdcc256874a2;Japan;semantic search;solution proposal;tool;education;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph based learning guidance for cybersecurity hands-on labs;"Cybersecurity; Knowledge graph; Laboratory";"Hands-on practice is a critical component of cybersecurity education. Most of the existing hands-on exercises or labs materials are usually managed in a problem-centric fashion, while it lacks a coherent way to manage existing labs and provide productive lab exercising plans for cybersecurity learners. With the advantages of big data and natural language processing (NLP) technologies, constructing a large knowledge graph and mining concepts from unstructured text becomes possible, which motivated us to construct a machine learning based lab exercising plan for cybersecurity education. In the research presented by this paper, we have constructed a knowledge graph in the cybersecurity domain using NLP technologies including machine learning based word embedding and hyperlink-based concept mining. We then utilized the knowledge graph during the regular learning process based on the following approaches: 1. We constructed a web-based front-end to visualize the knowledge graph, which allows students to browse and search cybersecurity-related concepts and the corresponding interdependence relations; 2. We created a personalized knowledge graph for each student based on their learning progress and status; 3.We built a personalized lab recommendation system by suggesting more relevant labs based on students' past learning history to maximize their learning outcomes. To measure the effectiveness of the proposed solution, we have conducted a use case study and collected survey data from a graduate-level cybersecurity class. Our study shows that, by leveraging the knowledge graph for the cybersecurity area study, students tend to benefit more and show more interests in cybersecurity area. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.";ACM;2019;10.1145/3300115.3309531;Deng Y., Lu D., Huang D., Chung C.-J., Lin F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065997977&doi=10.1145%2f3300115.3309531&partnerID=40&md5=00a70d6ba705828ff40a685447a16c56;United States;"entity alignment; semantic search";solution proposal;tool;education;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;research on power equipment system of knowledge graph under electric energy in smart grid;"Data visualization; Electric power transmission networks; Graph Databases; Information management; Knowledge representation; Natural language processing systems; Query processing; Search engines; Hierarchical organizations; Implementation mechanisms; Man machine interface; Management platforms; NAtural language processing; Spatio-temporal data; Technical architecture; Technological innovation; Smart power grids";"In order to realize technological innovation in the electric power field, the article uses artificial intelligence, big data analysis and mining, knowledge graphs, natural language processing and other technologies to construct Chinese professional dictionaries and knowledge graphs in the electric power field. And on this basis, the thesis puts forward the technical architecture of a comprehensive energy service support system based on the concept of ""a picture of the power grid"", a spatiotemporal data management platform and a graph database query application implementation mechanism. Finally, research and design the visualization of the hierarchical organization of the data, use the association relationship between the data to organize the data into multi-topic classification and hierarchical organization, and provide a friendly interactive man-machine interface. © Published under licence by IOP Publishing Ltd.";Scopus;2021;10.1088/1755-1315/714/4/042034;Hu J., Zhang N., Shang Y., Yu J., Zhang W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104186376&doi=10.1088%2f1755-1315%2f714%2f4%2f042034&partnerID=40&md5=14691d482b688ddd30b644dcb466fee3;China;"entity extraction; relation extraction";solution proposal;tool;energy;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;research on knowledge driven intelligent question answering system for electric power customer service;"electric power customer service; intelligent question answering system; knowledge engineering; knowledge graph";The electric power customer service domain-specific knowledge graph aims to describe the concepts, entities, events and their relationships in the electric power customer service business field, with a structured manner, and provide a more effective data organization, management, and cognitive ability for the customer service business. This paper proposes a method for constructing a knowledge graph in the field of electric customer service, and constructs a knowledge graph with over 15,000 entities and 20,000 relationships. Based on the knowledge graph, an intelligent question answering application architecture is designed, which consists of multiple functional modules such as dialogue process configuration, natural language processing, and business process processing. It provides more efficient and open knowledge retrieval services for the electric customer service business, and improves the intelligence level of customer service question answering. © 2021 Elsevier B.V.. All rights reserved.;ScienceDirect;2021;10.1016/j.procs.2021.04.072;Tan Y., Xu H., Wu Y., Zhang Z., An Y., Xiong Y., Wang F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112502110&doi=10.1016%2fj.procs.2021.04.072&partnerID=40&md5=6c073248179211ee6bd5efa521d1e551;China;"entity extraction; attribute extraction; question answering; semantic search";solution proposal;method;energy;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;auxiliary decision technology and application of power grid fault disposal based on knowledge understanding of fault preplan;"auxiliary decision-making; fault disposal; fault preplan; knowledge graph; natural language processing";Combined with the characteristics of power grid fault disposal, auxiliary decision-making technology and implementation architecture of power grid fault disposal that based on knowledge understanding of fault preplan are proposed. Natural language processing technology is used to structurally extract key information of the fault disposal preplan. On this basis, a fault disposal knowledge graph is established. The method can realize the intelligent decision-making and disposal of faults by online retrieving, matching knowledge graph information of real-time faults, automatically extracting key information of fault disposal, and automatic analysis and control navigation of disposal task. The application example shows that the proposed method can realize information extraction, system mapping, knowledge retrieval and construction of fault disposal platform based on fault disposal preplan. This method can effectively reduce the fault disposal pressure and improve fault disposal efficiency and intelligent level. © 2020 IEEE.;IEEE;2020;10.1109/icpre51194.2020.9233245;Bo W., Jian N., Mei D.Z., Yong Z., Shan X., Changming J., Zhe Z., Tingxiang L., Yiming Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096647988&doi=10.1109%2fICPRE51194.2020.9233245&partnerID=40&md5=be648fec858e03b69701fb8765afc12e;China;"entity extraction; relation extraction; semantic search";solution proposal;method;energy;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;visual analysis and mining of knowledge graph for power network data based on natural language processing;"data mining; knowledge graph; Natural language processing; power network; visual analysis";Visual analysis and mining of knowledge graph for power network data based on the natural language processing is proposed in this study. Intelligent substation, through the main equipment intelligence, the primary system modularization, the secondary system integration, the communication system network, realizes the remote centralized control to the substation operation adjustment and the electrical operation 'one-click' automatic completion. Hence, this paper has 2 core novelties. (1) Under the premise of big data in the power grid, the types, sources, access methods, storage methods and other attributes of the data itself are complex. How to realize the effective data management through visualization of the data itself is one of the important application scenarios. (2) Comprehensive perception refers to not only visualization of the power grid, but also deep perception of the internal operating conditions, and scenario simulation through simulation calculations, assisting analysis and decision-making, and realizing state optimization adjustments. The experimental results have proven the effectiveness. © 2020 IEEE.;IEEE;2020;10.1109/iccmc48092.2020.iccmc-00077;Zhao L., Zhao Z., Xu H., Zhang Y., Xu Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084660309&doi=10.1109%2fICCMC48092.2020.ICCMC-00077&partnerID=40&md5=aac16f7e9eb46623567ae79e224b52a8;China;"entity extraction; relation extraction; semantic search";solution proposal;method;energy;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an intelligent question answering system based on power knowledge graph;"Natural language processing;knowledge graph;ontology schema;intelligent reasoning;intelligent question answering system";The intelligent question answering (IQA) system can accurately capture users' search intention by understanding the natural language questions, searching relevant content efficiently from a massive knowledge-base, and returning the answer directly to the user. Since the IQA system can save inestimable time and workforce in data search and reasoning, it has received more and more attention in data science and artificial intelligence. This article introduced a domain knowledge graph using the graph database and graph computing technologies from massive heterogeneous data in electric power. It then proposed an IQA system based on the electrical power knowledge graph to extract the intent and constraints of natural interrogation based on the natural language processing (NLP) method, to construct graph data query statements via knowledge reasoning, and to complete the accurate knowledge search and analysis to provide users with an intuitive visualization. This method thoroughly combined knowledge graph and graph computing characteristics, realized high-speed multi-hop knowledge correlation reasoning analysis in tremendous knowledge. The proposed work can also provide a basis for the context-aware intelligent question and answer.;IEEE;2021;10.1109/pesgm46819.2021.9638018;"Y. Tang; H. Han; X. Yu; J. Zhao; G. Liu; L. Wei";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9638018;China;question answering;solution proposal;tool;energy;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;application prospect of knowledge graph technology in knowledge management of oil and gas exploration and development;"analogy and intelligent prediction; exploration and development; intelligent question and answer; knowledge graph; knowledge management; knowledge push; semantic search";A large number of research reports have been produced during the exploration and development of oil and gas. Traditional relational database-based information management systems and keyword-based information retrieval systems cannot effectively analyze, organize, and utilize the knowledge in these research reports. knowledge graph use machine learning, natural language processing, semantic search and other technologies to extract knowledge from multi-source heterogeneous knowledge carriers and build a graphical knowledge base. Knowledge management systems designed for oil and gas exploration and development, semantic search and knowledge Push, smart question and answer, analogy and intelligent prediction. © 2019 IEEE.;IEEE;2019;10.1109/icaibd.2019.8837003;Guan Q., Zhang F., Zhang E.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073189711&doi=10.1109%2fICAIBD.2019.8837003&partnerID=40&md5=0255cd4adc82365620a9de58b5a8132d;China;"entity extraction; relation extraction; entity linking; semantic search";solution proposal;tool;energy;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;petrokg: construction and application of knowledge graph in upstream area of petrochina;"knowledge graph; natural language processing; oil and gas industry";There is a large amount of heterogeneous data distributed in various sources in the upstream of PetroChina. These data can be valuable assets if we can fully use them. Meanwhile, the knowledge graph, as a new emerging technique, provides a way to integrate multi-source heterogeneous data. In this paper, we present one application of the knowledge graph in the upstream of PetroChina. Specifically, we first construct a knowledge graph from both structured and unstructured data with multiple NLP (natural language progressing) methods. Then, we introduce two typical knowledge graph powered applications and show the benefit that the knowledge graph brings to these applications: compared with the traditional machine learning approach, the well log interpretation method powered by knowledge graph shows more than 7.69% improvement of accuracy. © 2020, Institute of Computing Technology, Chinese Academy of Sciences.;Scopus;2020;10.1007/s11390-020-9966-7;Zhou X.-G., Gong R.-B., Shi F.-G., Wang Z.-F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085188751&doi=10.1007%2fs11390-020-9966-7&partnerID=40&md5=b37619827a8a9eab96d99350c864143e;China;"entity extraction; relation extraction; entity linking; semantic search";evaluation research;tool;energy;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;relation extraction of chinese fundamentals of electric circuits textbook based on cnn;"Chinese fundamentals of electric circuits; Convolutional neural network; Relation extraction";Deep neural network has been widely used in a variety of natural language processing (NLP) tasks nowadays. As one of the most import research areas, entity relation extraction applies usual recurrent neural networks (RNNs) and convolutional neural networks (CNNs) and has achieved good results. Most relation extraction tasks are about public and general datasets, they are usually natural languages or daily conversations, and have millions of samples, very few relates to small corpus in a specific field. We hope to construct a knowledge graph about Chinese fundamentals of electric circuits textbook for beginners. The knowledge graph shows students knowledge navigation and consists of important concepts about this field and logical relationships between them. To achieve the goal, the first step is to ensure entities and extract entity relationships from raw corpus automatically. In this paper, a relation extraction dataset is built from Chinese fundamentals of electric circuits textbook artificially and research the relation extraction performance of improved position-enhanced CNN model on this task. The experiment result validates the effectiveness of CNN on specific Chinese small corpus relation extraction task. © 2019 IEEE.;IEEE;2019;10.1109/itnec.2019.8729144;Li Y., Chen X., Bao Y., Guo D., Huang X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067892226&doi=10.1109%2fITNEC.2019.8729144&partnerID=40&md5=73dd4cf34e78a979c2a19cc7decce786;China;relation extraction;solution proposal;technique;engineering;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a framework for a comprehensive conceptualization of urban constructs;"Case-based reasoning (cbr) and case-based design (cbd); Deep neural network for structuring kg; Domain-specific knowledge graph of urban qualities; Natural language processing and comprehensive understanding of urban constructs; Urban cognition and design creativity";Analogy is thought to be foundational for designing and for design creativity. Nonetheless, practicing analogical reasoning needs a knowledge-base. The paper proposes a framework for constructing a knowledge-base of urban constructs that builds on an ontology of urbanism. The framework is composed of two modules that are responsible for representing either the concepts or the features of any urban constructs' materialization. The concepts are represented as a knowledge graph (KG) named SpatialNet, while the physical features are represented by a deep neural network (DNN) called SpatialFeaturesNet. For structuring SpatialNet, as a KG that comprehensively conceptualizes spatial qualities, deep learning applied to natural language processing (NLP) is employed. The comprehensive concepts of SpatialNet are firstly discovered using semantic analyses of nine English lingual corpora and then structured using the urban ontology. The goal of the framework is to map the spatial features to the plethora of their matching concepts. The granularity ànd the coherence of the proposed framework is expected to sustain or substitute other known analogical, knowledge-based, inspirational design approaches such as case-based reasoning (CBR) and its analogical application on architectural design (CBD). © 2020 and published by the Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.;Scopus;2020;;Ezzat M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091286980&partnerID=40&md5=6481b239274ce5a522c91a20a662588e;Egypt;"natural language inference; ontology construction";solution proposal;method;engineering;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;integrating and navigating engineering design decision-related knowledge using decision knowledge graph;"Decision support; Design; Knowledge graph; Navigation; Searching";Designers are usually facing a problem of finding information from a huge amount of unstructured textual documents in order to prepare for a decision to be made. The major challenge is that knowledge embedded in the textual documents are difficult to search at a semantic level and therefore not ready to support decisions in a timely manner. To address this challenge, in this paper we propose a knowledge-graph-based method for integrating and navigating decision-related knowledge in engineering design. The presented method is based on a meta-model of decision knowledge graph (mDKG) that is grounded in the compromise Decision Support Problem (cDSP) construct which is used by designers as a means to formulate design decisions linguistically and mathematically. Based on the mDKG, we propose a procedure for automatically converting word-based cDSPs to knowledge graph through natural language processing, and a procedure for rapidly and accurately navigating decision-related knowledge through divergence and convergence processes. The knowledge-graph-based method is verified using the textual data from the supply chain design domain. Results show that our method has better performance than the conventional keyword-based searching method in terms of both effectiveness and efficiency in finding the target knowledge. © 2021;ScienceDirect;2021;10.1016/j.aei.2021.101366;Hao J., Zhao L., Milisavljevic-Syed J., Ming Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111263006&doi=10.1016%2fj.aei.2021.101366&partnerID=40&md5=e05d292e5b9c4805f77d8c0e525b720a;China, United Kingdom;"entity extraction; relation extraction; semantic search";solution proposal;method;engineering;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;cross-domain knowledge discovery based on knowledge graph and patent mining;"Cross-Domain; Knowledge Graph; Natural Language Process (NLP); Patent Mining";This paper studies an approach on cross-domain knowledge discovery to assist the conceptual stage of the design process related to mechanical engineering. Variable methods and tools are proposed to obtain knowledge within a given domain until now. However, methods on cross-domain knowledge analysis is under-developed. In this paper, domain knowledge graph is built automatically by employing natural language process (NLP) and patent mining. They comprise patent documents obtaining and knowledge extraction. Then according to the international patent classification (IPC), the knowledge elements are divided to some different categories. The elements are stored in Databases and then the given domain knowledge graph is constructed after correlation analyses. The cross-domain knowledge surrounding the given domain knowledge is found by mining the correlation among cross-domain knowledge. The cross-domain knowledge can inspire designers about new design of a given domain. And the efficiency of knowledge reusing can be improved by domain knowledge graphs. © Published under licence by IOP Publishing Ltd.;Scopus;2021;10.1088/1742-6596/1744/4/042155;Ye F., Fu T., Gong L., Gao J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102170953&doi=10.1088%2f1742-6596%2f1744%2f4%2f042155&partnerID=40&md5=416fe466f6049e5cb4c4502d6f358877;China;entity extraction;solution proposal;method;engineering;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a heuristic grafting strategy for manufacturing knowledge graph extending and completion based on nature language processing: knowtree;"heuristic grafting strategy (HGS); Knowledge graph extending and completion; NLP";Applied to search, question answering, and semantic web of close-or-open domain, knowledge graph (KG) is known for its incompleteness subject to the rapid knowledge growing pace. Inspired by the agricultural grafting technology to fruit variety, this paper proposes a heuristic knowledge grafting strategy (HGS) for manufacturing knowledge graph (MKG) named KnowTree extending and completion with natural language processing (NLP) mining engineering cases document. Based on similarity analysis, firstly the grafting related definitions and mechanisms (completeness, relatedness, connectivity and reutilization) are defined. Then, focused on the four mechanisms, HGS takes a pair same engineering documents as input. KnowWords is built as a collection of KnowScion, and each scion is mined from engineering documents based on the SAO structure network, whose importance is evaluated by SAORank counting the in-out degree of centrality. On another hand, the KnowRoot system is designed based on the extended P S ontology model to characterize the structure of abstract document into four sub-space of knowledge: know-what (problem), know-why (context), know-how (solution) and know-with (result), where a pre-trained language representation model K-BERT is used to classify the KnowScion candidates into the designed KnowRoot system with a fine-tuning classification task. In the knowledge grafting process, the connection unit is constructed based on the extracted domain knowledge triples of the K-BERT model, where the head element of a triple is from the KnowScion candidate set KnowWords satisfying the threshold value, the tail element is from the domain MKG to be extended, and a connection factor is used to evaluate the relationship of union combination. To the goal of knowledge reuse, the path based reasoning rules are designed for KnowTree reutilization. Finally, take the latest engineering case abstract (ECA) in whitegoods domain as resources, a case study is conducted to validate the proposed HGS strategy. © 2013 IEEE.;IEEE;2021;10.1109/access.2021.3092019;He L., Dong B., Jiang P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112701844&doi=10.1109%2fACCESS.2021.3092019&partnerID=40&md5=8962f4344fb4181f1aedae10d9802f83;China, United States;"entity classification; link prediction";validation research;method;engineering;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;ba-ikg: bilstm embedded albert for industrial knowledge graph generation and reuse;"entity relation extraction; industrial knowledge graph; knowledge modeling; knowledge question and answer";As the industrial production mode is shifting towards digitalization and intelligence in the new era. Enterprises put forward higher requirements for efficient processing and utilization of accumulated unstructured data. At present, the knowledge and data contained in a large number of unstructured documents are scattered. The types of entities and relationships are diverse. And the constraints of production rules are complicated, which increases the difficulty of knowledge management and utilization. Therefore, this paper studies the semantic knowledge graph generation and reuse method for industrial documents, which can form standardized production resources, the knowledge related to the industry, and question and answer strategies for industrial processing. The challenge of the research is to explore a feasible process knowledge model and efficient industrial information extraction method to effectively provide structured knowledge of process documents. We build process knowledge representation models and information extraction models and algorithms based on process knowledge representation model and natural language processing. The entities and relations of the main production factors are extracted. The knowledge representation model associates the extracted entities and relations to form an industrial knowledge graph, which provides information support for processing knowledge retrieval and question answering methods. Finally, the approach is evaluated by employing the aerospace machining documents. And the proposed method can obtain valuable information in the document and improve utilization of industrial unstructured data. © 2020 IEEE.;IEEE;2020;10.1109/indin45582.2020.9442198;Zhou B., Bao J., Liu Y., Song D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111099965&doi=10.1109%2fINDIN45582.2020.9442198&partnerID=40&md5=e4d4bd82a21597be8e27caab0a594a33;China;"entity extraction; relation extraction; semantic search; question answering";solution proposal;method;engineering;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;robotic task oriented knowledge graph for human-robot collaboration in disassembly;"Human-robot collaboration; Knowledge base; Knowledge graph; Product disassembly";Traditional disassembly methods, such as manual and robotic disassembly, are no longer competent for the requirement of the complexity of the disassembly product. Therefore, the human-robot collaboration concept can be introduced to realize a novel disassembly system, towards increasing the flexibility and adaptability of them. In order to facilitate the efficient and smooth human-robot collaboration in disassembly, it is necessary to make the disassembly system more intelligent. In this paper, a robotic knowledge graph is proposed to provide an assistant for those who lack the relevant knowledge to complete the disassembly task. By natural language processing method, this paper extracts entities and relationships from the disassembly data to build a knowledge base in the form of knowledge graph. Combining graph-based knowledge representation, a prototype system is developed for human to acquire, analyze and manage the disassembly knowledge. Finally, a case study demonstrates that the proposed robotic knowledge graph has savings in terms of disassembly time, idle time and human workload, and it can be applied to assist human operator in disassembly by providing human and robots with various kinds of the needed knowledge. © 2019 The Authors. Published by Elsevier B.V.;ScienceDirect;2019;10.1016/j.procir.2019.03.121;Ding Y., Xu W., Liu Z., Zhou Z., Pham D.T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070543962&doi=10.1016%2fj.procir.2019.03.121&partnerID=40&md5=2a1848df6af97ba412de051e321de965;China, United Kingdom;"entity extraction; relation extraction";solution proposal;tool;engineering;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Journal Article;technet: technology semantic network based on patent data;Knowledge discovery, Word embedding, Technology semantic network, Knowledge representation;The growing developments in general semantic networks, knowledge graphs and ontology databases have motivated us to build a large-scale comprehensive semantic network of technology-related data for engineering knowledge discovery, technology search and retrieval, and artificial intelligence for engineering design and innovation. Specially, we constructed a technology semantic network (TechNet) that covers the elemental concepts in all domains of technology and their semantic associations by mining the complete U.S. patent database from 1976. To derive the TechNet, natural language processing techniques were utilized to extract terms from massive patent texts and recent word embedding algorithms were employed to vectorize such terms and establish their semantic relationships. We report and evaluate the TechNet for retrieving terms and their pairwise relevance that is meaningful from a technology and engineering design perspective. The TechNet may serve as an infrastructure to support a wide range of applications, e.g., technical text summaries, search query predictions, relational knowledge discovery, and design ideation support, in the context of engineering and technology, and complement or enrich existing semantic databases. To enable such applications, the TechNet is made public via an online interface and APIs for public users to retrieve technology-related terms and their relevancies.;ScienceDirect;2020;10.1016/j.eswa.2019.112995;Serhad Sarica and Jianxi Luo and Kristin L. Wood;https://www.sciencedirect.com/science/article/pii/S0957417419307122;Singapore;"entity extraction; relation extraction";solution proposal;tool;engineering;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;neural machine translation for semantic-driven q&a systems in the factory planning;"answering models; artificial neural networks; factory planning; knowledge graph; natural language processing; question; semantic web stack";Shorter lifecycles, increasing product variance and the integration of new products and technologies into existing factories lead to a high complexity in today's factory planning. In order to master this complexity, many companies attempt to improve their processes by using digitalization tools. This generates enormous amounts of data, which are currently only partially managed centrally in the company. In order to simplify the associated difficulties regarding the access to information, semantic technologies for the generation and application of knowledge graphs (KG) are currently being investigated intensively by research and industry. To retrieve information - stored in the KG - query languages such as SPARQL are used which require knowledge regarding the structure of the KG as well as a profound knowledge of query languages. To also enable non-expert users to retrieve the stored information in the KG, an intuitive user interface for question answering (Q&A) is needed. In this context, we propose a translation model using artificial neural networks (ANN), which translates questions in german into the query language SPARQL. Due to a lack of suitable datasets, we first developed a method to automatically generate synthetic data sets for training the translation model based on existing ontologies. Based on similar approaches from research, we develop an ANN architecture for the translation model. The method for data generation and the ANN were tested and validated at a german car manufacturer using a knowledge graph. It was shown that the developed architecture is particularly suitable for our field of application. © 2020 Elsevier B.V.. All rights reserved.;ScienceDirect;2020;10.1016/j.procir.2021.01.044;Dombrowski U., Reiswich A., Lamprecht R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101100470&doi=10.1016%2fj.procir.2021.01.044&partnerID=40&md5=e9654a429796d1777da8b401d8a6b0a8;Germany;question answering;validation research;method;engineering;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;technology knowledge graph for design exploration: application to designing the future of flying cars;"Knowledge graph; Natural language processing; Patent analysis; Patent analysis; Semantic-level knowledge";To pursue innovation, design engineers need to continuously exploit the knowledge in their design domain and explore other relevant knowledge around the domain. While many methods and tools have been developed to retrieve knowledge within a given design domain, e.g., flying cars, knowledge discovery beyond the domain for innovation remains a challenge, and relevant methods are under-developed. Herein, we introduce a methodology to use a technology knowledge graph (TKG), which covers sematic-level knowledge in all technology fields defined in the international patent classification system, to retrieve the existing engineering knowledge in a domain and discover engineering concepts around the domain for future design considerations and innovation. We demonstrate the TKG-based methodology by applying it to explore the future designs of flying cars, an emerging domain with high uncertainty despite growing prospects. Copyright © 2019 ASME.;Scopus;2019;10.1115/detc2019-97605;Sarica S., Song B., Luo J., Wood K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076406319&doi=10.1115%2fDETC2019-97605&partnerID=40&md5=f5bd3c7bb4e1b635854ead0f0e26c5d9;Singapore;"entity extraction; relation extraction; semantic search";solution proposal;method;engineering;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;a thesaurus-guided method for smart manufacturing diagnostics;"Knowledge graph; Natural Language Processing; Smart maintenance; Thesaurus";The unstructured historical data available in the databases of Computerized Maintenance Management Systems represents a wealth of diagnostic knowledge. In this paper, a methodology for converting the maintenance log data into formal knowledge graphs is presented. The methodology uses text analytics techniques, in combination with human-assisted thesaurus development methods, for generating a formal thesaurus, or knowledge graph, that encodes the semantic relationships between multiple maintenance entities. The knowledge graph proposed in this work uses Simple Knowledge Organization System (SKOS) standard. A java-based tool is developed that uses the generated knowledge graph as the input and conducts light-weight reasoning to support smart maintenance diagnosis. © IFIP International Federation for Information Processing 2019.;Scopus;2019;10.1007/978-3-030-30000-5_88;Ameri F., Yoder R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072986239&doi=10.1007%2f978-3-030-30000-5_88&partnerID=40&md5=e000e83f56c3a1c417ad05a947540674;United States;"entity extraction; relation extraction; semantic search";solution proposal;tool;engineering;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an efficient ros package searching approach powered by knowledge graph;"Knowledge graph; NLP; ROS package searching";Over the past several years, the Robot Operating System (ROS), has grown from a small research project into the most popular framework for robotics development. It offers a core set of software for operating robots that can be extended by creating or using existing packages, making it possible to program robotic software that can be reused on different hardware platforms. With thousands of packages available per stable distribution, encapsulating algorithms, sensor drivers, etc., it is the de facto middleware for robotics. However, finding the proper ROS package is a nontrivial task because ROS packages involve different functions and even with the same function, there are different ROS packages for different tasks. So it is time-consuming for developers to find suitable ROS packages for given task, especially for newcomers. To tackle this challenge, we build a ROS package knowledge graph, ROSKG, including the basic information of ROS packages and ROS package characteristics extracted from text descriptions, to comprehensively and precisely characterize ROS packages. Based on ROSKG, we support ROS packages search with specific task description or attributes as input. A comprehensive evaluation of ROSKG shows the high accuracy of our knowledge construction approach. A user study shows that ROSKG is promising in helping developers find suitable ROS packages for robotics software development tasks. © 2021 Knowledge Systems Institute Graduate School. All rights reserved.;Scopus;2021;10.18293/seke2021-063;Chen L., Mao X., Zhang Y., Yang S., Wang S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114283258&doi=10.18293%2fSEKE2021-063&partnerID=40&md5=33e213145f09134302ef21743f6e61f0;China;"entity extraction; relation extraction; entity linking; semantic search";validation research;method;engineering;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;smartkt: a search framework to assist program comprehension using smart knowledge transfer;"Knowledge Graph; Knowledge Transfer; Machine Learning; Natural Language Processing; Program Comprehension";Regardless of attempts to extract knowledge from code bases to aid in program comprehension, there is an absence of a framework to extract and integrate knowledge to provide a near-complete multifaceted understanding of a program. To bridge this gap, we propose SMARTKT (Smart Knowledge Transfer) to extract and transfer knowledge related to software development and application-specific characteristics and their interrelationships in form of a knowledge graph. For an application, the knowledge graph provides an overall understanding of the design and implementation and can be used by an intelligent natural language query system to convert the process of knowledge transfer into a developer-friendly Google-like search. For validation, we develop an analyzer to discover concurrency-related design aspects from runtime traces in a machine learning framework and obtain a precision and recall of around 97% and 95% respectively. We extract application-specific knowledge from code comments and obtain 72% match against human-Annotated ground truth. © 2019 IEEE.;IEEE;2019;10.1109/qrs.2019.00026;Majumdar S., Papdeja S., Das P.P., Ghosh S.K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073781599&doi=10.1109%2fQRS.2019.00026&partnerID=40&md5=697f3e53a7776f335a18730f364fa238;India;semantic search;solution proposal;method;engineering;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;improving api caveats accessibility by mining api caveats knowledge graph;"API caveats; Coreference Resolution; Entity Linking; Knowledge Graph";API documentation provides important knowledge about the functionality and usage of APIs. In this paper, we focus on API caveats that developers should be aware of in order to avoid unintended use of an API. Our formative study of Stack Overflow questions suggests that API caveats are often scattered in multiple API documents, and are buried in lengthy textual descriptions. These characteristics make the API caveats less discoverable. When developers fail to notice API caveats, it is very likely to cause some unexpected programming errors. In this paper, we propose natural language processing(NLP) techniques to extract ten subcategories of API caveat sentences from API documentation and link these sentences to API entities in an API caveats knowledge graph. The API caveats knowledge graph can support information retrieval based or entity-centric search of API caveats. As a proof-of-concept, we construct an API caveats knowledge graph for Android APIs from the API documentation on the Android Developers website. We study the abundance of different subcategories of API caveats and use a sampling method to manually evaluate the quality of the API caveats knowledge graph. We also conduct a user study to validate whether and how the API caveats knowledge graph may improve the accessibility of API caveats in API documentation. © 2018 IEEE.;IEEE;2018;10.1109/icsme.2018.00028;Li H., Li S., Sun J., Xing Z., Peng X., Liu M., Zhao X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058287370&doi=10.1109%2fICSME.2018.00028&partnerID=40&md5=4ef27c53df73fcaa669364c3d75f6673;Australia, China, Singapore;"entity extraction; relation extraction; entity linking; semantic search";validation research;method;engineering;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;programming bots by synthesizing natural language expressions into api invocations;"Botnet; Knowledge management; Learning systems; Software engineering; Complex applications; Development community; Entity recognition; Knowledge graphs; Lines of code; Natural language expressions; Natural languages; Real-world; Application programming interfaces (API)";"At present, bots are still in their preliminary stages of development. Many are relatively simple, or developed ad-hoc for a very specific use-case. For this reason, they are typically programmed manually, or utilize machine-learning classifiers to interpret a fixed set of user utterances. In reality, real world conversations with humans require support for dynamically capturing users expressions. Moreover, bots will derive immeasurable value by programming them to invoke APIs for their results. Today, within the Web and Mobile development community, complex applications are being stringed together with a few lines of code - all made possible by APIs. Yet, developers today are not as empowered to program bots in much the same way. To overcome this, we introduce BotBase, a bot programming platform that dynamically synthesizes natural language user expressions into API invocations. Our solution is two faceted: Firstly, we construct an API knowledge graph to encode and evolve APIs; secondly, leveraging the above we apply techniques in NLP, ML and Entity Recognition to perform the required synthesis from natural language user expressions into API calls. © 2017 IEEE.";IEEE;2017;10.1109/ase.2017.8115694;Zamanirad S., Benatallah B., Barukh M.C., Casati F., Rodriguez C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041448452&doi=10.1109%2fASE.2017.8115694&partnerID=40&md5=56e2ba36ccd6dc295937710f0751a7f4;Australia, Italy, Russian Federation;conversational interfaces;solution proposal;method;engineering;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1
Conference Paper;construction and application of knowledge graph of domestic operating system testing;Ontology construction, Reuse of test cases, Domestic operating system, Knowledge graph, Software testing;Aiming at the problems of poor reusability of domestic operating system test cases and insufficient sharing of test case design experience at this stage, a method for constructing knowledge graphs in the field of domestic operating system testing is proposed, and ontology construction and natural language processing technologies are applied to the field of software testing. Use the strong correlation of the knowledge graph to mine the experience knowledge in the design of historical test cases, select and reuse test cases that meet the test requirements for testers, and help them design test cases more efficiently. Through empirical research, this method gives full play to the advantages of knowledge graphs in relational network analysis and retrieval, and the coverage rate of reused test cases reaches 71%, which can greatly save test costs and improve test efficiency, and has strong engineering application value.;ACM;2021;10.1145/3494885.3494933;Jin, Dongsheng and Wang, Zhi and Li, Mingyang and Zhu, Xinjie;https://doi.org/10.1145/3494885.3494933;China;"entity extraction; relation extraction; ontology construction";solution proposal;tool;engineering;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;transfer in deep reinforcement learning using knowledge graphs;"Computer games; Graphic methods; Intelligent agents; Knowledge management; Learning systems; Natural language processing systems; Quality control; Reinforcement learning; Transfer learning; Adventure games; Domain knowledge; Knowledge graphs; Multiple computers; Question Answering; Reinforcement learning agent; State representation; Transfer learning methods; Deep learning";Text adventure games, in which players must make sense of the world through text descriptions and declare actions through text descriptions, provide a stepping stone toward grounding action in language. Prior work has demonstrated that using a knowledge graph as a state representation and question-answering to pre-train a deep Q-network facilitates faster control policy learning. In this paper, we explore the use of knowledge graphs as a representation for domain knowledge transfer for training text-adventure playing reinforcement learning agents. Our methods are tested across multiple computer generated and human authored games, varying in domain and complexity, and demonstrate that our transfer learning methods let us learn a higher-quality control policy faster. © 2019 EMNLP-IJCNLP 2019 - Graph-Based Methods for Natural Language Processing - Proceedings of the 13th Workshop. All rights reserved.;ACL;2019;;Ammanabrolu P., Riedl M.O.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085045262&partnerID=40&md5=c7c708325d80bd2488a7a6e8129a96f0;Georgia, United States;question answering;validation research;method;entertainment media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;playing text-adventure games with graph-based deep reinforcement learning;"Computational linguistics; Graphic methods; Natural language processing systems; Reinforcement learning; Transfer learning; Action spaces; Adventure games; Combinatorial action; Control policy; Graph-based; Knowledge graphs; Natural languages; Question Answering Task; Deep learning";Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language. We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration. This graph is used to prune the action space, enabling more efficient exploration. The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture. In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives. We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN. © 2019 Association for Computational Linguistics;ACL;2019;;Ammanabrolu P., Riedl M.O.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084309358&partnerID=40&md5=d963a79c4d1dc698fbf1568ac13464d2;Georgia, United States;question answering;validation research;tool;entertainment media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;a general process for the semantic annotation and enrichment of electronic program guides;"Electronic programming guides; Natural language processing; Semantic enrichment; Word embeddings";Electronic Program Guides (EPGs) are usual resources aimed to inform the audience about the programming being transmitted by TV stations and cable/satellite TV providers. However, they only provide basic metadata about the TV programs, while users may want to obtain additional information related to the content they are currently watching. This paper proposes a general process for the semantic annotation and subsequent enrichment of EPGs using external knowledge bases and natural language processing techniques with the aim to tackle the lack of immediate availability of related information about TV programs. Additionally, we define an evaluation approach based on a distributed representation of words that can enable TV content providers to verify the effectiveness of the system and perform an automatic execution of the enrichment process. We test our proposal using a real-world dataset and demonstrate its effectiveness by using different knowledge bases, word representation models and similarity measures. Results showed that DBpedia and Google Knowledge Graph knowledge bases return the most relevant content during the enrichment process, while word2vec and fasttext models with Words Mover’s Distance as similarity function can be combined to validate the effectiveness of the retrieval task. © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-21395-4_6;Gonzalez-Toral S., Espinoza-Mejia M., Palacio-Baus K., Saquicela V.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066117874&doi=10.1007%2f978-3-030-21395-4_6&partnerID=40&md5=eb0c586e64af57ec86124b4996db0299;Ecuador;semantic search;validation research;method;entertainment media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a natural language interface for search and recommendations of digital entertainment media;"Digital storage; Human computer interaction; Search engines; Conversation interface; Digital entertainment; Integrated platform; Knowledge graphs; Named entity recognition; Natural language interfaces; Natural languages; Relationships between entities; Natural language processing systems";We describe an integrated platform that combines a search and recommendations system of digital media with a novel conversation interface that enables users to use natural-language conversation for performing a variety of tasks on the digital content and information retrieval relating to meta-content. This advanced platform is built over a knowledge graph that consists of millions of tagged entities, along with structured relationships and popularities crawled and ingested from multiple sources, continuously evolving over time. The voice system uses a unique extensible architecture that combines natural language processing (NLP) techniques with named entity recognition of the knowledge graph determining both intent as well as entities extracted from user queries. Relationships between entities in the knowledge graph aid in identifying the right entities thereby creating meaningful, contextual, and temporally relevant interpretations. © 2015 IBC 2015. All rights reserved.;Scopus;2015;;Venkataraman S., Mohaideen N.A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048175643&partnerID=40&md5=57c0505be7679b94f767aa3e59d48b3c;United States;"conversational interfaces; semantic search";solution proposal;method;entertainment media;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;enriching word embeddings using knowledge graph for semantic tagging in conversational dialog systems;"Embeddings; Natural language processing systems; Semantics; Syntactics; Domain specific semantics; Knowledge graphs; Natural language queries; Objective functions; Semantic dependency; Semantic tagging; Syntactic dependencies; Word representations; Knowledge representation";Unsupervised word embeddings provide rich linguistic and conceptual information about words. However, they may provide weak information about domain specific semantic relations for certain tasks such as semantic parsing of natural language queries, where such information about words can be valuable. To encode the prior know ledge about the semantic word relations, we present new method as follows: we extend the neural network based lexical word embedding objective function (Mikolov et al. 2013) by incorporating the information about relationship between entities that we extract from knowledge bases. Our model can jointly learn lexical word representations from free text enriched by the relational word embeddings from relational data (e.g. Freebase) for each type of entity relations. We empirically show on the task of semantic tagging of natural language queries that our enriched embeddings can provide information about not only short-range syntactic dependencies but also long-range semantic dependencies between words. Using the enriched embeddings, we obtain an average of 2% improvement in F-score compared to the previous baselines. Copyright © 2015. Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;Scopus;2015;;Celikyilmaz A., Hakkani-Tiir D., Pasupat P., Sarikaya R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987629985&partnerID=40&md5=deb001215138bdab456b70f41603852e;United States;semantic parsing;validation research;technique;entertainment media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;the wasabi dataset: cultural, lyrics and audio analysis metadata about 2 million popular commercially released songs;"Linked data; Lyrics analysis; Music metadata; Named entities";Since 2017, the goal of the two-million song WASABI database has been to build a knowledge graph linking collected metadata (artists, discography, producers, dates, etc.) with metadata generated by the analysis of both the songs’ lyrics (topics, places, emotions, structure, etc.) and audio signal (chords, sound, etc.). It relies on natural language processing and machine learning methods for extraction, and semantic Web frameworks forrepresentation and integration. It describes more than 2 millions commercial songs, 200K albums and 77K artists. It can be exploited by music search engines, music professionals (e.g. journalists, radio presenters, music teachers) or scientists willing to analyze popular music published since 1950. It is available under an open license, in multiple formats and with online and open source services including an interactive navigator, a REST API and a SPARQL endpoint. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-77385-4_31;Buffa M., Cabrio E., Fell M., Gandon F., Giboin A., Hennequin R., Michel F., Pauwels J., Pellerin G., Tikat M., Winckler M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111106753&doi=10.1007%2f978-3-030-77385-4_31&partnerID=40&md5=bce385071e835b339fd4511411b72b6b;France, United Kingdom, Italy;semantic search;validation research;resource;entertainment media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Journal Article;natural language processing for music knowledge discovery;"entity linking; information extraction; Musicology; natural language processing; sentiment analysis";Today, a massive amount of musical knowledge is stored in written form, with testimonies dated as far back as several centuries ago. In this work, we present different Natural Language Processing (NLP) approaches to harness the potential of these text collections for automatic music knowledge discovery, covering different phases in a prototypical NLP pipeline, namely corpus compilation, text-mining, information extraction, knowledge graph generation, and sentiment analysis. Each of these approaches is presented alongside different use cases (i.e. flamenco, Renaissance and popular music) where large collections of documents are processed, and conclusions stemming from data-driven analyses are presented and discussed. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.;Scopus;2018;10.1080/09298215.2018.1488878;Oramas S., Espinosa-Anke L., Gómez F., Serra X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049580619&doi=10.1080%2f09298215.2018.1488878&partnerID=40&md5=2a5e0cc960847581c532f2aefd706b35;Spain, United Kingdom;"entity extraction; relation extraction; entity linking; semantic search";solution proposal;"method; guidelines";entertainment media;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;1
Conference Paper;natural language question/answering with user interaction over a knowledge base;"Knowledge Graph; Natural Language Processing; User Interaction";"In the demo, we present RecipeFinder, a system for searching the information from knowledge graphs with natural language. The sys-tem has following characteristics: (1) It supports human-computer interaction, to resolve question ambiguity; (2) It provides graphical interface to help users refine questions. © 2019 Association for Computing Machinery.";ACM;2019;10.1145/3349341.3349425;Zhan H., Sinha B., Jiang W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073052577&doi=10.1145%2f3349341.3349425&partnerID=40&md5=33a83971729b436f7cd30afdce501eca;China;question answering;solution proposal;tool;food;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;foodkg: a semantics-driven knowledge graph for food recommendation;"HTTP; Natural language processing systems; Cognitive agents; Construction process; Health condition; Knowledge graphs; Natural language questions; Software toolkits; Semantic Web";The proliferation of recipes and other food information on the Web presents an opportunity for discovering and organizing diet-related knowledge into a knowledge graph. Currently, there are several ontologies related to food, but they are specialized in specific domains, e.g., from an agricultural, production, or specific health condition point-of-view. There is a lack of a unified knowledge graph that is oriented towards consumers who want to eat healthily, and who need an integrated food suggestion service that encompasses food and recipes that they encounter on a day-to-day basis, along with the provenance of the information they receive. Our resource contribution is a software toolkit that can be used to create a unified food knowledge graph that links the various silos related to food while preserving the provenance information. We describe the construction process of our knowledge graph, the plan for its maintenance, and how this knowledge graph has been utilized in several applications. These applications include a SPARQL-based service that lets a user determine what recipe to make based on ingredients at hand while taking constraints such as allergies into account, as well as a cognitive agent that can perform natural language question answering on the knowledge graph. Resource Website: https://foodkg.github.io © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-30796-7_10;Haussmann S., Seneviratne O., Chen Y., Ne’eman Y., Codella J., Chen C.-H., McGuinness D.L., Zaki M.J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081079416&doi=10.1007%2f978-3-030-30796-7_10&partnerID=40&md5=10c19929136f853470c4d5eb27dd77af;United States;"entity extraction; relation extraction; ontology construction; question answering";validation research;"tool; resource";food;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;fine-grained information extraction from biomedical literature based on knowledge-enriched abstract meaning representation;"Artificial intelligence; Computational linguistics; Information retrieval; Knowledge based systems; Knowledge graph; Natural language processing systems; Semantics; Background knowledge; Biomedical information extractions; Biomedical literature; Domain specific; External knowledge; Extraction modeling; Fine grained; Natural languages texts; Scientific literature; Scientific papers; Complex networks";Biomedical Information Extraction from scientific literature presents two unique and nontrivial challenges. First, compared with general natural language texts, sentences from scientific papers usually possess wider contexts between knowledge elements. Moreover, comprehending the fine-grained scientific entities and events urgently requires domain-specific background knowledge. In this paper, we propose a novel biomedical Information Extraction (IE) model to tackle these two challenges and extract scientific entities and events from English research papers. We perform Abstract Meaning Representation (AMR) to compress the wide context to uncover a clear semantic structure for each complex sentence. Besides, we construct the sentence-level knowledge graph from an external knowledge base and use it to enrich the AMR graph to improve the model's understanding of complex scientific concepts. We use an edge-conditioned graph attention network to encode the knowledge-enriched AMR graph for biomedical IE tasks. Experiments on the GENIA 2011 dataset show that the AMR and external knowledge have contributed 1.8% and 3.0% absolute F-score gains respectively. In order to evaluate the impact of our approach on real-world problems that involve topic-specific fine-grained knowledge elements, we have also created a new ontology and annotated corpus for entity and event extraction for the COVID-19 scientific literature, which can serve as a new benchmark for the biomedical IE community. © 2021 Association for Computational Linguistics;ACL;2021;;Zhang Z., Parulian N., Ji H., Elsayed A.S., Myers S., Palmer M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115867463&partnerID=40&md5=1589ab2a22a2d2f1b0cf316aabe44065;United States;"entity extraction; relation extraction";validation research;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;joint biomedical entity and relation extraction with knowledge-enhanced collective inference;"Binding energy; Computational linguistics; Biomedical text; Collective inference; Domain information extraction; Domain knowledge; Entity extractions; External knowledge; Knowledge graphs; News domain; Relation extraction; State of the art; Knowledge graph";Compared to the general news domain, information extraction (IE) from biomedical text requires much broader domain knowledge. However, many previous IE methods do not utilize any external knowledge during inference. Due to the exponential growth of biomedical publications, models that do not go beyond their fixed set of parameters will likely fall behind. Inspired by how humans look up relevant information to comprehend a scientific text, we present a novel framework that utilizes external knowledge for joint entity and relation extraction named KECI (Knowledge-Enhanced Collective Inference). Given an input text, KECI first constructs an initial span graph representing its initial understanding of the text. It then uses an entity linker to form a knowledge graph containing relevant background knowledge for the the entity mentions in the text. To make the final predictions, KECI fuses the initial span graph and the knowledge graph into a more refined graph using an attention mechanism. KECI takes a collective approach to link mention spans to entities by integrating global relational information into local representations using graph convolutional networks. Our experimental results show that the framework is highly effective, achieving new state-of-the-art results in two different benchmark datasets: BioRelEx (binding interaction detection) and ADE (adverse drug event extraction). For example, KECI achieves absolute improvements of 4.59% and 4.91% in F1 scores over the state-of-the-art on the BioRelEx entity and relation extraction tasks. © 2021 Association for Computational Linguistics;ACL;2021;;Lai T., Ji H., Zhai C., Tran Q.H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114519900&partnerID=40&md5=a37a60f89adeb6120ac8af03ee7f338e;United States;"entity extraction; relation extraction";validation research;technique;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;bertkg-ddi: towards incorporating entity-specific knowledge graph information in predicting drug-drug interactions;"Embeddings; Knowledge representation; Natural language processing systems; Biomedical domain; Domain knowledge; Drug-drug interactions; Knowledge graphs; Natural language understanding; Relation classifications; Specific knowledge; State of the art; Drug interactions";Off-the-shelf biomedical embeddings obtained from the recently released various pre-trained language models (such as BERT, XLNET) have demonstrated state-of-the-art results (in terms of accuracy) for the various natural language understanding tasks (NLU) in the biomedical domain. Relation Classification (RC) falls into one of the most critical tasks. In this paper, we explore how to incorporate domain knowledge of the biomedical entities (such as drug, disease, genes), obtained from Knowledge Graph (KG) Embeddings, for predicting Drug-Drug Interaction from textual corpus. We propose a new method, BERTKG-DDI, to combine drug embeddings obtained from its interaction with other biomedical entities along with domain-specific BioBERT embedding-based RC architecture. Experiments conducted on the DDIExtraction 2013 corpus clearly indicate that this strategy improves other baselines architectures by 4.1% macro F1-score. Copyright © 2021for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).;Scopus;2021;;Mondal I.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103121791&partnerID=40&md5=2d3c79babc4ad8241255205756899bff;India;augmented language models;validation research;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;kgen: a knowledge graph generator from biomedical scientific literature;"Information Extraction; Knowledge Graphs; Ontologies; RDF Triples";Background: Knowledge is often produced from data generated in scientific investigations. An ever-growing number of scientific studies in several domains result into a massive amount of data, from which obtaining new knowledge requires computational help. For example, Alzheimer’s Disease, a life-threatening degenerative disease that is not yet curable. As the scientific community strives to better understand it and find a cure, great amounts of data have been generated, and new knowledge can be produced. A proper representation of such knowledge brings great benefits to researchers, to the scientific community, and consequently, to society. Methods: In this article, we study and evaluate a semi-automatic method that generates knowledge graphs (KGs) from biomedical texts in the scientific literature. Our solution explores natural language processing techniques with the aim of extracting and representing scientific literature knowledge encoded in KGs. Our method links entities and relations represented in KGs to concepts from existing biomedical ontologies available on the Web. We demonstrate the effectiveness of our method by generating KGs from unstructured texts obtained from a set of abstracts taken from scientific papers on the Alzheimer’s Disease. We involve physicians to compare our extracted triples from their manual extraction via their analysis of the abstracts. The evaluation further concerned a qualitative analysis by the physicians of the generated KGs with our software tool. Results: The experimental results indicate the quality of the generated KGs. The proposed method extracts a great amount of triples, showing the effectiveness of our rule-based method employed in the identification of relations in texts. In addition, ontology links are successfully obtained, which demonstrates the effectiveness of the ontology linking method proposed in this investigation. Conclusions: We demonstrate that our proposal is effective on building ontology-linked KGs representing the knowledge obtained from biomedical scientific texts. Such representation can add value to the research in various domains, enabling researchers to compare the occurrence of concepts from different studies. The KGs generated may pave the way to potential proposal of new theories based on data analysis to advance the state of the art in their research domains. © 2020, The Author(s).;Scopus;2020;10.1186/s12911-020-01341-5;Rossanez A., dos Reis J.C., Torres R.S., de Ribaupierre H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097554226&doi=10.1186%2fs12911-020-01341-5&partnerID=40&md5=fc9c69ff8b1fb180e8895d0c46348969;Brazil, United Kingdom, Norway;"entity extraction; relation extraction; ontology construction";validation research ;"tool; resource";health;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;knowledge detection and discovery using semantic graph embeddings on large knowledge graphs generated on text mining results;"Clinical research; Data integration; Decision making; Digital storage; Embeddings; Graphic methods; Information retrieval; Information systems; Information use; Knowledge representation; Natural language processing systems; Semantics; Algorithmic approach; Clinical decision making; Context information; Document Clustering; Knowledge extraction; Language technology; Scientific literature; Unstructured texts; Text mining";Knowledge graphs play a central role in big data integration, especially for connecting data from different domains. Bringing unstructured texts, e.g. from scientific literature, into a structured, comparable format is one of the key assets. Here, we use knowledge graphs in the biomedical domain working together with text mining based document data for knowledge extraction and retrieval from text and natural language structures. For example cause and effect models, can potentially facilitate clinical decision making or help to drive research towards precision medicine. However, the power of knowledge graphs critically depends on context information. Here we provide a novel semantic approach towards a context enriched biomedical knowledge graph utilizing data integration with linked data applied to language technologies and text mining. This graph concept can be used for graph embedding applied in different approaches, e.g with focus on topic detection, document clustering and knowledge discovery. We discuss algorithmic approaches to tackle these challenges and show results for several applications like search query finding and knowledge discovery. The presented remarkable approaches lead to valuable results on large knowledge graphs. © 2020 Polish Information Processing Society - as it is since 2011.;Scopus;2020;10.15439/2020f36;Dorpinghaus J., Jacobs M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095789650&doi=10.15439%2f2020F36&partnerID=40&md5=eec13e5800bbfd9a26200cff2d73104e;Germany;"knowledge graph embedding; semantic search";validation research;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;biomedical event extraction with hierarchical knowledge graphs;"Complex networks; Computational linguistics; Extraction; Graphic methods; Natural language processing systems; Biomolecular interactions; Complex events; Domain knowledge; Events extractions; Graph edges; Hierarchical graph representations; Hierarchical knowledge; Knowledge graphs; Language model; Unified medical language systems; Knowledge graph";Biomedical event extraction is critical in understanding biomolecular interactions described in scientific corpus. One of the main challenges is to identify nested structured events that are associated with non-indicative trigger words. We propose to incorporate domain knowledge from Unified Medical Language System (UMLS) to a pre-trained language model via a hierarchical graph representation encoded by a proposed Graph Edge-conditioned Attention Networks (GEANet). To better recognize the trigger words, each sentence is first grounded to a sentence graph based on a jointly modeled hierarchical knowledge graph from UMLS. The grounded graphs are then propagated by GEANet, a novel graph neural networks for enhanced capabilities in inferring complex events. On BioNLP 2011 GENIA Event Extraction task, our approach achieved 1.41% F1 and 3.19% F1 improvements on all events and complex events, respectively. Ablation studies confirm the importance of GEANet and hierarchical KG. ©2020 Association for Computational Linguistics;ACL;2020;;Huang K.-H., Yang M., Peng N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109732300&partnerID=40&md5=b63ec3f726a966a65e8732cea4e2f988;United States;"entity extraction; relation extraction";validation research;technique;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;adverse drug event prediction using noisy literature-derived knowledge graphs;"Adverse drug event; Deep learning; Knowledge graph embeddings";Adverse Drug Events (ADEs) are drug side-effects that are not known during clinical trials and cause substantial clinical and economic burden globally. A wealth of potential causal associations, that facilitate ADE discovery, lie in the growing body of biomedical literature, from which knowledge graphs - where vertices and edges represent clinical concepts and their relations - can be inferred using Natural Language Processing (NLP). State-of-the-art literature-based ADE prediction models employ representation learning to obtain vector representations of clinical concepts from such knowledge graphs, for use in machine learning models as features. However, previous representation learning methods do not model inaccuracies in the graph introduced during NLP inference. We develop a new method that addresses this limitation and learns clinical concept representations that have higher predictive value, for ADE identification, compared to those from previous methods, in our experiments. Our study thus highlights the importance of modelling such noise in literature-derived knowledge graphs. © ICIS 2020. All rights reserved.;Scopus;2020;;Lim A., Mariappan R., Rajan V.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103448748&partnerID=40&md5=3b77cb2d304d03fc335c51b05f3d1c2e;Singapore;knowledge graph embedding;validation research;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;drug-drug interaction prediction on a biomedical literature knowledge graph;"Drug-drug interactions; Knowledge discovery; Knowledge graph; Literature mining; Path analysis";Knowledge Graphs provide insights from data extracted in various domains. In this paper, we present an approach discovering probable drug-to-drug interactions, through the generation of a Knowledge Graph from disease-specific literature. The Graph is generated using natural language processing and semantic indexing of biomedical publications and open resources. The semantic paths connecting different drugs in the Graph are extracted and aggregated into feature vectors representing drug pairs. A classifier is trained on known interactions, extracted from a manually curated drug database used as a golden standard, and discovers new possible interacting pairs. We evaluate this approach on two use cases, Alzheimer’s Disease and Lung Cancer. Our system is shown to outperform competing graph embedding approaches, while also identifying new drug-drug interactions that are validated retrospectively. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-59137-3_12;Bougiatiotis K., Aisopos F., Nentidis A., Krithara A., Paliouras G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092241579&doi=10.1007%2f978-3-030-59137-3_12&partnerID=40&md5=c1433d47d57cebc5eb2e8e2938feb5f7;Greece;"link prediction; entity extraction; attribute extraction";validation research;tool;health;1;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;incorporating domain knowledge into medical nli using knowledge graphs;"Embeddings; Knowledge representation; Contextual words; Domain knowledge; Domain specific; Knowledge graphs; Medical domains; State of the art; State-of-the-art approach; Structured domain knowledge; Natural language processing systems";Recently, biomedical version of embeddings obtained from language models such as BioELMo have shown state-of-the-art results for the textual inference task in the medical domain. In this paper, we explore how to incorporate structured domain knowledge, available in the form of a knowledge graph (UMLS), for the Medical NLI task. Specifically, we experiment with fusing embeddings obtained from knowledge graph with the state-of-the-art approaches for NLI task, which mainly rely on contextual word embeddings. We also experiment with fusing the domain-specific sentiment information for the task. Experiments conducted on MedNLI dataset clearly show that this strategy improves the baseline BioELMo architecture for the Medical NLI task1. © 2019 Association for Computational Linguistics;ACL;2020;;Sharma S., Santosh T.Y.S.S., Santra B., Ganguly N., Jana A., Goyal P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084306601&partnerID=40&md5=15ad4243017b1c42293f5cfe7c28feb8;India;"augmented language models; natural language inference";validation research;tool;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;semantic data integration techniques for transforming big biomedical data into actionable knowledge;"Big Data; Biomedical Data; Knowledge Graph; Natural Language Processing; Semantic Data Integration";FAIR principles and the Open Data initiatives have motivated the publication of large volumes of data. Specifically, in the biomedical domain, the size of the data has increased exponentially in the last decade, and with the advances in the technologies to collect and generate data, a faster growth rate is expected for the next years. The available collections of data are characterized by the dominant dimensions of big data, i.e., they are not only large in volume, but they can be also heterogeneous and present quality issues. These data complexity problems impact on the typical tasks of data management, and particularly, in the task of integrating big biomedical data sources. We tackle the problem of big data integration and present a knowledge-driven framework able to extract and integrate data collected from structured and unstructured data sources. The proposed framework resorts to Natural Language Processing techniques to extract knowledge from unstructured data and short text. Furthermore, ontologies and controlled vocabularies, e.g., UMLS, are utilized to annotate the extracted entities and relations with terms from the ontology or controlled vocabulary. The annotated data is integrated into a knowledge graph. A unified schema is used to describe the meaning of the integrated data as well as the main properties and relations. As proof of concept, we show the results of applying the proposed framework to integrate clinical records from lung cancer patients with data extracted from open data sources like Drugbank and PubMed. The created knowledge graph enables the discovery of interactions between drugs in the treatments prescribed to lung cancer patients. © 2019 IEEE.;IEEE;2019;10.1109/cbms.2019.00116;Vidal M.-E., Jozashoori S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070971867&doi=10.1109%2fCBMS.2019.00116&partnerID=40&md5=05886717e5fc8034a9d0bc85bc45b07e;Germany;"entity extraction; relation extraction; semantic search";solution proposal;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;reasoning over paths via knowledge base completion;"Graphic methods; Knowledge based systems; Natural language processing systems; High frequency HF; Knowledge base; Knowledge graphs; Scientific literature; Simple approach; Vector representations; Graph theory";Reasoning over paths in large scale knowledge graphs is an important problem for many applications. In this paper we discuss a simple approach to automatically build and rank paths between a source and target entity pair with learned embeddings using a knowledge base completion model (KBC). We assembled a knowledge graph by mining the available biomedical scientific literature and extracted a set of high frequency paths to use for validation. We demonstrate that our method is able to effectively rank a list of known paths between a pair of entities and also come up with plausible paths that are not present in the knowledge graph. For a given entity pair we are able to reconstruct the highest ranking path 60% of the time within the top 10 ranked paths and achieve 49% mean average precision. Our approach is compositional since any KBC model that can produce vector representations of entities can be used. © 2019 EMNLP-IJCNLP 2019 - Graph-Based Methods for Natural Language Processing - Proceedings of the 13th Workshop. All rights reserved.;ACL;2019;;Sudhahar S., Roberts I., Pierleoni A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085036780&partnerID=40&md5=f5630074988db318a2f4d5f30aabbf28;United Kingdom;"relation classification; knowledge graph embedding; entity extraction; relation extraction";validation research;technique;health;1;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;the magic of semantic enrichment and nlp for medical coding;"Knowledge graphs; Medical coding; Natural Language Processing (NLP); Semantic enrichment; Word embeddings";Artificial Intelligence technologies are every day more present in the medical domain. Several healthcare activities that were entirely done manually by experts in the past, now are reaching a high level of automatization thanks to a satisfactory integration between these technologies and the medical professionals. This is the case of the medical coding process, consisting on the annotation of clinical notes (free-text narrative reports) to standard medical classifications in order to align this information with the patients’ records. This paper presents a combination of NLP and semantic enrichment techniques to generate an extended Biomedical Knowledge Graph in order to be exploited in the development of our automatic medical coding solution. © Springer Nature Switzerland AG 2019.;Scopus;2019;10.1007/978-3-030-32327-1_12;García-Santa N., San Miguel B., Ugai T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075575311&doi=10.1007%2f978-3-030-32327-1_12&partnerID=40&md5=30bde39ddf657142ebf5206687ddda25;Spain, Japan;"entity extraction; relation extraction";solution proposal;tool;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Journal Article;incorporating domain knowledge into language models by using graph convolutional networks for assessing semantic textual similarity: model development and performance comparison;"Bidirectional encoder representation from transformers; Graph neural networks; National NLP Clinical Challenges; Natural language processing";Background: Although electronic health record systems have facilitated clinical documentation in health care, they have also introduced new challenges, such as the proliferation of redundant information through the use of copy and paste commands or templates. One approach to trimming down bloated clinical documentation and improving clinical summarization is to identify highly similar text snippets with the goal of removing such text. Objective: We developed a natural language processing system for the task of assessing clinical semantic textual similarity. The system assigns scores to pairs of clinical text snippets based on their clinical semantic similarity. Methods: We leveraged recent advances in natural language processing and graph representation learning to create a model that combines linguistic and domain knowledge information from the MedSTS data set to assess clinical semantic textual similarity. We used bidirectional encoder representation from transformers (BERT)-based models as text encoders for the sentence pairs in the data set and graph convolutional networks (GCNs) as graph encoders for corresponding concept graphs that were constructed based on the sentences. We also explored techniques, including data augmentation, ensembling, and knowledge distillation, to improve the model's performance, as measured by the Pearson correlation coefficient (r). Results: Fine-tuning the BERT_base and ClinicalBERT models on the MedSTS data set provided a strong baseline (Pearson correlation coefficients: 0.842 and 0.848, respectively) compared to those of the previous year's submissions. Our data augmentation techniques yielded moderate gains in performance, and adding a GCN-based graph encoder to incorporate the concept graphs also boosted performance, especially when the node features were initialized with pretrained knowledge graph embeddings of the concepts (r=0.868). As expected, ensembling improved performance, and performing multisource ensembling by using different language model variants, conducting knowledge distillation with the multisource ensemble model, and taking a final ensemble of the distilled models further improved the system's performance (Pearson correlation coefficients: 0.875, 0.878, and 0.882, respectively). Conclusions: This study presents a system for the MedSTS clinical semantic textual similarity benchmark task, which was created by combining BERT-based text encoders and GCN-based graph encoders in order to incorporate domain knowledge into the natural language processing pipeline. We also experimented with other techniques involving data augmentation, pretrained concept embeddings, ensembling, and knowledge distillation to further increase our system's performance. Although the task and its benchmark data set are in the early stages of development, this study, as well as the results of the competition, demonstrates the potential of modern language model-based systems to detect redundant information in clinical notes. © 2021 JMIR Publications Inc.. All rights reserved.;Scopus;2021;10.2196/23101;Chang D., Lin E., Brandt C., Taylor R.A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120171749&doi=10.2196%2f23101&partnerID=40&md5=75cd7707fc3f80c27955fa4d85f4c2a5;United States;"augmented language models; semantic similarity; knowledge graph embedding";validation research;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a knowledge graph based question answering method for medical domain;"Artificial Intelligence; Data Mining and Machine Learning; Knowledge graph; Medical domain; Natural Language and Speech; Question answering; Weighted path ranking";Question answering (QA) is a hot field of research in Natural Language Processing. A big challenge in this field is to answer questions from knowledge-dependable domain. Since traditional QA hardly satisfies some knowledge-dependable situations, such as disease diagnosis, drug recommendation, etc. In recent years, researches focus on knowledge-based question answering (KBQA). However, there still exist some problems in KBQA, traditional KBQA is limited by a range of historical cases and takes too much human labor. To address the problems, in this paper, we propose an approach of knowledge graph based question answering (KGQA) method for medical domain, which firstly constructs a medical knowledge graph by extracting named entities and relations between the entities from medical documents. Then, in order to understand a question, it extracts the key information in the question according to the named entities, and meanwhile, it recognizes the questions’ intentions by adopting information gain. The next an inference method based on weighted path ranking on the knowledge graph is proposed to score the related entities according to the key information and intention of a given question. Finally, it extracts the inferred candidate entities to construct answers. Our approach can understand questions, connect the questions to the knowledge graph and inference the answers on the knowledge graph. Theoretical analysis and real-life experimental results show the efficiency of our approach. © 2021. Huang et al.;Scopus;2021;10.7717/peerj-cs.667;Huang X., Zhang J., Xu Z., Ou L., Tong J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116399084&doi=10.7717%2fpeerj-cs.667&partnerID=40&md5=5ae8448c08857ac21d10e4493b8d3b8b;China;question answering;validation research;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;detecting suicide risk using knowledge-aware natural language processing and counseling service data;"Artificial intelligence; Knowledge graph; Natural language processing; Online counseling services; Suicide prevention";Rationale: Detecting users at risk of suicide in text-based counseling services is essential to ensure that at-risk individuals are flagged and prioritized. Objective: The objective of this study is to develop a domain knowledge-aware risk assessment (KARA) model to improve our ability of suicide detection in online counseling systems. Methods: We obtained the largest known de-identified dataset from an emotional support system established in Hong Kong, comprising 5682 Cantonese conversations between help-seekers and counselors. Of those, 682 conversations disclosed crisis intentions of suicide. We constructed a suicide-knowledge graph, representing suicide-related domain knowledge as a computer-processible graph. Such knowledge graph was embedded into a deep learning model to improve its ability to identify help-seekers in crisis. As the baseline, a standard NLP model was applied to the same task. 80% of the study samples were randomly sampled to train model parameters. The remaining 20% were used for model validation. Evaluation metrics including precision, recall, and c-statistic were reported. Results: Both KARA and the baseline achieved high precision (0.984 and 0.951, shown in Table 2) and high recall (0.942 and 0.947) towards non-crisis cases. For crisis cases, however, KARA model achieved a much higher recall than the baseline (0.870 vs 0.791). The c-statistics of KARA and the baseline were 0.815 and 0.760, respectively. Conclusion: KARA significantly outperformed standard NLP models, demonstrating good translational value and clinical relevance. © 2021 Elsevier Ltd;ScienceDirect;2021;10.1016/j.socscimed.2021.114176;Xu Z., Xu Y., Cheung F., Cheng M., Lung D., Law Y.W., Chiang B., Zhang Q., Yip P.S.F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108917661&doi=10.1016%2fj.socscimed.2021.114176&partnerID=40&md5=90af0d089719b25e3fe12732734fa4a1;Hong Kong;text classification;validation research;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;research on the construction and application of breast cancer-specific database system based on full data lifecycle;"breast cancer; data governance; data security sharing; disease-specific database; knowledge graph; metadata";Relying on the Biomedical Big Data Center of West China Hospital, this paper makes an in-depth research on the construction method and application of breast cancer-specific database system based on full data lifecycle, including the establishment of data standards, data fusion and governance, multi-modal knowledge graph, data security sharing and value application of breast cancer-specific database. The research was developed by establishing the breast cancer master data and metadata standards, then collecting, mapping and governing the structured and unstructured clinical data, and parsing and processing the electronic medical records with NLP natural language processing method or other applicable methods, as well as constructing the breast cancer-specific database system to support the application of data in clinical practices, scientific research, and teaching in hospitals, giving full play to the value of medical big data of the Biomedical Big Data Center of West China Hospital. © Copyright © 2021 Jin, Junren, Jingwen, Yajing, Xi and Ke.;Scopus;2021;10.3389/fpubh.2021.712827;Jin Y., Junren W., Jingwen J., Yajing S., Xi C., Ke Q.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111395848&doi=10.3389%2ffpubh.2021.712827&partnerID=40&md5=edbb067353fb4669563c44dcecff2bb1;China;entity extraction;solution proposal;"method; tool";health;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;drug-drug interaction predictions via knowledge graph and text embedding: instrument validation study;"Drug-drug interactions; Knowledge graph; Natural language processing";Background: Minimizing adverse reactions caused by drug-drug interactions (DDIs) has always been a prominent research topic in clinical pharmacology. Detecting all possible interactions through clinical studies before a drug is released to the market is a demanding task. The power of big data is opening up new approaches to discovering various DDIs. However, these data contain a huge amount of noise and provide knowledge bases that are far from being complete or used with reliability. Most existing studies focus on predicting binary DDIs between drug pairs and ignore other interactions. Objective: Leveraging both drug knowledge graphs and biomedical text is a promising pathway for rich and comprehensive DDI prediction, but it is not without issues. Our proposed model seeks to address the following challenges: data noise and incompleteness, data sparsity, and computational complexity. Methods: We propose a novel framework, Predicting Rich DDI, to predict DDIs. The framework uses graph embedding to overcome data incompleteness and sparsity issues to make multiple DDI label predictions. First, a large-scale drug knowledge graph is generated from different sources. The knowledge graph is then embedded with comprehensive biomedical text into a common low-dimensional space. Finally, the learned embeddings are used to efficiently compute rich DDI information through a link prediction process. Results: To validate the effectiveness of the proposed framework, extensive experiments were conducted on real-world data sets. The results demonstrate that our model outperforms several state-of-the-art baseline methods in terms of capability and accuracy. Conclusions: We propose a novel framework, Predicting Rich DDI, to predict DDIs. Using rich DDI information, it can competently predict multiple labels for a pair of drugs across numerous domains, ranging from pharmacological mechanisms to side effects. To the best of our knowledge, this framework is the first to provide a joint translation-based embedding model that learns DDIs by integrating drug knowledge graphs and biomedical text simultaneously in a common low-dimensional space. The model also predicts DDIs using multiple labels rather than single or binary labels. Extensive experiments were conducted on real-world data sets to demonstrate the effectiveness and efficiency of the model. The results show our proposed framework outperforms several state-of-the-art baselines. © 2021 JMIR Medical Education.;Scopus;2021;10.2196/28277;Wang M., Wang H., Liu X., Ma X., Wang B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108820673&doi=10.2196%2f28277&partnerID=40&md5=12ad88a4b49d95f0f4fceb820bf885ca;China;"entity linking; link prediction; knowledge graph embedding";validation research;method;health;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a literature-derived knowledge graph augments the interpretation of single cell rna-seq datasets;"Natural language processing; Single cell genomics";"Technology to generate single cell RNA-sequencing (scRNA-seq) datasets and tools to annotate them have advanced rapidly in the past several years. Such tools generally rely on existing transcriptomic datasets or curated databases of cell type defining genes, while the application of scalable natural language processing (NLP) methods to enhance analysis workflows has not been adequately explored. Here we deployed an NLP framework to objectively quantify associations between a comprehensive set of over 20,000 human protein-coding genes and over 500 cell type terms across over 26 million biomedical documents. The resultant gene-cell type associations (GCAs) are significantly stronger between a curated set of matched cell type-marker pairs than the complementary set of mismatched pairs (Mann Whitney p = 6.15 × 10−76, r = 0.24; cohen’s D = 2.6). Building on this, we developed an augmented annotation algorithm (single cell Annotation via Literature Encoding, or scALE) that leverages GCAs to categorize cell clusters identified in scRNA-seq datasets, and we tested its ability to predict the cellular identity of 133 clusters from nine datasets of human breast, colon, heart, joint, ovary, prostate, skin, and small intestine tissues. With the optimized settings, the true cellular identity matched the top prediction in 59% of tested clusters and was present among the top five predictions for 91% of clusters. scALE slightly outperformed an existing method for reference data driven automated cluster annotation, and we demonstrate that integration of scALE can meaningfully improve the annotations derived from such methods. Further, contextualization of differential expression analyses with these GCAs highlights poorly characterized markers of well-studied cell types, such as CLIC6 and DNASE1L3 in retinal pigment epithelial cells and endothelial cells, respectively. Taken together, this study illustrates for the first time how the systematic application of a literature-derived knowledge graph can expedite and enhance the annotation and interpretation of scRNA-seq data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.";Scopus;2021;10.3390/genes12060898;Doddahonnaiah D., Lenehan P.J., Hughes T.K., Zemmour D., Garcia-Rivera E., Venkatakrishnan A.J., Chilaka R., Khare A., Kasaraneni A., Garg A., Anand A., Barve R., Thiagarajan V., Soundararajan V.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108405001&doi=10.3390%2fgenes12060898&partnerID=40&md5=ae16a148c6cecba93f21a2b11bf2c102;India, United States;semantic search;validation research;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;research on application of chinese natural language processing in constructing knowledge graph of chronic diseases;"Knowledge Graph; Named entity recognition; Natural language processing; Relationship extraction";Knowledge Graph can describe the concepts in the objective world and the relationships between these concepts in a structured way, and identify, discover and infer the relationships between things and concepts. It has been developed in the field of medical and health care. In this paper, the method of natural language processing has been used to build chronic disease knowledge graph, such as named entity recognition, relationship extraction. This method is beneficial to forecast analysis of chronic disease, network monitoring, basic education, etc. The research of this paper can greatly help medical experts in the treatment of chronic disease treatment, and assist primary clinicians with making more scientific decision, and can help Patients with chronic diseases to improve medical efficiency. In the end, it also has practical significance for clinical scientific research of chronic disease. © 2021 IEEE.;IEEE;2021;10.1109/cisce52179.2021.9445976;Qin S., Xu C., Zhang F., Jiang T., Ge W., Li J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111428835&doi=10.1109%2fCISCE52179.2021.9445976&partnerID=40&md5=19c9fd0e21a582d4faa8adebcee84e3f;China;"entity extraction; relation extraction";solution proposal;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;construction of therapy-disease knowledge graph (tdkg) based on entity relationship extraction;"Knowledge Graph; Natural Language Processing; Relation Extraction; Treatment";"The knowledge graph of treatment-disease relationship can be a benefit not only to understand, inquire, and learn the relations between treatments and diseases from a macro level, but also to obtain the differences between treatments to the same disease through the comparison of different treatments; with the aid of commonalities of some treatments, a treatment to a disease that has not been discovered may be recognized; and with the aid of the commonalities of some diseases, a treatment to a disease that has not been discovered may be recognized too. At present, the therapy-disease knowledge graph has become the focus of medical informatics fields. International and domestic Internet giants have deployed some products in this area. The basic method of knowledge graph research is relation extraction in natural language processing. This paper uses semantic technology to discover several sentence patterns expressed in the therapy-disease sentence, and uses a method similar to BERT, that is, using the known part of the sentence to learn the unknown part of the sentence. An unsupervised learning algorithm is designed that extracts the relationship between therapies and diseases. By extracting the relationship between diseases and therapies entities from the abstracts of 300844 literature on diseases' treatments, 203, 238 entity relationships were identified, of which 180, 675 entity relationships were valid. The results show that the sentence patterns expressing entity relationships in the literature on disease-treatment are relatively fixed. The entity relationship extraction is performed by dividing the sentence structure by subject, predicate and object. And the accuracy of extraction is 88.98%, and the recall rate is 60.05%. © 2021 IEEE.";IEEE;2021;10.1109/aemcse51986.2021.00173;Wang H., Wang A., Su F., Feng H., Chen Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114034422&doi=10.1109%2fAEMCSE51986.2021.00173&partnerID=40&md5=5680b3aa153414fa30059605ccad5812;China;relation extraction;solution proposal;technique;health;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;smedbert: a knowledge-enhanced pre-trained language model with structured semantics for medical text mining;"Computational linguistics; Natural language processing systems; Semantics; Background knowledge; Knowledge sources; Language model; Language understanding; Large-scales; Medical domains; Medical terms; Performance; Semantic representation; Text-mining; Knowledge graph";Recently, the performance of Pre-trained Language Models (PLMs) has been significantly improved by injecting knowledge facts to enhance their abilities of language understanding. For medical domains, the background knowledge sources are especially useful, due to the massive medical terms and their complicated relations are difficult to understand in text. In this work, we introduce SMedBERT, a medical PLM trained on large-scale medical corpora, incorporating deep structured semantics knowledge from neighbours of linked-entity. In SMedBERT, the mention-neighbour hybrid attention is proposed to learn heterogeneous-entity information, which infuses the semantic representations of entity types into the homogeneous neighbouring entity structure. Apart from knowledge integration as external features, we propose to employ the neighbors of linked-entities in the knowledge graph as additional global contexts of text mentions, allowing them to communicate via shared neighbors, thus enrich their semantic representations. Experiments demonstrate that SMedBERT significantly outperforms strong baselines in various knowledge-intensive Chinese medical tasks. It also improves the performance of other tasks such as question answering, question matching and natural language inference. © 2021 Association for Computational Linguistics;ACL;2021;;Zhang T., Cai Z., Wang C., Qiu M., Yang B., He X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115667288&partnerID=40&md5=f2a063d45b53f12db67ca76c9d82132c;China;augmented language models;validation research;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a chinese machine reading comprehension dataset automatic generated based on knowledge graph;"Knowledge graph; Machine reading comprehension; PLMs";Machine reading comprehension (MRC) is a typical natural language processing (NLP) task and has developed rapidly in the last few years. Various reading comprehension datasets have been built to support MRC studies. However, large-scale and high-quality datasets are rare due to the high complexity and huge workforce cost of making such a dataset. Besides, most reading comprehension datasets are in English, and Chinese datasets are insufficient. In this paper, we propose an automatic method for MRC dataset generation, and build the largest Chinese medical reading comprehension dataset presently named CMedRC. Our dataset contains 17k questions generated by our automatic method and some seed questions. We obtain the corresponding answers from a medical knowledge graph and manually check all of them. Finally, we test BiLSTM and BERT-based pre-trained language models (PLMs) on our dataset and propose a baseline for the following studies. Results show that the automatic MRC dataset generation method is considerable for future model improvements. © 2021, Springer Nature Switzerland AG.;ACL;2021;10.1007/978-3-030-84186-7_18;Zhao H., Yuan S., Leng J., Pan X., Xue Z., Ma Q., Liang Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113578050&doi=10.1007%2f978-3-030-84186-7_18&partnerID=40&md5=e17697829fea1c40d22e12c9ef982cff;China, United States;"question answering; question generation";validation research;"method; resource";health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;interactive domain-specific knowledge graphs from text: a covid-19 implementation;"COVID-19; Information retrieval software; Knowledge graphs; Natural language processing; Personalized analytics";Information creation runs at a higher rate than information assimilation, creating an information gap for domain specialists that usual information frameworks such as search engines are unable to bridge. Knowledge graphs have been used to summarize large amounts of textual data, therefore facilitating information retrieval, but they require programming and machine learning skills not usually available to domains specialists. To bridge this gap, this work proposes a framework, KG4All (Knowledge Graphs for All), to allow for domain specialists to build and interact with a knowledge graph created from their own chosen corpus. In order to build the knowledge graph, a transition-based system model is used to extract and link medical entities, with tokens represented as embeddings from the prefix, suffix, shape and lemmatized features of individual words. We used abstracts from the COVID-19 Open Research Dataset Challenge (CORD-19) as corpus to test the framework. The results include an online prototype and correspondent source code. Preliminary results show that it is possible to automate the extraction of entity relations from medical text and to build an interactive user knowledge graph without programming background. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.;Scopus;2021;10.1007/978-3-030-77417-2_18;de Sousa V.M., Kern V.M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111379685&doi=10.1007%2f978-3-030-77417-2_18&partnerID=40&md5=2d50742b21c49abc22919efb7e1e28a3;Brazil;"entity extraction; relation extraction; semantic search";solution proposal;tool;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;drug repositioning based on network-specific core genes identifies potential drugs for the treatment of autism spectrum disorder in children;"Autism spectrum disorder; Coexpression network; Drug repositioning; Knowledge graph; Natural language processing";Identification of exact causative genes is important for in silico drug repositioning based on drug-gene-disease relationships. However, the complex polygenic etiology of the autism spectrum disorder (ASD) is a challenge in the identification of etiological genes. The network-based core gene identification method can effectively use the interactions between genes and accurately identify the pathogenic genes of ASD. We developed a novel network-based drug repositioning framework that contains three steps: network-specific core gene (NCG) identification, potential therapeutic drug repositioning, and candidate drug validation. First, through the analysis of transcriptome data for 178 brain tissues, gene network analysis identified 365 NCGs in 18 coexpression modules that were significantly correlated with ASD. Second, we evaluated two proposed drug repositioning methods. In one novel approach (dtGSEA), we used the NCGs to probe drug-gene interaction data and identified 35 candidate drugs. In another approach, we compared NCG expression patterns with drug-induced transcriptome data from the Connectivity Map database and found 46 candidate drugs. Third, we validated the candidate drugs using an in-house mental diseases and compounds knowledge graph (MCKG) that contained 7509 compounds, 505 mental diseases, and 123,890 edges. We found a total of 42 candidate drugs that were associated with mental illness, among which 10 drugs (baclofen, sulpiride, estradiol, entinostat, everolimus, fluvoxamine, curcumin, calcitriol, metronidazole, and zinc) were postulated to be associated with ASD. This study proposes a powerful network-based drug repositioning framework and also provides candidate drugs as well as potential drug targets for the subsequent development of ASD therapeutic drugs. © 2021 The Authors;ScienceDirect;2021;10.1016/j.csbj.2021.06.046;Gao H., Ni Y., Mo X., Li D., Teng S., Huang Q., Huang S., Liu G., Zhang S., Tang Y., Lu L., Liang H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110120513&doi=10.1016%2fj.csbj.2021.06.046&partnerID=40&md5=121efe941832da8b55c21e42521bcd11;China;semantic search;validation research;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;automated medical reporting: from multimodal inputs to medical reports through knowledge graphs;"Automated Reporting; Dialogue Interpretation; Electronic Medical Record; Healthcare Workflow Management; Knowledge Graphs; Patient Medical Graph";Care providers generally experience a high workload mainly due to the large amount of time required for adequate documentation. This paper presents our visionary idea of real-time automated medical reporting through the integration of speech and action recognition technology with knowledge-based summarization of the interaction between care provider and patient. We introduce the Patient Medical Graph as a formal representation of the dialogue and actions during a medical consultation. This knowledge graph represents human anatomical entities, symptoms, medical observations, diagnoses and treatment plans. The formal representation enables automated preparation of a consultation report by means of sentence plans to generate natural language. The architecture and functionality of the Care2Report prototype illustrate our vision of automated reporting of human communication and activities using knowledge graphs and NLP tools. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved;Scopus;2021;;Maas L., Kisjes A., Hashemi I., Heijmans F., Dalpiaz F., van Dulmen S., Brinkkemper S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103819304&partnerID=40&md5=3fa4564632dd16ff158745ab59b96749;Netherlands;conversational interfaces;solution proposal;tool;health;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;research on medical question answering system based on knowledge graph;"knowledge graph; medical knowledge; Natural language processing; question and answer system";To meet the high-efficiency question answering needs of existing patients and doctors, this system integrates medical professional knowledge, knowledge graphs, and question answering systems that conduct man-machine dialogue through natural language. This system locates the medical field, uses crawler technology to use vertical medical websites as data sources, and uses diseases as the core entity to construct a knowledge graph containing 44,000 knowledge entities of 7 types and 300,000 entities of 11 kinds. It is stored in the Neo4j graph database, using rule-based matching methods and string-matching algorithms to construct a domain lexicon to classify and query questions. This system has specific practical value in the medical field knowledge graph and question answering system. © 2013 IEEE.;IEEE;2021;10.1109/access.2021.3055371;Jiang Z., Chi C., Zhan Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100497832&doi=10.1109%2fACCESS.2021.3055371&partnerID=40&md5=d0ca64c32fbac37501bed0410ad5f096;China;"entity extraction; relation extraction; attribute extraction; question answering";solution proposal;tool;health;1;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;dynamic causality knowledge graph generation for supporting the chatbot healthcare system;"Artificial intelligent; Causality analysis; Chatbot; Healthcare; Knowledge graph; Natural language processing";With recent viruses across the world affecting millions and millions of people, the self-healthcare information systems show an important role in helping individuals to understand the risks, self-assessment, and self-educating to avoid being affected. In addition, self-healthcare information systems can perform more interactive tasks to effectively assist the treatment process and health condition management. Currently, the technologies used in such kind of systems are mostly based on text crawling from website resources such as text-searching and blog-based crowdsourcing applications. In this research paper, we introduce a novel Artificial Intelligence (AI) framework to support interactive and causality reasoning for a Chatbot application. The Chatbot will interact with the user to provide self-healthcare education and self-assessment (condition prediction). The framework is a combination of Natural Language Processing (NLP) and Knowledge Graph (KG) technologies with added causality and probability (uncertainty) properties to original Description Logic. This novel framework can generate causal knowledge probability neural networks to perform question answering and condition prediction tasks. The experimental results from a prototype showed strong positive feedback. The paper also identified remaining limitations and future research directions. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-63092-8_3;Yu H.Q.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096464640&doi=10.1007%2f978-3-030-63092-8_3&partnerID=40&md5=ec3417be4502dd39e391b41896dfbebb;United Kingdom;conversational interfaces;solution proposal;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;a deep learning knowledge graph approach to drug labelling;"deep learning; drug labels; knowledge graph embeddings; LSTM";Ensuring the accuracy and completeness of drug labels is a labour-intensive and potentially error prone process, as labels contain unstructured text that is not suitable for automated processing. To address this, we have developed a novel deep learning system that uses a bidirectional LSTM model to extract and structure drug information in a knowledge graph-based embedding space. This allows us to evaluate drug label consistency with ground truth knowledge, along with the ability to predict additional drug interactions. Annotated sentences from 7,117 drug labels sentences were used to train the LSTM model and 1,779 were used to test it. The drug entity extraction system was able to correctly detect relevant entities and relations with a F1 score of 91% and 81% respectively. The knowledge graph embedding model was able to identify inconsistent facts with ground truth data in 76% of the cases tested. This demonstrates that there is potential in building a natural language processing system that automatically extracts drug interaction information from drug labels and embeds this structured data into a knowledge graph embedding space to help evaluate drug label accuracy. We note that the accuracy of the system needs to be improved significantly before it can fully automate drug labeling related tasks. Rather such a system could provide best utility within a human-in-the-loop approach, where operators augment model training and evaluation. © 2020 IEEE.;IEEE;2020;10.1109/bibm49941.2020.9313350;Sastre J., Zaman F., Duggan N., McDonagh C., Walsh P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100330601&doi=10.1109%2fBIBM49941.2020.9313350&partnerID=40&md5=833d1e46def4c00273ca698715e038c3;Ireland;"knowledge graph embedding; entity extraction";validation research;technique;health;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;link prediction using semi-automated ontology and knowledge graph in medical sphere;"COVID-19; Deep learning; Graph convolutional networks; Knowledge Graph; link prediction; MeSH; Natural language processing; Ontology";Presently, medical professionals and researchers face a dire problem trying to identify important and subject specific documents for medical research. This is mainly owing to the fact that there is a disconnection in the pipeline for finding essential documents via a common platform which can parse and link the complex medical terminologies. To solve this problem, a model is generated, which creates a Semi-automated ontology and Knowledge-graph for link prediction using unstructured medical documents. To extract entities from a document is a tiresome task but can be achieved using multiple resources like DBPedia, pretrained statistical models on English provided by spaCy. Though, for biomedical data above two are not enough, as another key challenge with biomedical data is with its commonly occurring abbreviated names and noun compounds containing punctuation, which might lead to misidentification. To overcome this problem and also to train this model more medical specific, [bionlp13cg] model provided by scispaCy is used. It is a spaCy NER model trained on the BIONLP13CG corpus. This model not only extracts entities which are more specific to the medical domain, but also label them according to the category they belong to. All the entities are classified into subclass and main-class using ontologies. Hence link is predicted between two entities according to the categories they belong to. Ontology is created using Medical Subject Headings (MeSH) RDF. It is a linked data representation of the MeSH biomedical vocabulary produced by the National Library of Medicine, thereby it provides precise results. Since, some entities are not identified by Mesh, they are first categorized using labels obtained by scispaCy, if it is recognized by latter. Further these categories are mapped to MeSH Ontology to enhance the precision of linked entities. Since this model is graph enabled, it gives users a very specific relation between medical terminologies. © 2020 IEEE.;IEEE;2020;10.1109/indicon49873.2020.9342301;Varma S., Shivam S., Jamaiyar R., Anukriti A., Kashyap S., Sarkar A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101501532&doi=10.1109%2fINDICON49873.2020.9342301&partnerID=40&md5=934e555733cacf01164cde61e33f5ac5;India;"link prediction; entity extraction; ontology construction";solution proposal;technique;health;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;using character-level and entity-level representations to enhance bidirectional encoder representation from transformers-based clinical semantic textual similarity model: clinicalsts modeling study;"Clinical semantic textual similarity; Deep learning; Knowledge graph; Natural language processing";"Background: With the popularity of electronic health records (EHRs), the quality of health care has been improved. However, there are also some problems caused by EHRs, such as the growing use of copy-and-paste and templates, resulting in EHRs of low quality in content. In order to minimize data redundancy in different documents, Harvard Medical School and Mayo Clinic organized a national natural language processing (NLP) clinical challenge (n2c2) on clinical semantic textual similarity (ClinicalSTS) in 2019. The task of this challenge is to compute the semantic similarity among clinical text snippets. Objective: In this study, we aim to investigate novel methods to model ClinicalSTS and analyze the results. Methods: We propose a semantically enhanced text matching model for the 2019 n2c2/Open Health NLP (OHNLP) challenge on ClinicalSTS. The model includes 3 representation modules to encode clinical text snippet pairs at different levels: (1) character-level representation module based on convolutional neural network (CNN) to tackle the out-of-vocabulary problem in NLP; (2) sentence-level representation module that adopts a pretrained language model bidirectional encoder representation from transformers (BERT) to encode clinical text snippet pairs; and (3) entity-level representation module to model clinical entity information in clinical text snippets. In the case of entity-level representation, we compare 2 methods. One encodes entities by the entity-type label sequence corresponding to text snippet (called entity I), whereas the other encodes entities by their representation in MeSH, a knowledge graph in the medical domain (called entity II). Results: We conduct experiments on the ClinicalSTS corpus of the 2019 n2c2/OHNLP challenge for model performance evaluation. The model only using BERT for text snippet pair encoding achieved a Pearson correlation coefficient (PCC) of 0.848. When character-level representation and entity-level representation are individually added into our model, the PCC increased to 0.857 and 0.854 (entity I)/0.859 (entity II), respectively. When both character-level representation and entity-level representation are added into our model, the PCC further increased to 0.861 (entity I) and 0.868 (entity II). Conclusions: Experimental results show that both character-level information and entity-level information can effectively enhance the BERT-based STS model. © Ying Xiong, Shuai Chen, Qingcai Chen, Jun Yan, Buzhou Tang. Originally published in JMIR Medical Informatics (http://medinform.jmir.org), 29.12.2020. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Medical Informatics, is properly cited. The complete bibliographic information, a link to the original publication on http://medinform.jmir.org/, as well as this copyright and license information must be included.";Scopus;2020;10.2196/23357;Xiong Y., Chen S., Chen Q., Yan J., Tang B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098537330&doi=10.2196%2f23357&partnerID=40&md5=3bffae3ee2d61d23c487f717aaf44ee1;China;"semantic similarity; augmented language models";validation research ;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;exploring the social drivers of health during a pandemic: leveraging knowledge graphs and population trends in covid-19;"COVID-19 risk factors; Knowledge Graphs; Natural Language Processing; Population Trends; Relation Extraction; Social determinants of health";Social determinants of health (SDoH) are the factors which lie outside of the traditional health system, such as employment or access to nutritious foods, that influence health outcomes. Some efforts have focused on identifying vulnerable populations during the COVID-19 pandemic, however, both the short-and long-term social impacts of the pandemic on individuals and populations are not well understood. This paper presents a pipeline to discover health outcomes and related social factors based on trending SDoH at population-level using Google Trends. A knowledge graph was built from a corpus of research literature (PubMed) and the social determinants that trended high at the start of the pandemic were examined. This paper reports on related social and health concepts which may be impacted by the COVID-19 outbreak and may be important to monitor as the pandemic evolves. The proposed pipeline should have wider applicability in surfacing related social or clinical characteristics of interest, outbreak surveillance, or to mine relations between social and health concepts that can, in turn, help inform and support citizen-centred services. © 2020 The European Federation for Medical Informatics (EFMI) and IOS Press.;Scopus;2020;10.3233/shti200684;Bettencourt-Silva J.H., Mulligan N., Jochim C., Yadav N., Sedlazek W., Lopez V., Gleize M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096733678&doi=10.3233%2fSHTI200684&partnerID=40&md5=f8281b9f3569922d2d958fdaead2bf79;Ireland;"entity extraction; relation extraction; semantic search";solution proposal;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;drug repurposing against parkinson's disease by text mining the scientific literature;"Data representation; Drug repurposing; Graph embedding; Knowledge representation learning; Machine learning; Parkinson's disease; Scientific literature; Text mining";Purpose: Drug repurposing involves the identification of new applications for existing drugs. Owing to the enormous rise in the costs of pharmaceutical R&D, several pharmaceutical companies are leveraging repurposing strategies. Parkinson's disease is the second most common neurodegenerative disorder worldwide, affecting approximately 1–2 percent of the human population older than 65 years. This study proposes a literature-based drug repurposing strategy in Parkinson's disease. Design/methodology/approach: The literature-based drug repurposing strategy proposed herein combined natural language processing, network science and machine learning methods for analyzing unstructured text data and producing actional knowledge for drug repurposing. The approach comprised multiple computational components, including the extraction of biomedical entities and their relationships, knowledge graph construction, knowledge representation learning and machine learning-based prediction. Findings: The proposed strategy was used to mine information pertaining to the mechanisms of disease treatment from known treatment relationships and predict drugs for repurposing against Parkinson's disease. The F1 score of the best-performing method was 0.97, indicating the effectiveness of the proposed approach. The study also presents experimental results obtained by combining the different components of the strategy. Originality/value: The drug repurposing strategy proposed herein for Parkinson's disease is distinct from those existing in the literature in that the drug repurposing pipeline includes components of natural language processing, knowledge representation and machine learning for analyzing the scientific literature. The results of the study provide important and valuable information to researchers studying different aspects of Parkinson's disease. © 2020, Emerald Publishing Limited.;Scopus;2020;10.1108/lht-08-2019-0170;Zhu Y., Jung W., Wang F., Che C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083987300&doi=10.1108%2fLHT-08-2019-0170&partnerID=40&md5=3be7c9af2eb0fcefaa40d3ca03fec094;China, United States;"entity extraction; relation extraction; semantic search";validation research;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;explainable prediction of medical codes with knowledge graphs;"automated ICD coding; explainable; knowledge graphs; medical records; natural language processing";International Classification of Diseases (ICD) is an authoritative health care classification system of different diseases. It is widely used for disease and health records, assisted medical reimbursement decisions, and collecting morbidity and mortality statistics. The most existing ICD coding models only translate the simple diagnosis descriptions into ICD codes. And it obscures the reasons and details behind specific diagnoses. Besides, the label (code) distribution is uneven. And there is a dependency between labels. Based on the above considerations, the knowledge graph and attention mechanism were expanded into medical code prediction to improve interpretability. In this study, a new method called G_Coder was presented, which mainly consists of Multi-CNN, graph presentation, attentional matching, and adversarial learning. The medical knowledge graph was constructed by extracting entities related to ICD-9 from freebase. Ontology contains 5 entity classes, which are disease, symptom, medicine, surgery, and examination. The result of G_Coder on the MIMIC-III dataset showed that the micro-F1 score is 69.2% surpassing the state of art. The following conclusions can be obtained through the experiment: G_Coder integrates information across medical records using Multi-CNN and embeds knowledge into ICD codes. Adversarial learning is used to generate the adversarial samples to reconcile the writing styles of doctor. With the knowledge graph and attention mechanism, most relevant segments of medical codes can be explained. This suggests that the knowledge graph significantly improves the precision of code prediction and reduces the working pressure of the human coders. © Copyright © 2020 Teng, Yang, Chen, Huang and Xu.;Scopus;2020;10.3389/fbioe.2020.00867;Teng F., Yang W., Chen L., Huang L., Xu Q.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090009909&doi=10.3389%2ffbioe.2020.00867&partnerID=40&md5=787cd8bbbaa7baa2a50c0af6661edfa4;China;text classification;validation research;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;extraction of information related to drug safety surveillance from electronic health record notes: joint modeling of entities and relations using knowledge-aware neural attentive models;"Adverse drug events; Adverse drug reaction reporting systems; Deep learning; Electronic health records; Information extraction; Named entity recognition; Natural language processing; Relation extraction";"Background: An adverse drug event (ADE) is commonly defined as ""an injury resulting from medical intervention related to a drug.""Providing information related to ADEs and alerting caregivers at the point of care can reduce the risk of prescription and diagnostic errors and improve health outcomes. ADEs captured in structured data in electronic health records (EHRs) as either coded problems or allergies are often incomplete, leading to underreporting. Therefore, it is important to develop capabilities to process unstructured EHR data in the form of clinical notes, which contain a richer documentation of a patient's ADE. Several natural language processing (NLP) systems have been proposed to automatically extract information related to ADEs. However, the results from these systems showed that significant improvement is still required for the automatic extraction of ADEs from clinical notes. Objective: This study aims to improve the automatic extraction of ADEs and related information such as drugs, their attributes, and reason for administration from the clinical notes of patients. Methods: This research was conducted using discharge summaries from the Medical Information Mart for Intensive Care III (MIMIC-III) database obtained through the 2018 National NLP Clinical Challenges (n2c2) annotated with drugs, drug attributes (ie, strength, form, frequency, route, dosage, duration), ADEs, reasons, and relations between drugs and other entities. We developed a deep learning-based system for extracting these drug-centric concepts and relations simultaneously using a joint method enhanced with contextualized embeddings, a position-attention mechanism, and knowledge representations. The joint method generated different sentence representations for each drug, which were then used to extract related concepts and relations simultaneously. Contextualized representations trained on the MIMIC-III database were used to capture context-sensitive meanings of words. The position-attention mechanism amplified the benefits of the joint method by generating sentence representations that capture long-distance relations. Knowledge representations were obtained from graph embeddings created using the US Food and Drug Administration Adverse Event Reporting System database to improve relation extraction, especially when contextual clues were insufficient. Results: Our system achieved new state-of-the-art results on the n2c2 data set, with significant improvements in recognizing crucial drug-reason (F1=0.650 versus F1=0.579) and drug-ADE (F1=0.490 versus F1=0.476) relations. Conclusions: This study presents a system for extracting drug-centric concepts and relations that outperformed current state-of-the-art results and shows that contextualized embeddings, position-attention mechanisms, and knowledge graph embeddings effectively improve deep learning-based concepts and relation extraction. This study demonstrates the potential for deep learning-based methods to help extract real-world evidence from unstructured patient data for drug safety surveillance. © 2020 Bharath Dandala, Venkata Joopudi, Ching-Huei Tsou, Jennifer J Liang, Parthasarathy Suryanarayanan.";Scopus;2020;10.2196/18417;Dandala B., Joopudi V., Tsou C.-H., Liang J.J., Suryanarayanan P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097479168&doi=10.2196%2f18417&partnerID=40&md5=7ac69d2befaa5afb0d00b8fe9f2d7120;United States;"entity extraction; relation extraction; knowledge graph embedding";validation research;technique;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;research and implementation of intelligent question answering system based on knowledge graph of traditional chinese medicine;"intelligent question answering; knowledge graph; Knowledge of traditional Chinese medicine; Neo4j";"The combination of knowledge graph and natural language processing technology has become more and more widely used, and it has become one of the areas that major search engine companies attach importance to. Despite the steady progress of scientific and technological innovation and popularization of traditional Chinese medicine(TCM) knowledge, how to visualize and analyze complex TCM information in the field of TCM is still a difficult problem to solve. To this end, this research is based on the field of traditional Chinese medicine, and uses the open source data of the Compendium of ""Materia Medica""on the vertical Chinese medicine website as a data source to build a knowledge graph of Chinese medicine with 9 categories of 7k knowledge entities and 7 relationships. On the basis of this knowledge graph, the functions of automatic question and answer of traditional Chinese medicine knowledge and auxiliary prescriptions have been realized. The realization of this system is of great significance and reference value in enhancing the popularization of Chinese medicine knowledge among the general public and providing decision support for clinical practice, scientific research and teaching of Chinese medicine. © 2020 Technical Committee on Control Theory, Chinese Association of Automation.";IEEE;2020;10.23919/ccc50068.2020.9189518;Zou Y., He Y., Liu Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091401695&doi=10.23919%2fCCC50068.2020.9189518&partnerID=40&md5=0e1dbf8849cbe7a398980d686bf4016e;China, Mongolia;question answering;solution proposal;tool;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;hhh: an online medical chatbot system based on knowledge graph and hierarchical bi-directional attention;"Hierarchial BiLSTM attention model; knowledge graph; medical chatbot.; natural language processing; question answering";This paper proposes a chatbot framework that adopts a hybrid model which consists of a knowledge graph and a text similarity model. Based on this chatbot framework, we build HHH, an online question-and-answer (QA) Healthcare Helper system for answering complex medical questions. HHH maintains a knowledge graph constructed from medical data collected from the Internet. HHH also implements a novel text representation and similarity deep learning model, Hierarchical BiLSTM Attention Model (HBAM), to find the most similar question from a large QA dataset. We compare HBAM with other state-of-the-art language models such as bidirectional encoder representation from transformers (BERT) and Manhattan LSTM Model (MaLSTM). We train and test the models with a subset of the Quora duplicate questions dataset in the medical area. The experimental results show that our model is able to achieve a superior performance than these existing methods. © 2020 ACM.;ACM;2020;10.1145/3373017.3373049;Bao Q., Ni L., Liu J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079865624&doi=10.1145%2f3373017.3373049&partnerID=40&md5=03da275abf6df819631230ddce5ebf38;New Zealand;question answering;validation research;"tool; resource";health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;fle at clef ehealth 2020: text mining and semantic knowledge for automated clinical encoding;"CLEF eHealth; Clinical encoding; Named entity recognition (NER); Semantic knowledge; Text mining";In Healthcare domain, several documents are provided in a narrative way, following textual unstructured formats. This is the case of the discharge summaries, which are clinical texts where physicians describe the conditions of the patients with natural language, making the automated processing of such texts hard and challenging. The objective of the tasks of the 2020 CLEF eHealth for Multilingual Information Extraction is to develop solutions to automatically annotate Spanish clinical texts with codes from the International Classification of Diseases, 10th version (ICD-10). In the present paper, we show our approach which is based on Named Entity Recognition (NER) to detect the diagnoses and procedures, and semantic linking against a Knowledge Graph to extract the ICD-10 codes. Besides, we exploit text augmentation techniques to generate synthetic input samples and we use BERT pre-trained models and architecture to train the NERs. Copyright © 2020 for this paper by its authors.;Scopus;2020;;García-Santa N., Cetina K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113466369&partnerID=40&md5=f2a5e2151f16495bff6c43210d875892;Spain;"entity extraction; entity linking; semantic search";validation research;technique;health;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;towards context-aware knowledge entailment from health conversations;"Knowledge representation; Natural language processing systems; Back-ground knowledge; Contextualized knowledge; Conversational agents; Domain-specific ontologies; Machine learning approaches; NAtural language processing; Reasoning capabilities; Recognizing textual entailments; Learning systems";Despite the competitive efforts of leading companies, cognitive technologies such as chatbot technologies still have limited cognitive capabilities. One of the major challenges that they face is knowledge entailment from the ongoing conversations with a user. Knowledge entailment implies entailing facts that indicate opinions, beliefs, expressions, requests, and feelings of a particular user about a particular target during conversations. The entailed pieces of knowledge will evolve the background knowledge graph of cognitive technologies and advance their contextual inference and reasoning capabilities. Although the Natural Language Processing (NLP) community deals with the Recognizing Textual Entailment (RTE) task, it is treated in a static manner where the predefined hypothesis is typically fed to the learning model, and then the model decides whether it is an entailment or not. However, since the discourse of conversations is dynamic and unpredictable, the traditional RTE approach does not suffice in the context of conversational agents. In this vision paper, we demonstrate our work in progress as to inject background knowledge into machine learning approaches where it entails facts using domain-specific ontologies and contextualized knowledge. Further, we propose investigating solutions for extending or transferring this approach to other domains. We frame our discussion in a case study related to mental health conversations. Copyright © 2020 for this paper by its authors.;Scopus;2020;;Shekarpour S., Alshargi F., Shekarpour M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108841003&partnerID=40&md5=35f7cdc597ce11e21dc1f7e1873df653;Germany, United States;"conversational interfaces; natural language inference";solution proposal;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;bert-mk: integrating graph contextualized knowledge into pre-trained language models;"Computational linguistics; Knowledge representation; Topology; Contextualized knowledge; Knowledge graphs; Knowledge-representation; Language model; Learning methods; Structure of knowledge; Subgraphs; Topological structure; Traditional knowledge; Training unit; Knowledge graph";Complex node interactions are common in knowledge graphs (KGs), and these interactions can be considered as contextualized knowledge exists in the topological structure of KGs. Traditional knowledge representation learning (KRL) methods usually treat a single triple as a training unit, neglecting the usage of graph contextualized knowledge. To utilize these unexploited graph-level knowledge, we propose an approach to model subgraphs in a medical KG. Then, the learned knowledge is integrated with a pre-trained language model to do the knowledge generalization. Experimental results demonstrate that our model achieves the state-of-the-art performance on several medical NLP tasks, and the improvement above MedERNIE indicates that graph contextualized knowledge is beneficial. ©2020 Association for Computational Linguistics;ACL;2020;;He B., Zhou D., Xiao J., Jiang X., Liu Q., Yuan N.J., Xu T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106741988&partnerID=40&md5=6fb832505647133fbe428aaf69cbcd20;China;augmented language models;validation research;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;predictive article recommendation using natural language processing and machine learning to support evidence updates in domain-specific knowledge graphs;"Artificial intelligence; Machine learning; Natural language processing; Precision medicine";"Objectives: Describe an augmented intelligence approach to facilitate the update of evidence for associations in knowledge graphs. Methods: New publications are filtered through multiple machine learning study classifiers, and filtered publications are combined with articles already included as evidence in the knowledge graph. The corpus is then subjected to named entity recognition, semantic dictionary mapping, term vector space modeling, pairwise similarity, and focal entity match to identify highly related publications. Subject matter experts review recommended articles to assess inclusion in the knowledge graph; discrepancies are resolved by consensus. Results: Study classifiers achieved F-scores from 0.88 to 0.94, and similarity thresholds for each study type were determined by experimentation. Our approach reduces human literature review load by 99%, and over the past 12 months, 41% of recommendations were accepted to update the knowledge graph. Conclusion: Integrated search and recommendation exploiting current evidence in a knowledge graph is useful for reducing human cognition load. © The Author(s) 2020.";Scopus;2020;10.1093/jamiaopen/ooaa028;Sharma B., Willis V.C., Huettner C.S., Beaty K., Snowdon J.L., Xue S., South B.R., Jackson G.P., Weeraratne D., Michelini V.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102082317&doi=10.1093%2fJAMIAOPEN%2fOOAA028&partnerID=40&md5=96cd196b2a667e74a01cef611e6ad2c1;United States;semantic search;validation research;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;towards medical machine reading comprehension with structural knowledge and plain text;"Computational linguistics; Diagnosis; Large dataset; Comprehension models; Language model; Large-scales; Medical fields; Medical knowledge; Multi choices; Plain text; Reading comprehension; Structural knowledge; Training data; Knowledge graph";Machine reading comprehension (MRC) has achieved significant progress on the open domain in recent years, mainly due to large-scale pre-trained language models. However, it performs much worse in specific domains such as the medical field due to the lack of extensive training data and professional structural knowledge neglect. As an effort, we first collect a large scale medical multi-choice question dataset (more than 21k instances) for the National Licensed Pharmacist Examination in China. It is a challenging medical examination with a passing rate of less than 14.2% in 2018. Then we propose a novel reading comprehension model KMQA, which can fully exploit the structural medical knowledge (i.e., medical knowledge graph) and the reference medical plain text (i.e., text snippets retrieved from reference books). The experimental results indicate that the KMQA outperforms existing competitive models with a large margin and passes the exam with 61.8% accuracy rate on the test set. © 2020 Association for Computational Linguistics;ACL;2020;;Li D., Hu B., Chen Q., Peng W., Wang A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100236546&partnerID=40&md5=15e2103d03284c26bdf2a9017c3d48a6;China;"question answering; augmented language models";validation research;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;extracting and representing causal knowledge of health conditions;"AI; Causality; Health; Knowledge Graph; NLP";Most healthcare and health research organizations published their health knowledge on the web through HTML or semantic presentations nowadays e.g. UK National Health Service website. Especially, the HTML contents contain valuable information about the individual health condition and graph knowledge presents the semantics of words in the contents. This paper focuses on combining these two for extracting causality knowledge. Understanding causality relations is one of the crucial tasks to support building an Artificial Intelligent (AI) enabled healthcare system. Unlike other raw data sources used by AI processes, the causality semantic dataset is generated in this paper, which is believed to be more efficient and transparent for supporting AI tasks. Currently, neural network-based deep learning processes found themselves in a hard position to explain the prediction outputs, which is majorly because of lacking knowledge-based probability analysis. Dynamic probability analysis based on causality modeling is a new research area that not only can model the knowledge in a machine-understandable way but also can create causal probability relations inside the knowledge. To achieve this, a causal probability generation framework is proposed in this paper that extends the current Description Logic (DL), applies semantic Natural Language Processing (NLP) approach, and calculates runtime causal probabilities according to the given input conditions. The framework can be easily implemented using existing programming standards. The experimental evaluations extract 383 common disease conditions from the UK NHS (the National Health Service) and enable automatically linked 418 condition terms from the DBpedia dataset. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). BIRDS 2020, 30 July 2020, Xi’an, China (online).;Scopus;2020;;Yu H.Q.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098999851&partnerID=40&md5=8d540898a16e5de105e8f73c95b6c834;United Kingdom;"entity extraction; relation extraction; semantic search";solution proposal;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;learning conceptual-contextual embeddings for medical text;"Benchmarking; Encoding (symbols); Knowledge representation; Semantics; Text processing; Context modeling; Electronic health record (EHRs); External knowledge; Medical text processing; Natural language understanding; Structured knowledge; Text representation; Text representation models; Embeddings";External knowledge is often useful for natural language understanding tasks. We introduce a contextual text representation model called Conceptual-Contextual (CC) embeddings, which incorporates structured knowledge into text representations. Unlike entity embedding methods, our approach encodes a knowledge graph into a context model. CC embeddings can be easily reused for a wide range of tasks in a similar fashion to pre-trained language models. Our model effectively encodes the huge UMLS database by leveraging semantic generalizability. Experiments on electronic health records (EHRs) and medical text processing benchmarks showed our model gives a major boost to the performance of supervised medical NLP tasks. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;Scopus;2020;;Zhang X., Dou D., Wu J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097815289&partnerID=40&md5=48c8c9d3dacae571301bcb2a6e15d214;China, United States;augmented language models;validation research;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an auto question answering system for tree hole rescue;"Automatic question answering; Knowledge graph; Natural language processing; Tree Hole Rescue; Word embedding";This paper introduces an automatic question answering system which aimed to provide online how-to instructions for volunteers of Tree Hole Rescue–a Chinese online suicide rescue organization. When a volunteer needs to make sure how to deal with a rescue task professionally, he/she could ask this system via its WeChat public account other than reading a rescue instruction menu book. Firstly, a Tree Hole Rescue question-answer knowledge graph was constructed to manage Tree Hole Rescue question-answer knowledge and its relationship. Then, based on this semantic technology, a question in Chinese natural language was parsed into a machine-readable logical language through the question preprocessing and entity mapping process. And, a candidate question set was generated through a hierarchical information retrieval strategy. Finally, an exact or close answer and recommended similar questions were sent to the asker after calculating words sequence similarity via an algorithm which combined word form and semantic features. If the system could not match an answer for a question, the question would be added to unsolved question list and the system would alert administrator to deal with it. System testing shew that the Q&A system has a high accuracy rate in response of Tree Hole Rescue questions. Meanwhile, this system provides a series of methods to improve the update capability of the Q&A library and the scalability of the system. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-61951-0_2;Wang F., Li Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094138128&doi=10.1007%2f978-3-030-61951-0_2&partnerID=40&md5=aa49e698e3f4afbea1f6d0f1fd5083e6;China;question answering;solution proposal;method;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;question-answering system based on the knowledge graph of traditional chinese medicine;"Chinese medicine; Knowledge Graph; Natural language processing; Question analysis; Question-Answering system";With the development of artificial intelligence, the emergence of the QA system meets the search needs of people in the mass information age. The traditional question-Answering system mostly matches the questions with fixed templates, and the dataset of questions and answers often rely on human-designed features, which is time-consuming and with low accuracy. To address this dilemma, the current prevailing technology of Knowledge Graph provides a new way, helping to build a domain-specific intelligent question answering system. In this paper, we combine the Knowledge Graph with the question and answer system to analyze the relationship of diseases, prescriptions, and Chinese herbal medicines, and finally implement a smart question answering system for the Traditional Chinese Medicine. © 2019 IEEE.;IEEE;2019;10.1109/ihmsc.2019.10156;Miao F., Wang X., Zhang P., Jin L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078299443&doi=10.1109%2fIHMSC.2019.10156&partnerID=40&md5=024366ba65e4442e6b9d76545a6577e6;China;question answering;solution proposal;tool;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;multi-modal question answering system driven by domain knowledge graph;"big data; domain knowledge graph; knowledge engineering; multimodal combination; question-answering system";In the era of big data explosion, the Internet serving as an infrastructure for organizing and acquiring information and knowledge, has usability shortcomings in specific application scenarios. For professional application business, we need more efficient information organization and interactive interface to facilitate the formalization of expert experience and access to associated information by ordinary users. This paper designs a domain knowledge graph driven multi-modal question answering system, using knowledge graph as foundation framework for domain data, combined with intelligent question answering and image recognition technology, achieve efficient information query scheme. In the process of establishing the domain knowledge graph, we adopt the method of combining intelligent natural language processing with crowdsourcing artificial entity-relational extraction, which can effectively solve the problem of knowledge engineering in professional fields. © 2019 IEEE.;IEEE;2019;10.1109/bigcom.2019.00015;Zhao Z., Wang X., Xu X., Wang Q.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076108008&doi=10.1109%2fBIGCOM.2019.00015&partnerID=40&md5=35845999fecb21d86972e0156ad230bb;China;question answering;solution proposal;tool;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;long distance entity relation extraction with article structure embedding and applied to mining medical knowledge;"Article structured embedding; Medical knowledge graph; Neural network; Relation extraction";As a central work in medical knowledge graph construction, relation extraction has gained extensive attention in the fields of natural language processing and artificial intelligence. Conventional works on relation extraction share a common assumption: a sentence can express a relation of an entity pair only if both entities appear in this sentence. Under this assumption, plenty of informative sentences are precluded. In this paper, we break the assumption and propose a new relation extraction model that incorporates article structure information, which not only provide additional information, but also allows extracting long distance relations. We apply the model to online medical relation extraction and demonstrate its advantage over conventional models. © 2019 IEEE.;IEEE;2019;10.1109/ichi.2019.8904821;Lin Y., Ma C., Gaoz D., Fan Z., Cheng Z., Wang Z., Yu S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075919573&doi=10.1109%2fICHI.2019.8904821&partnerID=40&md5=2a1ff2bd2c943e17ef93413411419614;China, United States;relation extraction;validation research;technique;health;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;conceptualisation and annotation of drug nonadherence information for knowledge extraction from patient-generated texts;"Computational linguistics; Data mining; Extraction; Natural language processing systems; Annotation scheme; Drug effects; Extraction systems; Knowledge extraction; Named entities; Noun phrase; Scale-up; Systems trainings; Train systems; User-generated; Knowledge graph";Approaches to knowledge extraction (KE) in the health domain often start by annotating text to indicate the knowledge to be extracted, and then use the annotated text to train systems to perform the KE. This may work for annotating named entities or other contiguous noun phrases (drugs, some drug effects), but becomes increasingly difficult when items tend to be expressed across multiple, possibly noncontiguous, syntactic constituents (e.g. most descriptions of drug effects in user-generated text). Other issues include that it is not always clear how annotations map to actionable insights, or how they scale up to, or can form part of, more complex KE tasks. This paper reports our efforts in developing an approach to extracting knowledge about drug nonadherence from health forums which led us to conclude that development cannot proceed in separate steps but that all aspects-from conceptualisation to annotation scheme development, annotation, KE system training and knowledge graph instantiation-are interdependent and need to be co-developed. Our aim in this paper is two-fold: we describe a generally applicable framework for developing a KE approach, and present a specific KE approach, developed with the framework, for the task of gathering information about antidepressant drug nonadherence. We report the conceptualisation, the annotation scheme, the annotated corpus, and an analysis of annotated texts. © 2019 Association for Computational Linguistics;ACL;2019;;Belz A., Ford E., Hoile R., Mullick A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107398817&partnerID=40&md5=607c7acfe33177c692ad5260b7f342a6;United Kingdom;"entity extraction; relation extraction";solution proposal;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;named entity recognition in traditional chinese medicine clinical cases combining bilstm-crf with knowledge graph;"Knowledge graph; Named entity recognition; Traditional Chinese Medicine";Named entity recognition in Traditional Chinese Medicine (TCM) clinical cases is a fundamental and crucial task for follow-up work. In recent years, deep learning approaches have achieved remarkable results in named entity recognition and other natural language processing tasks. However, these methods cannot effectively solve the problem of low recognition rate of rare words, which is common in TCM field. In this paper, we propose TCMKG-LSTM-CRF model that utilizes knowledge graph information to strength the learning ability and recognize rare words. This model introduces knowledge attention vector model to implement attention mechanism between hidden vector of neural networks and knowledge graph candidate vectors and consider influence from previous word. The experiment results prove the effectiveness of our model. © Springer Nature Switzerland AG 2019.;Scopus;2019;10.1007/978-3-030-29551-6_48;Jin Z., Zhang Y., Kuang H., Yao L., Zhang W., Pan Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081618149&doi=10.1007%2f978-3-030-29551-6_48&partnerID=40&md5=bd7a0b9b206d53f25998ca9ffb7f9554;China, United States;"entity extraction; augmented language models";validation research;technique;health;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;graphical induction of qualified medical knowledge;"Bioinformatics; electronic medical record; information retrieval; knowledge extraction";The introduction of electronic medical records (EMRs) enabled the access of unprecedented volumes of clinical data, both in structured and unstructured formats. A significant amount of this clinical data is expressed within the narrative portion of the EMRs, requiring natural language processing techniques to unlock the medical knowledge referred to by physicians. This knowledge, derived from the practice of medical care, complements medical knowledge already encoded in various structured biomedical ontologies. Moreover, the clinical knowledge derived from EMRs also exhibits relational information between medical concepts, derived from the cohesion property of clinical text, which is an attractive attribute that is currently missing from the vast biomedical knowledge bases. In this paper, we describe an automatic method of generating a graph of clinically related medical concepts by considering the belief values associated with those concepts. The belief value is an expression of the clinician's assertion that the concept is qualified as present, absent, suggested, hypothetical, ongoing, etc. Because the method detailed in this paper takes into account the hedging used by physicians when authoring EMRs, the resulting graph encodes qualified medical knowledge wherein each medical concept has an associated assertion (or belief value) and such qualified medical concepts are spanned by relations of different strengths, derived from the clinical contexts in which concepts are used. In this paper, we discuss the construction of a qualified medical knowledge graph (QMKG) and treat it as a BigData problem addressed by using MapReduce for deriving the weighted edges of the graph. To be able to assess the value of the QMKG, we demonstrate its usage for retrieving patient cohorts by enabling query expansion that produces greatly enhanced results against state-of-the-art methods. © 2013 World Scientific Publishing Company.;Scopus;2013;10.1142/s1793351x13400126;Goodwin T., Harabagiu S.M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996542297&doi=10.1142%2fS1793351X13400126&partnerID=40&md5=999debbd9d84ce8c577974dd6da9284e;United States;"entity extraction; relation extraction";solution proposal;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;bert based clinical knowledge extraction for biomedical knowledge graph construction and analysis;Knowledge graph, Biomedical informatics, Clinical data, Natural language processing, BERT;Background: Knowledge is evolving over time, often as a result of new discoveries or changes in the adopted methods of reasoning. Also, new facts or evidence may become available, leading to new understandings of complex phenomena. This is particularly true in the biomedical field, where scientists and physicians are constantly striving to find new methods of diagnosis, treatment and eventually cure. Knowledge Graphs (KGs) offer a real way of organizing and retrieving the massive and growing amount of biomedical knowledge. Objective: We propose an end-to-end approach for knowledge extraction and analysis from biomedical clinical notes using the Bidirectional Encoder Representations from Transformers (BERT) model and Conditional Random Field (CRF) layer. Methods: The approach is based on knowledge graphs, which can effectively process abstract biomedical concepts such as relationships and interactions between medical entities. Besides offering an intuitive way to visualize these concepts, KGs can solve more complex knowledge retrieval problems by simplifying them into simpler representations or by transforming the problems into representations from different perspectives. We created a biomedical Knowledge Graph using using Natural Language Processing models for named entity recognition and relation extraction. The generated biomedical knowledge graphs (KGs) are then used for question answering. Results: The proposed framework can successfully extract relevant structured information with high accuracy (90.7% for Named-entity recognition (NER), 88% for relation extraction (RE)), according to experimental findings based on real-world 505 patient biomedical unstructured clinical notes. Conclusions:In this paper, we propose a novel end-to-end system for the construction of a biomedical knowledge graph from clinical textual using a variation of BERT models.;ScienceDirect;2021;10.1016/j.cmpbup.2021.100042;Ayoub Harnoune and Maryem Rhanoui and Mounia Mikram and Siham Yousfi and Zineb Elkaimbillah and Bouchra {El Asri};https://www.sciencedirect.com/science/article/pii/S2666990021000410;Morocco;"entity extraction; relation extraction; question answering";solution proposal;method;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;constructing knowledge graphs and their biomedical applications;knowledge graphs, Network embeddings, Text mining, Natural language processing, Machine learning, Lterature review;Knowledge graphs can support many biomedical applications. These graphs represent biomedical concepts and relationships in the form of nodes and edges. In this review, we discuss how these graphs are constructed and applied with a particular focus on how machine learning approaches are changing these processes. Biomedical knowledge graphs have often been constructed by integrating databases that were populated by experts via manual curation, but we are now seeing a more robust use of automated systems. A number of techniques are used to represent knowledge graphs, but often machine learning methods are used to construct a low-dimensional representation that can support many different applications. This representation is designed to preserve a knowledge graph’s local and/or global structure. Additional machine learning methods can be applied to this representation to make predictions within genomic, pharmaceutical, and clinical domains. We frame our discussion first around knowledge graph construction and then around unifying representational learning techniques and unifying applications. Advances in machine learning for biomedicine are creating new opportunities across many domains, and we note potential avenues for future work with knowledge graphs that appear particularly promising.;ScienceDirect;2020;10.1016/j.csbj.2020.05.017;David N. Nicholson and Casey S. Greene;https://www.sciencedirect.com/science/article/pii/S2001037020302804;United States;"relation extraction; semantic search";secondary research;guidelines;health;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;knowledge graphs for covid-19: an exploratory review of the current landscape;"COVID-19; knowledge graph; natural language processing; drug repurposing";Background: Searching through the COVID-19 research literature to gain actionable clinical insight is a formidable task, even for experts. The usefulness of this corpus in terms of improving patient care is tied to the ability to see the big picture that emerges when the studies are seen in conjunction rather than in isolation. When the answer to a search query requires linking together multiple pieces of information across documents, simple keyword searches are insufficient. To answer such complex information needs, an innovative artificial intelligence (AI) technology named a knowledge graph (KG) could prove to be effective. Methods: We conducted an exploratory literature review of KG applications in the context of COVID-19. The search term used was ``covid-19 knowledge graph''. In addition to PubMed, the first five pages of search results for Google Scholar and Google were considered for inclusion. Google Scholar was used to include non-peer-reviewed or non-indexed articles such as pre-prints and conference proceedings. Google was used to identify companies or consortiums active in this domain that have not published any literature, peer-reviewed or otherwise. Results: Our search yielded 34 results on PubMed and 50 results each on Google and Google Scholar. We found KGs being used for facilitating literature search, drug repurposing, clinical trial mapping, and risk factor analysis. Conclusions: Our synopses of these works make a compelling case for the utility of this nascent field of research.;WoS;2021;10.3390/jpm11040300;Chatterjee A,Nardi C,Oberije C,Lambin P;http://dx.doi.org/10.3390/jpm11040300;Italy, Netherlands;semantic search;secondary research;guidelines;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;qanalysis: a question-answer driven analytic tool on knowledge graphs for leveraging electronic medical records for clinical research;"Electronic medical record; Statistical question answering; Graph database; Context-free grammar";BackgroundWhile doctors should analyze a large amount of electronic medical record (EMR) data to conduct clinical research, the analyzing process requires information technology (IT) skills, which is difficult for most doctors in China.MethodsIn this paper, we build a novel tool QAnalysis, where doctors enter their analytic requirements in their natural language and then the tool returns charts and tables to the doctors. For a given question from a user, we first segment the sentence, and then we use grammar parser to analyze the structure of the sentence. After linking the segmentations to concepts and predicates in knowledge graphs, we convert the question into a set of triples connected with different kinds of operators. These triples are converted to queries in Cypher, the query language for Neo4j. Finally, the query is executed on Neo4j, and the results shown in terms of tables and charts are returned to the user.ResultsThe tool supports top 50 questions we gathered from two hospital departments with the Delphi method. We also gathered 161 questions from clinical research papers with statistical requirements on EMR data. Experimental results show that our tool can directly cover 78.20% of these statistical questions and the precision is as high as 96.36%. Such extension is easy to achieve with the help of knowledge-graph technology we have adopted. The recorded demo can be accessed from https://github.com/NLP-BigDataLab/QAnalysis-project.ConclusionOur tool shows great flexibility in processing different kinds of statistic questions, which provides a convenient way for doctors to get statistical results directly in natural language.;WoS;2019;10.1186/s12911-019-0798-8;Ruan T,Huang Y,Liu X,Xia Y,Gao J;http://dx.doi.org/10.1186/s12911-019-0798-8;China;question answering;solution proposal;tool;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;construction of diabetes knowledge graph based on deep learning;"named entity recognition;relation extraction;knowledge extraction";To integrate medical data which is scattered over the internet, natural language processing (NLP) is widely used in medical text mining. BERT (Bidirectional Encoder Representations from Transformers) is outstanding among many other representation models and vector representation based on Bert pre-training language model can help the target task learn more semantic information. The knowledge graph intuitively reveals the relationship between entities and helps explore deeper semantic connections between entities. There are three important parts in the construction of a knowledge graph, including entity extraction, relation extraction, and graph generation. Based on these methods this paper proposes a Bert-based named entities identification model Bert-BiLSTM-CRF and it is outperforming the established methods. In the relation extraction part, use the BERT-Softmax to improve the semantic expression and its F1-value increased by 12 percent compared with the traditional entity relation extraction model. Based on the above redefined the entities of diabetes and their relationships to enrich the semantics of the knowledge graph. Finally, the Neo4j graph database was used to realize the visualization of the diabetes knowledge map.;IEEE;2021;10.1109/icnisc54316.2021.00181;"Y. Lu; R. Zhao; S. Huang; R. Liu";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9603816;China;"entity extraction; relation extraction";validation research;tool;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;entity pair recognition using semantic enrichment and adversarial training for chinese drug knowledge extraction;medical field, knowledge induction, subclass and hyponym, entity pair verification;"Existing knowledge extraction methods in pharmacy often use natural language processing tools and deep learning model to identify drug entities and extract their relationships from drug instructions, thus obtaining drug-drug or drug-disease knowledge. However, sentences in drug instructions may contain multiple drug-related entities, and existing methods lack the capability of identifying valid the ""drug-drug"" or ""drug-disease"" entity pairs. This will introduce significant noise data in the subsequent tasks such as entity relationship extraction and knowledge graph construction. Meanwhile, some mentions in the sentence can have hierarchical relations even if they do not form valid entity pairs, such information is also crucial to knowledge extraction. To solve these two problems, this paper proposes an entity pair verification model based on entity semantic enhancement and adversarial training. Through the experiment on more than 2000 kinds of drug instructions data, the experimental results show that the F1 value of the model for entity pair verification is up to 98.65%, which is up to 9.37% compared with the existing methods.";ACM;2021;10.1145/3500931.3500939;Gao, Feng and Zhou, LunSheng and Gu, JinGuang;https://doi.org/10.1145/3500931.3500939;China;"entity extraction; relation extraction";validation research;technique;health;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;semantics of the black-box: can knowledge graphs help make deep learning systems more interpretable and explainable;"Human computer interaction; Knowledge representation; Learning systems; Natural language processing systems; Semantics; Domain knowledge; Human understanding; Interpretability; Knowledge graphs; Massive computing; NAtural language processing; Natural language processing applications; Technology domain; Deep learning";The recent series of innovations in deep learning (DL) have shown enormous potential to impact individuals and society, both positively and negatively. DL models utilizing massive computing power and enormous datasets have significantly outperformed prior historical benchmarks on increasingly difficult, well-defined research tasks across technology domains such as computer vision, natural language processing, and human-computer interactions. However, DL's black-box nature and over-reliance on massive amounts of data condensed into labels and dense representations pose challenges for interpretability and explainability. Furthermore, DLs have not proven their ability to effectively utilize relevant domain knowledge critical to human understanding. This aspect was missing in early data-focused approaches and necessitated knowledge-infused learning (K-iL) to incorporate computational knowledge. This article demonstrates how knowledge, provided as a knowledge graph, is incorporated into DL using K-iL. Through examples from natural language processing applications in healthcare and education, we discuss the utility of K-iL towards interpretability and explainability. © 1997-2012 IEEE.;Scopus;2021;10.1109/mic.2020.3031769;Gaur M., Faldu K., Sheth A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101733555&doi=10.1109%2fMIC.2020.3031769&partnerID=40&md5=535818e762aeda69838f8430acb1e30c;India, United States;"semantic search; text summarization";solution proposal;"method; guidelines";"health; education";0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a novel word similarity measure method for iot-enabled healthcare applications;"Entropy; Healthcare; Internet of Things; Knowledge graph; Word embedding; Word similarity";"With the development of the Internet of Things (IoT), Natural Language Processing(NLP) has become a key part of IoT applications in Healthcare. NLP is bringing a revolutionary shift to Healthcare, powered by rapid progress of NLP analytics techniques and increasing availability of Healthcare data. Therefore, using NLP solution for IoT enable Healthcare application is an urgent and valuable task. Word similarity measurement is the basis of semantic analysis, which can be applied to translation and disambiguation of medical terms, prescription analysis, medical question and answer systems, diagnostic assistance, etc. Previous similarity measures have mainly focused on either knowledge-graph-based or word-embedding-based methods, which suffer from two problems: (1) word-embedding-based methods have difficulty discriminating words with approximately the same surrounding context; and (2) knowledge-graph-based methods do not contain multiexpression words or named entities and cannot generally converge for large-scale and updated words. To solve these two problems, this paper proposes a novel method that combines knowledge-graph-based and word-embedding-based similarity measures via word entropy. An experiment is conducted on five public datasets (R&G, M&C, WS353, WS353-Sim and SimLex). The experimental results show that the proposed method achieves significant improvements over other word similarity measures in terms of the correlation coefficient. © 2020 Elsevier B.V.";ScienceDirect;2021;10.1016/j.future.2020.07.053;Zhang D., Xia X., Yang Y., Yang P., Xie C., Cui M., Liu Q.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089150154&doi=10.1016%2fj.future.2020.07.053&partnerID=40&md5=6e6e20d1bab7c15958801aa8a4b7329d;China, United Kingdom;semantic similarity;validation research;technique;"health; information technology";0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Journal Article;mining the sociome for health informatics: analysis of therapeutic lifestyle adherence of diabetic patients in twitter;Sociome, Community detection, Topic modelling, Knowledge graphs, Diabetes, Twitter;In recent years, the number of active users in social media has grown exponentially. Despite the thematic diversity of the messages, social media have become an important vehicle to disseminate health information as well as to gather insights about patients’ experiences and emotional intelligence. Therefore, the present work proposes a new methodology of analysis to identify and interpret the behaviour, perceptions and appreciations of patients and close relatives towards a health condition through their social interactions. At the core of this methodology are techniques of natural language processing and machine learning as well as the reconstruction of knowledge graphs, and further graph mining. The case study is the diabetes community, and more specifically, the patients communicating about type 1 diabetes (T1D) and type 2 diabetes (T2D). The results produced in this study show the effectiveness of the proposed method to discover useful and non-trivial knowledge about patient perceptions of disease. Such knowledge may be used in the context of Health Informatics to promote healthy lifestyles in more efficient ways as well as to improve communication with the patients.;ScienceDirect;2020;10.1016/j.future.2020.04.025;Gael Pérez-Rodríguez and Martín Pérez-Pérez and Florentino Fdez-Riverola and Anália Lourenço;https://www.sciencedirect.com/science/article/pii/S0167739X19329516;Spain, Portugal;"entity extraction; relation extraction";solution proposal;method;"health; social media";1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1
Journal Article;mining temporal evolution of knowledge graphs and genealogical features for literature-based discovery prediction;"Dynamic Supervised Link Prediction; Genealogical Community; Keyword Co-occurrence Network (KCN); Literature-based Knowledge Discovery; Weighted Temporal Citation";Literature-based discovery process identifies the important but implicit relations among information embedded in published literature. Existing techniques from Information Retrieval (IR) and Natural Language Processing (NLP) attempt to identify the hidden or unpublished connections between information concepts within published literature, however, these techniques overlooked the concept of predicting the future and emerging relations among scientific knowledge components such as author selected keywords encapsulated within the literature. Keyword Co-occurrence Network (KCN), built upon author selected keywords, is considered as a knowledge graph that focuses both on these knowledge components and knowledge structure of a scientific domain by examining the relationships between knowledge entities. Using data from two multidisciplinary research domains other than the bio-medical domain, and capitalizing on bibliometrics, the dynamicity of temporal KCNs, and a recurrent neural network, this study develops some novel features supportive for the prediction of the future literature-based discoveries - the emerging connections (co-appearances in the same article) among keywords. Temporal importance extracted from both bipartite and unipartite networks, communities defined by genealogical relations, and the relative importance of temporal citation counts were used in the feature construction process. Both node and edge-level features were input into a recurrent neural network to forecast the feature values and predict the future relations between different scientific concepts/topics represented by the author selected keywords. High performance rates, compared both against contemporary heterogeneous network-based method and preferential attachment process, suggest that these features complement both the prediction of future literature-based discoveries and emerging trend analysis. © 2020 Elsevier Ltd.;ScienceDirect;2020;10.1016/j.joi.2020.101057;Choudhury N., Faisal F., Khushi M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092253994&doi=10.1016%2fj.joi.2020.101057&partnerID=40&md5=3640be71a2e6570f1b3911b7c3b3f288;Australia, United States;"link prediction; semantic search";validation research;method;history;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;digitalhistorian: search & analytics using annotations;"Natural language processing systems; Query processing; Semantics; Digital Documents; Digital humanities; Document collection; Knowledge graphs; Retrieval systems; Semantic annotations; State-of-the-art methods; Temporal expressions; Information retrieval";Born-digital document collections contain vast amounts of historical facts and knowledge. However, manual assessment of these large text collections is infeasible. In this paper, we demonstrate a retrieval system, DIGITALHISTORIAN, that analyzes these document collections using semantic annotations in the form of temporal expressions and named entities linked to a knowledge graph. For queries about entities or events DIGITALHISTORIAN utilizes state-of-the-art methods to understand and analyze temporal expressions in the content of documents. It understands uncertainty in temporal expressions and uses them to mine interesting time intervals for keyword queries. These time intervals are further used for re-ranking and diversifying documents, so that the ranked list of documents portray a historic overview of the query. Further, to contextualize the interesting time intervals, we use frequently occurring named entities and display them in informative visualizations. DIGITALHISTORIAN is designed to help scholars in digital humanities explore large document collections quickly without having any prior knowledge about interesting time intervals or entities for given keyword query. © 2016, CEUR-WS. All rights reserved.;Scopus;2016;;Gupta D., Strötgen J., Berberich K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983549712&partnerID=40&md5=112e2ab2179c04eb72e69d05d0bc724f;Germany;semantic search;solution proposal;tool;history;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;oekg: the open event knowledge graph;"Natural language processing systems; Open Data; Global impacts; Knowledge graphs; Multiple applications; Named entity recognition; News articles; Olympic games; Question Answering; Temporal knowledge; Knowledge representation";Accessing and understanding contemporary and historical events of global impact such as the US elections and the Olympic Games is a major prerequisite for cross-lingual event analytics that investigate event causes, perception and consequences across country borders. In this paper, we present the Open Event Knowledge Graph (OEKG), a multilingual, event-centric, temporal knowledge graph composed of seven different data sets from multiple application domains, including question answering, entity recommendation and named entity recognition. These data sets are all integrated through an easy-to-use and robust pipeline and by linking to the event-centric knowledge graph EventKG. We describe their common schema and demonstrate the use of the OEKG at the example of three use cases: type-specific image retrieval, hybrid question answering over knowledge graphs and news articles, as well as language-specific event recommendation. The OEKG and its query endpoint are publicly available. © 2021 for this paper by its authors. Use permitted under Creative;Scopus;2021;;Gottschalk S., Kacupaj E., Abdollahi S., Alves D., Amaral G., Koutsiana E., Kuculo T., Major D., Mello C., Cheema G.S., Sittar A., Swati, Tahmasebzadeh G., Thakkar G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103195785&partnerID=40&md5=8be5bde6108e7924dc9d07a2b49d21cd;Germany, United Kingdom, Croatia, Slovenia;"semantic search; question answering";solution proposal;resource;history;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;1
Conference Paper;a system for automated open-source threat intelligence gathering and management;"security knowledge graph; threat intelligence";To remain aware of the fast-evolving cyber threat landscape, open-source Cyber Threat Intelligence (OSCTI) has received growing attention from the community. Commonly, knowledge about threats is presented in a vast number of OSCTI reports. Despite the pressing need for high-quality OSCTI, existing OSCTI gathering and management platforms, however, have primarily focused on isolated, low-level Indicators of Compromise. On the other hand, higher-level concepts (e.g., adversary tactics, techniques, and procedures) and their relationships have been overlooked, which contain essential knowledge about threat behaviors that is critical to uncovering the complete threat scenario. To bridge the gap, we propose SecurityKG, a system for automated OSCTI gathering and management. SecurityKG collects OSCTI reports from various sources, uses a combination of AI and NLP techniques to extract high-fidelity knowledge about threat behaviors, and constructs a security knowledge graph. SecurityKG also provides a UI that supports various types of interactivity to facilitate knowledge graph exploration. © 2021 Owner/Author.;Scopus;2021;10.1145/3448016.3452745;Gao P., Liu X., Choi E., Soman B., Mishra C., Farris K., Song D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103051870&doi=10.1145%2f3448016.3452745&partnerID=40&md5=484b8c41fda8f0b37d0685d96c20feaf;United States;"entity extraction; relation extraction; entity linking; semantic search";solution proposal;tool;information technology;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;combining knowledge graph embedding and network embedding for detecting similar mobile applications;"Iterative methods; Knowledge representation; Metadata; Mobile computing; Natural language processing systems; Security of data; Semantics; Embedding method; Embedding strategies; Knowledge graphs; Lightweight ontology; Mobile applications; Network embedding; Semantic representation; Unstructured texts; Embeddings";With the popularity of mobile devices, large amounts of mobile applications (a.k.a.“app”) have been developed and published. Detecting similar apps from a large pool of apps is a fundamental and important task because it has many benefits for various purposes. There exist several works that try to combine different metadata of apps for measuring the similarity between apps. However, few of them pay attention to the roles of this service. Besides, existing methods do not distinguish the characters of contents in the metadata. Therefore, it is hard to obtain accurate semantic representations of apps and capture their fine-grained correlations. In this paper, we propose a novel framework by knowledge graph (KG) techniques and a hybrid embedding strategy to fill above gaps. For the construction of KG, we design a lightweight ontology tailored for the service of cybersecurity analysts. Benefited from a defined schema, more linkages can be shared among apps. To detect similar apps, we divide the relations in KG into structured and unstructured ones according to their related content. Then, TextRank algorithm is employed to extract important tokens from unstructured texts and transform them into structured triples. In this way, the representations of apps in our framework can be iteratively learned by combining KG embedding methods and network embedding models for improving the performance of similar apps detection. Preliminary results indicate the effectiveness of our method comparing to existing models in terms of reciprocal ranking and minimum ranking. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-60450-9_21;Li W., Zhang B., Xu L., Wang M., Luo A., Niu Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093101846&doi=10.1007%2f978-3-030-60450-9_21&partnerID=40&md5=d5671a86298ad1ac1128a9f544edc26e;China;"knowledge graph embedding; semantic search";validation research;method;information technology;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;automatic analysis and reasoning based on vulnerability knowledge graph;"Cybersecurity; Knowledge extraction; Knowledge graph; Knowledge graph reasoning; Vulnerability";In the security community, it is valuable to extract and store the vulnerability knowledge. Many data sources record vulnerability in unstructured data and semi-structured data which are hard for machine-understanding and reuse. Security expert need to analyze the description, link to related knowledge and reason out the hidden connection among various weakness. It is necessary to analyze the vulnerability data automatically and manage knowledge in a more intelligent method. In this paper, we propose a model for automatic analysis and reasoning based on the vulnerability knowledge graph. The vulnerability knowledge graph is extracted from several widely used vulnerability databases and stored in the graph database. Natural language processing technique is used to process and analyze the latest vulnerability description. The extracted entity will be linked to the vulnerability knowledge graph and added as new knowledge. Reasoning function can find hidden relationships among weaknesses based on the knowledge graph. Finally, we present sample cases to demonstrate the practical usage of the model. © 2019, Springer Nature Singapore Pte Ltd.;Scopus;2019;10.1007/978-981-15-1922-2_1;Qin S., Chow K.P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076971573&doi=10.1007%2f978-981-15-1922-2_1&partnerID=40&md5=6ee331224995e0d86a8fc1742a6131cc;Hong Kong;"entity extraction; entity linking";solution proposal;"method; resource";information technology;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;constructing micro knowledge graphs from technical support documents;"Natural language processing systems; Search engines; Websites; Chatbots; Graph search; Key actions; Key entity; Knowledge graphs; Knowledge sources; Large corpora; Question answering systems; Technical support; Web-page; Knowledge graph";Short technical support pages such as IBM Technotes are quite common in technical support domain. These pages can be very useful as the knowledge sources for technical support applications such as chatbots, search engines and question-answering (QA) systems. Information extracted from documents to drive technical support applications is often stored in the form of Knowledge Graph (KG). Building KGs from a large corpus of documents poses a challenge of granularity because a large number of entities and actions are present in each page. The KG becomes virtually unusable if all entities and actions from these pages are stored in the KG. Therefore, only key entities and actions from each page are extracted and stored in the KG. This approach however leads to loss of knowledge represented by entities and actions left out of the KG as they are no longer available to graph search and reasoning functions. We propose a set of techniques to create micro knowledge graph (micrograph) for each of such web pages. The micrograph stores all the entities and actions in a page and also takes advantage of the structure of the page to represent exactly in which part of that page these entities and actions appeared, and also how they relate to each other. These micrographs can be used as additional knowledge sources by technical support applications. We define schemas for representing semi-structured and plain text knowledge present in the technical support web pages. Solutions in technical support domain include procedures made of steps. We also propose a technique to extract procedures from these webpages and the schemas to represent them in the micrographs. We also discuss how technical support applications can take advantage of the micrographs. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-80418-3_37;Kumar A., Gupta N., Dana S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115852519&doi=10.1007%2f978-3-030-80418-3_37&partnerID=40&md5=071e55856bb7c1c89e6a838bad66b920;India;"entity extraction; relation extraction; entity linking";solution proposal;method;information technology;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a3id: an automatic and interpretable implicit interference detection method for smart home via knowledge graph;"Interference detection; knowledge graph; natural language processing (NLP); smart home";The smart home brings together devices, the cloud, data, and people to make home living more comfortable and safer. Trigger-action programming enables users to connect smart devices using if-this-then-that (IFTTT)-style rules. With the increasing number of devices in smart home systems, multiple running rules that act on actuators in contradictory ways may cause unexpected and unpredictable interference problems, which can put residents and their belongings at risk. Previous studies have considered explicit interference problems related to multiple rules targeting a single actuator, whereas implicit interference (interference across different actuators) detection is still challenging and not yet well studied owing to the effort-intensive and time-consuming annotation work of obtaining device information. The lack of knowledge about devices is a critical reason that affects the accuracy and efficiency in implicit interference detection. In this article, we propose A3ID, an automatic detection method for implicit interference based on knowledge graphs. Using natural language processing (NLP) techniques and a lexical database, A3ID can extract knowledge of devices from a knowledge graph, including functionality, effect, and scope. Then, it analyzes and detects interferences among the different devices semantically in three steps, without human intervention. Furthermore, it provides user-friendly explanations in a well-designed structure to specify possible reasons for the implicit interference problems. Our experiment on 11 859 IFTTT-style rules shows that A3ID outperforms state-of-the-art methods by more than 33% in the F1-score for the detection of implicit interference. Moreover, evaluations on an extended data set for devices from ConceptNet (a knowledge graph) and five smart home systems suggest that A3ID also has favorable performance with other devices not limited to the smart home domain. © 2014 IEEE.;IEEE;2020;10.1109/jiot.2019.2959063;Xiao D., Wang Q., Cai M., Zhu Z., Zhao W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082106635&doi=10.1109%2fJIOT.2019.2959063&partnerID=40&md5=494b3ef4dfee8edbbda1c1e426044f56;China;"entity extraction; relation extraction; semantic search";validation research;method;information technology;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an efficient application searching approach based on user review knowledge graph;"App searching; Knowledge-graph; NLP";Finding a software application that perfectly suits user needs is essential for improving user experiences, as well as contributing to the development of the application ecosystems. However, it is not an easy task regarding the huge number of existing applications that are available for use. In this paper, we propose to tackle this challenge by exploring valuable information from user reviews. In particular, we design a user review knowledge graph that consists of both functional information and user preferences in order to comprehensively and precisely characterize software applications. Based on such a review knowledge graph, our approach can support application search in an efficient and precise manner. To evaluate our proposal, we have collected a total of 4,370 applications and 4,396,950 pieces of reviews for constructing a comprehensive review knowledge graph and have illustrated how users and developers can efficiently retrieve applications and improve software functionality based on the knowledge graph. © 2020 Knowledge Systems Institute Graduate School. All rights reserved.;Scopus;2020;10.18293/seke2020-119;Li F., Li T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090507011&doi=10.18293%2fSEKE2020-119&partnerID=40&md5=a075aa04e9bd01e670516ea4cb6c9382;China;"entity extraction; relation extraction; semantic search";validation research;method;information technology;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;patentminer: patent vacancy mining via context-enhanced and knowledge-guided graph attention;"Co-occurrence relationship; Graph attention networks; Knowledge graph; Link prediction";"Although there are a small number of work to conduct patent research by building knowledge graph, but without constructing patent knowledge graph using patent documents and combining latest natural language processing methods to mine hidden rich semantic relationships in existing patents and predict new possible patents. In this paper, we propose a new patent vacancy prediction approach named PatentMiner to mine rich semantic knowledge and predict new potential patents based on knowledge graph (KG) and graph attention mechanism. Firstly, patent knowledge graph over time (e.g. year) is constructed by carrying out named entity recognition and relation extraction from patent documents. Secondly, Common Neighbor Method (CNM), Graph Attention Networks (GAT) and Context-enhanced Graph Attention Networks (CGAT) are proposed to perform link prediction in the constructed knowledge graph to dig out the potential triples. Finally, patents are defined on the knowledge graph by means of co-occurrence relationship, that is, each patent is represented as a fully connected subgraph containing all its entities and co-occurrence relationships of the patent in the knowledge graph; Furthermore, we propose a new patent prediction task which predicts a fully connected subgraph with newly added prediction links as a new patent. The experimental results demonstrate that our proposed patent prediction approach can correctly predict new patents and Context-enhanced Graph Attention Networks is much better than the baseline. © 2021, Springer Nature Singapore Pte Ltd.";Scopus;2021;10.1007/978-981-16-6471-7_17;Wu G., Xu B., Qin Y., Kong F., Liu B., Zhao H., Chang D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119408902&doi=10.1007%2f978-981-16-6471-7_17&partnerID=40&md5=fb6bef277f8f9069b3f3016dce0fce59;China;"entity extraction; relation extraction; link prediction";solution proposal;method;law;1;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;leveraging online behaviors for interpretable knowledge-aware patent recommendation;"Interpretable knowledge-aware recommendation; Online behaviors; Patent recommendation";Purpose: Patent trade recommendations necessitate recommendation interpretability in addition to recommendation accuracy because of patent transaction risks and the technological complexity of patents. This study designs an interpretable knowledge-aware patent recommendation model (IKPRM) for patent trading. IKPRM first creates a patent knowledge graph (PKG) for patent trade recommendations and then leverages paths in the PKG to achieve recommendation interpretability. Design/methodology/approach: First, we construct a PKG to integrate online company behaviors and patent information using natural language processing techniques. Second, a bidirectional long short-term memory network (BiLSTM) is utilized with an attention mechanism to establish the connecting paths of a company — patent pair in PKG. Finally, the prediction score of a company — patent pair is calculated by assigning different weights to their connecting paths. The semantic relationships in connecting paths help explain why a candidate patent is recommended. Findings: Experiments on a real dataset from a patent trading platform verify that IKPRM significantly outperforms baseline methods in terms of hit ratio and normalized discounted cumulative gain (nDCG). The analysis of an online user study verified the interpretability of our recommendations. Originality/value: A meta-path-based recommendation can achieve certain explainability but suffers from low flexibility when reasoning on heterogeneous information. To bridge this gap, we propose the IKPRM to explain the full paths in the knowledge graph. IKPRM demonstrates good performance and transparency and is a solid foundation for integrating interpretable artificial intelligence into complex tasks such as intelligent recommendations. © 2021, Emerald Publishing Limited.;Scopus;2021;10.1108/intr-08-2020-0473;Du W., Yan Q., Zhang W., Ma J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107717528&doi=10.1108%2fINTR-08-2020-0473&partnerID=40&md5=de0eec8cad311f3e51382373d25b8025;China, Hong Kong;semantic search;validation research;method;law;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;salkg: a semantic annotation system for building a high-quality legal knowledge graph;"Annotation System; Knowledge Graph; Legal Text; Semantic Annotation";Knowledge graph has become an essential tool for semantic analysis with the development of natural language processing and deep learning. A high-quality knowledge graph is handy for building a high-performance knowledge-driven application. Despite recent advances in information extraction (IE) techniques, no suitable automated methods can be applied to constructing a domain-specific, comprehensive, and high-quality knowledge graph. However, a semi-automatic strategy, which can ensure the basic quality requirements of a knowledge graph, has been successfully implemented in the elementary science domain. This paper presents a semantic annotation system developed for building a high-quality legal knowledge graph (SALKG) using the semi-automatic strategy. We introduce its system design, architecture, algorithms, functions, and implementation. To investigate the effectiveness of SALKG, we conduct a preliminary annotation experiment with 280 legal texts which were collected from the Harvard Caselaw Access Project. The user evaluation from 32 graduate students demonstrates the high usability of SALKG in semantic annotation and the potential for building a high-quality legal knowledge graph. The system can also be adapted to other fields for constructing domain-specific knowledge graphs. © 2020 IEEE.;IEEE;2020;10.1109/bigdata50022.2020.9378107;Tang M., Su C., Chen H., Qu J., Ding J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103843885&doi=10.1109%2fBigData50022.2020.9378107&partnerID=40&md5=82016294baea2b82bb3e0ce426518263;China;"entity extraction; relation extraction; ontology construction";validation research;tool;law;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;measuring semantic similarity across eu gdpr regulation and cloud privacy policies;"Big Data Categories; Document Similarity; General Data Protection Regulation; Ontology; Organizations; Semantic Web; Text Extraction";Data protection authorities formulate policies and rules which the service providers have to comply with to ensure security and privacy when they perform Big Data analytics using users Personally Identifiable Information (PII). The knowledge contained in the data regulations and organizational privacy policies are typically maintained as short unstructured text in HTML or PDF formats. Hence it is an open challenge to determine the specific regulation rules that are being addressed by a provider's privacy policies. We have developed a semantically rich framework, using techniques from Semantic Web and Natural Language Processing, to extract and compare the context of a short text in real-time. This framework allows automated incremental text comparison and identifying context from short text policy documents by determining the semantic similarity score and extracting semantically similar key terms. Additionally, we also created a knowledge graph to store the semantically similar comparison results while evaluating our framework across EU GDPR and privacy policies of 20 organizations complying with this regulation associated with various categories apply to Big Data stored in the cloud. Our approach can be utilized by Big Data practitioners to update their referential documents regularly based on the authority documents. © 2020 IEEE.;IEEE;2020;10.1109/bigdata50022.2020.9377864;Elluri L., Pande Joshi K., Kotal A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103823587&doi=10.1109%2fBigData50022.2020.9377864&partnerID=40&md5=57463a0ba8d61a88b87ff148a3314eda;United States;semantic similarity;solution proposal;method;law;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;legal knowledge extraction for knowledge graph based question-answering;"Legal Knowledge Extraction; Ontology Design Pattern Alignment; Question-Answering";This paper presents the Open Knowledge Extraction (OKE) tools combined with natural language analysis of the sentence in order to enrich the semantic of the legal knowledge extracted from legal text. In particular the use case is on international private law with specific regard to the Rome I Regulation EC 593/2008, Rome II Regulation EC 864/2007, and Brussels I bis Regulation EU 1215/2012. A Knowledge Graph (KG) is built using OKE and Natural Language Processing (NLP) methods jointly with the main ontology design patterns defined for the legal domain (e.g., event, time, role, agent, right, obligations, jurisdiction). Using critical questions, underlined by legal experts in the domain, we have built a question answering tool capable to support the information retrieval and to answer to these queries. The system should help the legal expert to retrieve the relevant legal information connected with topics, concepts, entities, normative references in order to integrate his/her searching activities. © 2020 The Authors, Faculty of Law, Masaryk University and IOS Press.;Scopus;2020;10.3233/faia200858;Sovrano F., Palmirani M., Vitali F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098663436&doi=10.3233%2fFAIA200858&partnerID=40&md5=3225d78234530e3dbe9397f72d351338;Italy;"entity extraction; relation extraction; ontology construction; question answering";solution proposal;"tool; resource";law;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;a spatiotemporal knowledge bank from rape news articles for decision support;"Knowledge graph; Location-based; Ontology; PeNLP Parser; Spatiotemporal";Rape cases have been on the increase during the COVID’19 pandemic. All News media including the online Newsfeed report these cases around our communities. It is important for intending visitors or residents to be properly informed of specific locations and the times these occurrences are predominant. Our proposed model is aimed at providing a spatiotemporal knowledge bank useful for personal, governmental and/or organizational decision support on occurrences like rape and armed robbery. This model uses a hybrid of preposition enabled natural language processing (PeNLP) parser and ontology-based approach for spatiotemporal data extraction from online news publications to create the knowledge bank for decision support systems (DSS). Protégé is used in the development of the ontology and the resulting graph shows the knowledge bank entities. The result from the PeNLP parser stored in the knowledge bank follows the domain categorization modeled in the graph. The Precision, Recall and F-measure in spatial feature extraction were 100%, 88.89% and 94.12% respectively. The average Precision, Recall and F-measure of our model in temporal feature extraction is 100%. These results represent a successful extraction of spatiotemporal features from online news reports necessary for reasoning in any DSS. © Springer Nature Switzerland AG 2020.;Scopus;2020;10.1007/978-3-030-65384-2_11;Usip P.U., Ijebu F.F., Dan E.A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098253496&doi=10.1007%2f978-3-030-65384-2_11&partnerID=40&md5=a7473ee4b0c5873dbd5b6edbaa4928db;Niger, Nigeria;"entity extraction; relation extraction; ontology construction; semantic search";solution proposal;method;law;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;orchestrating nlp services for the legal domain;"Applications; Knowledge Discovery/Representation; Systems; Text Analytics; Tools";Legal technology is currently receiving a lot of attention from various angles. In this contribution we describe the main technical components of a system that is currently under development in the European innovation project Lynx, which includes partners from industry and research. The key contribution of this paper is a workflow manager that enables the flexible orchestration of workflows based on a portfolio of Natural Language Processing and Content Curation services as well as a Multilingual Legal Knowledge Graph that contains semantic information and meaningful references to legal documents. We also describe different use cases with which we experiment and develop prototypical solutions. © European Language Resources Association (ELRA), licensed under CC-BY-NC;ACL;2020;;Moreno-Schneider J., Rehm G., Montiel-Ponsoda E., Rodríguez-Doncel V., Revenko A., Karampatakis S., Khvalchik M., Sageder C., Gracia J., Maganza F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094515387&partnerID=40&md5=33cbdc2f68cab07c3c4f581ca3d2edf9;Austria, Germany, Spain, Italy;"entity extraction; relation extraction; semantic search";solution proposal;tool;law;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;creation and enrichment of a terminological knowledge graph in the legal domain;"Knowledge Graphs; Linguistic Linked Data; Semantic Web; Terminology Management";Domain-specific terminologies are of great use in a number of contexts, such as information retrieval from text documents or supporting humans in translation tasks. However, automated terminology extraction tools usually render plain lists with no additional information (hierarchical relations, definitions or examples of use, amongst others). The output of these tools is very often offered in non-open formats, hampering their reuse and interoperability. Moreover, terminology management tools demand a lot of manual work to curate and enrich the resources and they do not support the representation of terminological relations beyond broader/narrower. The contributions of this Thesis mitigate these problems by automating the creation of rich terminologies from plain text documents, by establishing links to external resources, and by adopting the W3C standards for the Semantic Web. The proposed method comprises six tasks: refinement, disambiguation, enrichment, relation validation, relation extraction and RDF conversion. We have applied this methodology to two different legal corpora, i.e., contracts and collective agreements. The result of this methodology will be a Terminological Knowledge Graph that can be exploited by different Natural Language Processing applications. Copyright © 2020 held by the author.;Scopus;2020;;Martín-Chozas P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084616018&partnerID=40&md5=bcb915526ea38ea83a305eab069c6d96;Spain;"relation extraction; error detection";solution proposal;method;law;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;engineering knowledge graph for keyword discovery in patent search;"Engineering knowledge graph; Machine learning; Ontologies; Semantic data processing";Patent retrieval and analytics have become common tasks in engineering design and innovation. Keyword-based search is the most common method and the core of integrative methods for patent retrieval. Often searchers intuitively choose keywords according to their knowledge on the search interest which may limit the coverage of the retrieval. Although one can identify additional keywords via reading patent texts from prior searches to refine the query terms heuristically, the process is tedious, time-consuming, and prone to human errors. In this paper, we propose a method to automate and augment the heuristic and iterative keyword discovery process. Specifically, we train a semantic engineering knowledge graph on the full patent database using natural language processing and semantic analysis, and use it as the basis to retrieve and rank the keywords contained in the retrieved patents. On this basis, searchers do not need to read patent texts but just select among the recommended keywords to expand their queries. The proposed method improves the completeness of the search keyword set and reduces the human effort for the same task. © 2019 Design Society. All rights reserved.;Scopus;2019;10.1017/dsi.2019.231;Sarica S., Song B., Low E., Luo J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076468727&doi=10.1017%2fdsi.2019.231&partnerID=40&md5=46825280606b569a78765523b1d07f04;Singapore;semantic search;solution proposal;"tool; resource";law;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;an investigative search engine for the human trafficking domain;"Human trafficking; Illicit domains; Investigative search; Knowledge graph construction; Knowledge graphs";Enabling intelligent search systems that can navigate and facet on entities, classes and relationships, rather than plain text, to answer questions in complex domains is a longstanding aspect of the Semantic Web vision. This paper presents an investigative search engine that meets some of these challenges, at scale, for a variety of complex queries in the human trafficking domain. The engine provides a real-world case study of synergy between technology derived from research communities as diverse as Semantic Web (investigative ontologies, SPARQL-inspired querying, Linked Data), Natural Language Processing (knowledge graph construction, word embeddings) and Information Retrieval (fast, user-driven relevance querying). The search engine has been rigorously prototyped as part of the DARPA MEMEX program and has been integrated into the latest version of the Domain-specific Insight Graph (DIG) architecture, currently used by hundreds of US law enforcement agencies for investigating human trafficking. Over a hundred millions ads have been indexed. The engine is also being extended to other challenging illicit domains, such as securities and penny stock fraud, illegal firearm sales, and patent trolling, with promising results. © Springer International Publishing AG 2017.;Scopus;2017;10.1007/978-3-319-68204-4_25;Kejriwal M., Szekely P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032171447&doi=10.1007%2f978-3-319-68204-4_25&partnerID=40&md5=ae88cc0e6341b348cecd40f6bb20fb58;United States;"entity extraction; relation extraction; semantic search";evaluation research;tool;law;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;the effect of text ambiguity on creating policy knowledge graphs;"privacy policy;ambiguity;knowledge graph;knowledge extraction;policy maintenance";A growing number of web and cloud-based products and services rely on data sharing between consumers, service providers, and their subsidiaries and third parties. There is a growing concern around the security and privacy of data in such large-scale shared architectures. Most organizations have a human-written privacy policy that discloses all the ways that data is shared, stored, and used. The organizational privacy policies must also be compliant with government and administrative regulations. This raises a major challenge for providers as they try to launch new services. Thus they are moving towards a system of automatic policy maintenance and regulatory compliance. This requires extracting policy from text documents and representing it in a semi-structured, machine-processable framework. The most popular method to this end is extracting policy information into a Knowledge Graph (KG). There exists a significant body of work that converts text descriptions of regulations into policies expressed in languages such as OWL and XACML and is grounded in the control-based schema by using NLP approaches. In this paper, we show that the NLP-based approaches to extract knowledge from written policy documents and representing them in enforceable Knowledge Graphs fail when the text policies are ambiguous. Ambiguity can arise from lack of clarity, misuse of syntax, and/or the use of complex language. We describe a system to extract features from a policy document that affect its ambiguity and classify the documents based on the level of ambiguity present. We validate this approach using human annotators. We show that a large number of documents in a popular privacy policy corpus (OPP-115) are ambiguous. This affects the ability to automatically monitor privacy policies. We show that for policies that are more ambiguous according to our proposed measure, NLP-based text segment classifiers are less accurate.;IEEE;2021;10.1109/ispa-bdcloud-socialcom-sustaincom52081.2021.00201;"A. Kotal; A. Joshi; K. Pande Joshi";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644852;United States;text analysis;validation research;method;law;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;are you for real detecting identity fraud via dialogue interactions;"Crime; Heuristic methods; Knowledge representation; Speech processing; Speech recognition; Dialogue management; Dialogue strategy; Financial industry; Knowledge graphs; Personal information; Problem analysis; Real-world scenario; Recognition accuracy; Natural language processing systems";Identity fraud detection is of great importance in many real-world scenarios such as the financial industry. However, few studies addressed this problem before. In this paper, we focus on identity fraud detection in loan applications and propose to solve this problem with a novel interactive dialogue system which consists of two modules. One is the knowledge graph (KG) constructor organizing the personal information for each loan applicant. The other is structured dialogue management that can dynamically generate a series of questions based on the personal KG to ask the applicants and determine their identity states. We also present a heuristic user simulator based on problem analysis to evaluate our method. Experiments have shown that the trainable dialogue system can effectively detect fraudsters, and achieve higher recognition accuracy compared with rule-based systems. Furthermore, our learned dialogue strategies are interpretable and flexible, which can help promote real-world applications.1. © 2019 Association for Computational Linguistics;ACL;2020;;Wang W., Zhang J., Li Q., Zong C., Li Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084292925&partnerID=40&md5=fbfea3931e12234683c152c01d783bde;China;conversational interfaces;validation research;tool;law;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a semantic approach for automating knowledge in policies of cyber insurance services;"Cyber Insurance; Knowledge Representation; Ontology; Policies";With the rapid adoption of web services, the need to protect against various threats has become imperative for organizations operating in cyberspace. Organizations are increasingly opting to get financial cover in the event of losses due to a security incident. This helps them safeguard against the threat posed to third-party services that the organization uses. It is in the organization's interest to understand the insurance requirements and procure all necessary direct and liability coverages. This helps transfer some risks to the insurance providers. However, cyber insurance policies often list details about coverages and exclusions using legalese that can be difficult to comprehend. Currently, it takes a significant manual effort to parse and extract knowledgeable rules from these lengthy and complicated policy documents. We have developed a semantically rich machine processable framework to automatically analyze cyber insurance policy and populate a knowledge graph that efficiently captures various inclusion and exclusion terms and rules embedded in the policy. In this paper, we describe this framework that has been built using technologies from AI, including Semantic Web, Modal/Deontic Logic, and Natural Language Processing. We have validated our approach using industry standards proposed by the United States Federal Trade Commission (FTC) and applying it against publicly available policies of 7 cyber insurance vendors. Our system will enable cyber insurance seekers to automatically analyze various policy documents and make a well-informed decision by identifying its inclusions and exclusions. © 2019 IEEE.;IEEE;2019;10.1109/icws.2019.00018;Joshi K., Joshi K.P., Mittal S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072767819&doi=10.1109%2fICWS.2019.00018&partnerID=40&md5=9cbd97e2a8279756dad060efe5994d22;United States;"entity extraction; relation extraction; semantic search";solution proposal;method;"law; information technology";1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;use learnable knowledge graph in dialogue system for visually impaired macro navigation;"Dialogue system; Knowledge graph; Navigation system; NLP; Reasoning; Visually impaired assistance";Dialogue in natural language is the most important communication method for the visually impaired. Therefore, the dialogue system is the main subsystem in the visually impaired navigation system. The purpose of the dialogue system is to understand the user’s intention, gradually establish context through multiple conversations, and finally provide an accurate destination for the navigation system. We use the knowledge graph as the basis of reasoning in the dialogue system, and then update the knowledge graph so that the system gradually conforms to the user’s background. Based on the experience of using the knowledge graph in the navigation system of the visually impaired, we expect that the same framework can be applied to more fields in order to improve the practicality of natural language dialogue in human–computer interaction. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Scopus;2021;10.3390/app11136057;Chen C.-H., Shiu M.-F., Chen S.-H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109408603&doi=10.3390%2fapp11136057&partnerID=40&md5=858e4000a2c849838ec0fd50d3cc00dd;Taiwan;conversational interfaces;solution proposal;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0
Conference Paper;application of geocognitive technologies to basin & petroleum system analyses;"Character recognition; Cognitive systems; Convolutional neural networks; Deep neural networks; Engines; Gasoline; Graph Databases; Lithology; Natural language processing systems; Ontology; Petroleum geology; Petroleum prospecting; Petroleum reservoir evaluation; Recurrent neural networks; Structural geology; Amount of information; Extracting information; Graphical representations; Innovative technology; NAtural language processing; Structural elements; Technical documents; Three-step approach; Search engines";Objectives/Scope: When dealing with new exploration areas, basin geologists face the challenge of collecting relevant information from all available sources. This include a number of structured commercial databases, but also large corpora of technical documents in which an invaluable amount of information is scattered across. Even if assisted by search tools to filter the documents of interest, extracting information requires a human effort in reading and understanding the documents. Methods, Procedures, Process: Eni and IBM developed a cognitive engine exploiting a deep learning approach to scan documents searching for basin geology concepts, extracting information about petroleum system elements (e.g. formation name, geological age and lithology of source rocks, reservoirs and seals) and enabling basin geologists to perform automated queries to collect all the information related to a basin of interest. The collected information is fully referenced to the original paragraphs, tables or pictures of the document in which it was discovered, therefore enabling to validate the robustness of the results. Results, Observations, Conclusions: The cognitive engine has been integrated within an application which enables to build a graphical representation of the Petroleum System Event Charts of the basin, integrating the information extracted from commercial databases, the results from the cognitive engine and the manual input from the geologist. The quality of the results from the cognitive engine has been evaluated using a commercial database which provides both tabular data about basins and detailed pdf reports. The cognitive engine has been trained on the pdf reports alone, and the results have been compared with the tabular content of the database, representing the ground truth. The cognitive engine succeeded in identifying the right formations, lithologies and geological ages of the petroleum systems with an accuracy in the range 75% - 90%. Novel/Additive Information: The cognitive engine is built with highly innovative technologies, combining the data driven capabilities of deep neural networks with more traditional natural language processing methods based on ontologies. Documents are processed with a three-step approach. In the first step, convolutional neural networks (CNN) are used to recognize the structural elements within a technical paper (e.g. title, authors, paragraphs, figures, tables, references) and to convert a complex pdf structure into a clean sequence of text, which can be analyzed. In the second step, concepts are extracted from these processed documents using extractors, NLP annotators (based on recurrent neural networks) and aggregators. Finally, the joint use of the results from the deep learning tools and the provided ontologies are used to build a knowledge graph, which links together all the discovered entities and their relationships. A fit-for-purpose high efficient graph database has been developed so that the graph can be traversed with full flexibility, collecting all the concepts needed for basin geology studies. © 2019, Society of Petroleum Engineers;Scopus;2019;10.2118/197610-ms;Ruffo P., Piantanida M., Bergero F., Staar P., Bekas C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084780600&doi=10.2118%2f197610-ms&partnerID=40&md5=14ea728e8b5ffee8889ac775de259b50;Italy, United States;"entity extraction; relation extraction; ontology construction; semantic search";solution proposal;tool;"natural science; energy";1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;information extraction and knowledge graph construction from geoscience literature;"Chinese word segmentation; Chord and bigram graphs; Geological corpus; Geoscience literature; Knowledge graph";Geoscience literature published online is an important part of open data, and brings both challenges and opportunities for data analysis. Compared with studies of numerical geoscience data, there are limited works on information extraction and knowledge discovery from textual geoscience data. This paper presents a workflow and a few empirical case studies for that topic, with a focus on documents written in Chinese. First, we set up a hybrid corpus combining the generic and geology terms from geology dictionaries to train Chinese word segmentation rules of the Conditional Random Fields model. Second, we used the word segmentation rules to parse documents into individual words, and removed the stop-words from the segmentation results to get a corpus constituted of content-words. Third, we used a statistical method to analyze the semantic links between content-words, and we selected the chord and bigram graphs to visualize the content-words and their links as nodes and edges in a knowledge graph, respectively. The resulting graph presents a clear overview of key information in an unstructured document. This study proves the usefulness of the designed workflow, and shows the potential of leveraging natural language processing and knowledge graph technologies for geoscience. © 2017 Elsevier Ltd;ScienceDirect;2018;10.1016/j.cageo.2017.12.007;Wang C., Ma X., Chen J., Chen J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039732196&doi=10.1016%2fj.cageo.2017.12.007&partnerID=40&md5=036ffb8dd33000dbb8efc6fd3ba9afa3;China, United States;"entity extraction; relation extraction";solution proposal;method;natural science;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;intelligent learning for knowledge graph towards geological data;"Geology; Natural language processing systems; Ontology; Semantics; Application systems; Document pre-processing; Effectiveness and efficiencies; Geological information; Intelligent learning; Knowledge extraction; NAtural language processing; Semantic associations; Data mining";Knowledge graph (KG) as a popular semantic network has been widely used. It provides an effective way to describe semantic entities and their relationships by extending ontology in the entity level. This article focuses on the application of KG in the traditional geological field and proposes a novel method to construct KG. On the basis of natural language processing (NLP) and data mining (DM) algorithms, we analyze those key technologies for designing a KG towards geological data, including geological knowledge extraction and semantic association. Through this typical geological ontology extracting on a large number of geological documents and open linked data, the semantic interconnection is achieved, KG framework for geological data is designed, application system of KG towards geological data is constructed, and dynamic updating of the geological information is completed accordingly. Specifically, unsupervised intelligent learning method using linked open data is incorporated into the geological document preprocessing, which generates a geological domain vocabulary ultimately. Furthermore, some application cases in the KG system are provided to show the effectiveness and efficiency of our proposed intelligent learning approach for KG. © 2017 Yueqin Zhu et al.;Scopus;2017;10.1155/2017/5072427;Zhu Y., Zhou W., Xu Y., Liu J., Tan Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014189855&doi=10.1155%2f2017%2f5072427&partnerID=40&md5=29b4ca77c0fb930ce97a117cddbf2ccb;China;"entity extraction; relation extraction; ontology construction";solution proposal;method;natural science;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;understanding ore-forming conditions using machine reading of text;Machine reading of text, Ore-forming conditions, Geological information extraction;Mineral exploration reports assist present day exploration by providing valuable observations about the geological environments in which mineral deposits form. Querying and aggregating historical data can assist in reducing future exploration risks and costs. However, since the reports are written in unstructured text, it is a challenging task to derive meaningful geological information without manually reading through a large collection of reports, which is a formidable task for geologists. In this study, geological information relevant to mineralisation and ore-forming conditions is automatically extracted from such under-utilised exploration reports. This is achieved by constructing knowledge graphs that describe geological entities and their relations as they appear in exploration reports. Natural language processing and deep learning methods are used to automatically extract and label geological terms with the correct entity types and establish the relationships between these entities. In this research, six dominant entity types are considered, namely, geographical location, geological timescale, stratigraphic unit, rock type, ore and deposit type, and contained minerals. Two knowledge graphs are constructed for two high-quality mineral exploration reports, one for iron ore and the other for gold deposit, to illustrate the effectiveness of our methodology. The knowledge graphs are then assessed by determining whether the contents of the source reports were depicted accurately, specifically the labelled geological terms in the nodes and their associations in node connections. The results show that the structured information stored in the knowledge graphs faithfully represent the contents of the source reports, matching well with the domain knowledge. The proposed methods are capable of rapidly and robustly transforming text data into a structured form, the untapped area towards geological knowledge mining.;ScienceDirect;2021;10.1016/j.oregeorev.2021.104200;Majigsuren Enkhsaikhan and Eun-Jung Holden and Paul Duuring and Wei Liu;https://www.sciencedirect.com/science/article/pii/S0169136821002250;Australia;"entity extraction; relation extraction";solution proposal;method;natural science;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;improving the quality and efficiency of operational planning and risk management with ml and nlp;"Knowledge management; Offshore oil well production; Planning; Risk management; Concurrent activities; NAtural language processing; Natural language understanding; Operation conditions; Operational experience; Operational planning; Personal experience; Technical conditions; Natural language processing systems";To ensure safe and efficient operations, all offshore operations follow a plan devised to take into account current operation conditions and identify the optimum workflow with the minimum risk potential. Previously, planners had to manually consult eight data sources, each with a separate UI, and summarise the plan in a.pdf document. Equinor's Operation Planning Tool (OPT) has been developed to easily present the planners with the technical conditions of a platform, identify potentially dangerous combinations of concurrent activities, and propose learnings from eight years’ worth of incident recordings – all relevant to the current list of planned activities. The tool aims to answer questions such as ‘are other activities planned for the same time which would make this activity unsafe?’ or ‘have incidents previously occurred whilst performing similar tasks on this equipment type?’. This paper details the development of the OPT with a particular focus on the application of Natural Language Understanding for extracting equipment types and tasks involved in previous incidents and relating these to planned activities. Utilising natural language processing techniques, a system has been developed that mines the content of Equinor's incident database, and assigns context to incidents, by identifying the systems, activities and equipment involved and the conditions on the asset at the time of the incident. The same context is also discovered from the content of planned activities. These key concepts are organised into a knowledge graph synthesising Equinor's institutional safety and operational experience. The OPT has reduced time spent planning by providing a single interface detailing a plant's technical conditions, all planned work orders and relevant lessons learned from previous incidents. By reducing the reliance on personal experience, the tool has provided subjectively improved risk identification and handling, plus faster knowledge transfer to new employees as well as focussed cross-platform knowledge sharing. The success of the tool highlights the strength of combining data and leveraging the vast quantities of historic data available both in unstructured and structured forms to create a safe, offshore work environment. Copyright 2019, Society of Petroleum Engineers;Scopus;2019;10.2118/195750-ms;Birnie C.E., Sampson J., Sjaastad E., Johansen B., Obrestad L.E., Larsen R., Khamassi A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084012858&doi=10.2118%2f195750-MS&partnerID=40&md5=0a184d1d1db50ac4d435ae8e5b6b32a0;United Kingdom;"entity extraction; relation extraction; ontology construction; semantic search";evaluation research;tool;energy;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;marine variable linker: exploring relations between changing variables in marine science literature;"Computational linguistics; Demonstrations; Graphical user interfaces; Knowledge representation; Text mining; Causal relations; Co-occurrence; Interactive way; Knowledge graphs; Marine science; Marine scientists; Web based; Carbon dioxide";We report on a demonstration system for text mining of literature in marine science and related disciplines. It automatically extracts variables (e.g. CO2) involved in events of change/increase/decrease (e.g increasing CO2), as well as cooccurrence and causal relations among these events (e.g. increasing CO2 causes a decrease in pH in seawater), resulting in a big knowledge graph. A web-based graphical user interface targeted at marine scientists facilitates searching, browsing and visualising events and their relations in an interactive way. © 2017 Association for Computational Linguistics.;ACL;2017;10.18653/v1/e17-3023;Marsi E., Øzturk P., Ardelan M.V.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021681301&doi=10.18653%2fv1%2fe17-3023&partnerID=40&md5=3df635031763e232a2f01d33ce24dc06;Norway;"entity extraction; relation extraction; semantic search";solution proposal;tool;natural science;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;compare to the knowledge: graph neural fake news detection with external knowledge;"Computational linguistics; Directed graphs; Knowledge graph; Semantics; Comparison networks; End to end; External knowledge; Heterogeneous documents; Heterogeneous graph; Knowledge graphs; Linguistic features; Neural modelling; News content; Semantic features; Knowledge based systems";Nowadays, fake news detection, which aims to verify whether a news document is trusted or fake, has become urgent and important. Most existing methods rely heavily on linguistic and semantic features from the news content, and fail to effectively exploit external knowledge which could help determine whether the news document is trusted. In this paper, we propose a novel end-to-end graph neural model called CompareNet, which compares the news to the knowledge base (KB) through entities for fake news detection. Considering that fake news detection is correlated with topics, we also incorporate topics to enrich the news representation. Specifically, we first construct a directed heterogeneous document graph for each news incorporating topics and entities. Based on the graph, we develop a heterogeneous graph attention network for learning the topic-enriched news representation as well as the contextual entity representations that encode the semantics of the news content. The contextual entity representations are then compared to the corresponding KB-based entity representations through a carefully designed entity comparison network, to capture the consistency between the news content and KB. Finally, the topic-enriched news representation combining the entity comparison features are fed into a fake news classifier. Experimental results on two benchmark datasets demonstrate that CompareNet significantly outperforms state-of-the-art methods. © 2021 Association for Computational Linguistics;ACL;2021;;Hu L., Yang T., Zhang L., Zhong W., Tang D., Shi C., Duan N., Zhou M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118918173&partnerID=40&md5=d45c2848d5b7bf759bf5812f6d2aabf0;China;text analysis;validation research;technique;news;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;fake news detection via nlp is vulnerable to adversarial attacks;"Attack; Fact Checking; Fake News Detection; NLP; Outsourced Knowledge Graph";News plays a significant role in shaping people's beliefs and opinions. Fake news has always been a problem, which wasn't exposed to the mass public until the past election cycle for the 45th President of the United States. While quite a few detection methods have been proposed to combat fake news since 2015, they focus mainly on linguistic aspects of an article without any fact checking. In this paper, we argue that these models have the potential to misclassify fact-tampering fake news as well as under-written real news. Through experiments on Fakebox, a state-of-the-art fake news detector, we show that fact tampering attacks can be effective. To address these weaknesses, we argue that fact checking should be adopted in conjunction with linguistic characteristics analysis, so as to truly separate fake news from real news. A crowdsourced knowledge graph is proposed as a straw man solution to collecting timely facts about news events. Copyright © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved;Scopus;2019;10.5220/0007566307940800;Zhou Z., Guan H., Bhat M.M., Hsu J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064814138&doi=10.5220%2f0007566307940800&partnerID=40&md5=375c826442cc6befdf27ad0b2e0fe4ce;China, United States;text analysis;solution proposal;guidelines;news;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;building event-centric knowledge graphs from news;Event-centric knowledge, Natural language processing, Event extraction, Information integration, Big data, Real world data;Knowledge graphs have gained increasing popularity in the past couple of years, thanks to their adoption in everyday search engines. Typically, they consist of fairly static and encyclopedic facts about persons and organizations–e.g. a celebrity’s birth date, occupation and family members–obtained from large repositories such as Freebase or Wikipedia. In this paper, we present a method and tools to automatically build knowledge graphs from news articles. As news articles describe changes in the world through the events they report, we present an approach to create Event-Centric Knowledge Graphs (ECKGs) using state-of-the-art natural language processing and semantic web techniques. Such ECKGs capture long-term developments and histories on hundreds of thousands of entities and are complementary to the static encyclopedic information in traditional knowledge graphs. We describe our event-centric representation schema, the challenges in extracting event information from news, our open source pipeline, and the knowledge graphs we have extracted from four different news corpora: general news (Wikinews), the FIFA world cup, the Global Automotive Industry, and Airbus A380 airplanes. Furthermore, we present an assessment on the accuracy of the pipeline in extracting the triples of the knowledge graphs. Moreover, through an event-centered browser and visualization tool we show how approaching information from news in an event-centric manner can increase the user’s understanding of the domain, facilitates the reconstruction of news story lines, and enable to perform exploratory investigation of news hidden facts.;ScienceDirect;2016;10.1016/j.websem.2015.12.004;Marco Rospocher and Marieke {van Erp} and Piek Vossen and Antske Fokkens and Itziar Aldabe and German Rigau and Aitor Soroa and Thomas Ploeger and Tessel Bogaard;https://www.sciencedirect.com/science/article/pii/S1570826815001456;Italy, Netherlands, Spain;"entity extraction; relation extraction; entity linking";solution proposal;tool;news;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Journal Article;a knowledge-graph platform for newsrooms;Computational journalism, Journalistic knowledge platforms, Newsroom systems, Knowledge graphs, Semantic technologies, RDF, OWL, Ontology, Natural-language processing (NLP), Machine learning (ML);Journalism is challenged by digitalisation and social media, resulting in lower subscription numbers and reduced advertising income. Information and communication techniques (ICT) offer new opportunities. Our research group is collaborating with a software developer of news production tools for the international market to explore how social, open, and other data sources can be leveraged for journalistic purposes. We have developed an architecture and prototype called News Hunter that uses knowledge graphs, natural-language processing (NLP), and machine learning (ML) together to support journalists. Our focus is on combining existing data sources and computation and storage techniques into a flexible architecture for news journalism. The paper presents News Hunter along with plans and possibilities for future work.;ScienceDirect;2020;10.1016/j.compind.2020.103321;Arne Berven and Ole A. Christensen and Sindre Moldeklev and Andreas L. Opdahl and Kjetil J. Villanger;https://www.sciencedirect.com/science/article/pii/S0166361520305558;Norway;semantic search;solution proposal;tool;news;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;construction research and application of poverty alleviation knowledge graph;"An approach of knowledge graph construction; Bayesian classification; Knowledge question answering; Neo4j graph storage; Poverty alleviation knowledge graph";Based on the integration of multi-source data, an approach of domain-specific knowledge graph construction is proposed to guide the construction of a “people-centered” poverty alleviation knowledge graph, and to achieve cross-functional and cross-regional sharing and integration of national basic data resources and public services. Focusing on “precise governance and benefit people service”, poverty alleviation ontology is constructed to solve semantic heterogeneity in multiple data sources integration, and provide an upper data schema for poverty alleviation knowledge graph construction. Karma modeling is used to implement semantic mapping between ontology concepts and data, and integrate multi-source heterogeneous data into RDF data. The RDF2Neo4j interpreter is developed to parse RDF data and store RDF data schema based on the graph database Neo4j. Based on visualization technology and natural language processing technology, Poverty Alleviation Knowledge Graph Application System is designed to achieve knowledge graph query and knowledge question answering function, which improved the application value of government data. © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-30952-7_42;Yun H., He Y., Lin L., Pan Z., Zhang X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075604976&doi=10.1007%2f978-3-030-30952-7_42&partnerID=40&md5=ad05e8ecb90d9d804a3578be64bf8330;China;"entity extraction; relation extraction; semantic search; ontology construction";solution proposal;tool;public sector;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;tnnt: the named entity recognition toolkit;"information extraction; knowledge graph construction pipeline; named entity recognition; natural language processing";Extraction of categorised named entities from text is a complex task given the availability of a variety of Named Entity Recognition (NER) models and the unstructured information encoded in different source document formats. Processing the documents to extract text, identifying suitable NER models for a task, and obtaining statistical information is important in data analysis to make informed decisions. This paper presents\footnoteThe manuscript follows guidelines to showcase a demonstration that introduces an overview of how the toolkit works: input document set, initial settings, processing, and output set. The input document set is artificial in order to show various toolkit capabilities. TNNT, a toolkit that automates the extraction of categorised named entities from unstructured information encoded in source documents, using diverse state-of-the-art (SOTA) Natural Language Processing (NLP) tools and NER models.TNNT integrates 21 different NER models as part of a Knowledge Graph Construction Pipeline (KGCP) that takes a document set as input and processes it based on the defined settings, applying the selected blocks of NER models to output the results. The toolkit generates all results with an integrated summary of the extracted entities, enabling enhanced data analysis to support the KGCP, and also, to aid further NLP tasks. © 2021 ACM.;ACM;2021;10.1145/3460210.3493550;Seneviratne S., Rodríguez Méndez S.J., Zhang X., Omran P.G., Taylor K., Haller A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120920823&doi=10.1145%2f3460210.3493550&partnerID=40&md5=140f7f4846bde88afa9d00528278f009;Australia;entity extraction;solution proposal;tool;public sector;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;entity classification for military knowledge graph based on baidu encyclopedia distance learning;"Distance learning; Entity classification; Military industry knowledge graph; Web crawler";Entity types are a critical enabler for many NLP tasks that use KGs as a reference source. However, Classifying terminological entities without context remains an important outstanding obstacle in the field of KG completion. In this paper, we put forward a method combining distance learning and deep learning to address the classification of entity with no context. We compare the performance of our method with several text classification methods and shows our approach is empirically effective. Furthermore, the experiment result shows our approach can reduce the labeling work cost and expand the entities for further knowledge graph construction. © 2021 IEEE.;IEEE;2021;10.1109/ibcast51254.2021.9393163;Jia H., Li Y., Song D., Wang Q.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104659784&doi=10.1109%2fIBCAST51254.2021.9393163&partnerID=40&md5=67d8376aaf5f2c3d6e77333ea73be386;China;"entity classification; entity extraction";validation research;technique;public sector;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;question answering system over knowledge graph of weapon field;"knowledge graph; natural language processing; question answering; weapon field";Question answering system in the weapon field not only enables users to obtain information on weapons quickly and accurately, but also provides smarter question answering. With military weapons as the research direction, an SVM question classification method based on Chinese character algorithm is proposed, and a question answering system over knowledge graph of weapons is established. The domain word segmentation is used in this system to analyze user questions, extract question features for classification, intelligently generate SPARQL, query RDF to get answers, and return them to the user. Experiments show that the intelligent question answering system with the multi-question classification is effective and highly accurate in answering questions in the field of weapon. © 2020 IEEE.;IEEE;2020;10.1109/crc51253.2020.9253485;Gao P., Zhao T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097828203&doi=10.1109%2fCRC51253.2020.9253485&partnerID=40&md5=ae75435b73af7d9b778a949210f71121;China;"question answering; text classification";validation research;method;public sector;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;armatweet: detecting events by semantic tweet analysis;"Disasters; Search engines; Social networking (online); Knowledge graphs; Natural disasters; Science and Technology; Semantic event detection; Social media analysis; Sparql queries; Swiss Armed Forces; Terrorist activities; Semantic Web";Armasuisse Science and Technology, the R&D agency for the Swiss Armed Forces, is developing a Social Media Analysis (SMA) system to help detect events such as natural disasters and terrorist activity by analysing Twitter posts. The system currently supports only keyword search, which cannot identify complex events such as ‘politician dying’ or ‘militia terror act’ since the keywords that correctly identify such events are typically unknown. In this paper we present ArmaTweet, an extension of SMA developed in a collaboration between armasuisse and the Universities of Fribourg and Oxford that supports semantic event detection. Our system extracts a structured representation from the tweets’ text using NLP technology, which it then integrates with DBpedia and WordNet in an RDF knowledge graph. Security analysts can thus describe the events of interest precisely and declaratively using SPARQL queries over the graph. Our experiments show that ArmaTweet can detect many complex events that cannot be detected by keywords alone. © Springer International Publishing AG 2017.;Scopus;2017;10.1007/978-3-319-58451-5_10;Tonon A., Cudré-Mauroux P., Blarer A., Lenders V., Motik B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019637337&doi=10.1007%2f978-3-319-58451-5_10&partnerID=40&md5=dd623c35f634a194a7029fa06f42bf96;Switzerland, United Kingdom;"entity extraction; relation extraction; semantic search";validation research;tool;"public sector; social media";1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;1
Journal Article;gis-kg: building a large-scale hierarchical knowledge graph for geographic information science;"Geographic information science (GIS); information retrieval; knowledge graph; natural language processing; ontology";An organized knowledge base can facilitate the exploration of existing knowledge and the detection of emerging topics in a domain. Knowledge about and around Geographic Information Science and its associated system technologies (GIS) is complex, extensive and emerging rapidly. Taking the challenge, we built a GIS knowledge graph (GIS-KG) by (1) merging existing GIS bodies of knowledge to create a hierarchical ontology and then (2) applying deep-learning methods to map GIS publications to the ontology. We conducted several experiments on information retrieval to evaluate the novelty and effectiveness of the GIS-KG. Results showed the robust support of GIS-KG for knowledge search of existing GIS topics and potential to explore emerging research themes. © 2021 Informa UK Limited, trading as Taylor & Francis Group.;Scopus;2021;10.1080/13658816.2021.2005795;Du J., Wang S., Ye X., Sinton D.S., Kemp K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119981012&doi=10.1080%2f13658816.2021.2005795&partnerID=40&md5=2cfe2e15000b6bf298f7e3a19e3d2df0;United States;"ontology construction; entity linking; entity alignment";validation research;method;natural science;0;0;0;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;identifying used methods and datasets in scientific publications;"Character recognition; Indexing (of information); Knowledge representation; Natural language processing systems; Human interactions; Identifying methods; Knowledge graphs; Named entity recognition; Paper recommendations; Scientific method; Scientific publications; Textual contexts; Publishing";Although it has become common to assess publications and researchers by means of their citation count (e.g., using the h-index), measuring the impact of scientific methods and datasets (e.g., using an h-index for datasets) has been performed only to a limited extent. This is not surprising because the usage information of methods and datasets is typically not explicitly provided by the authors, but hidden in a publication's text. In this paper, we propose an approach to identifying methods and datasets in texts that have actually been used by the authors. Our approach first recognizes datasets and methods in the text by means of a domain-specific named entity recognition method with minimal human interaction. It then classifies these mentions into used vs. non-used based on the textual contexts. The obtained labels are aggregated on the document level and integrated into the Microsoft Academic Knowledge Graph modeling publications' metadata. In experiments based on the Microsoft Academic Graph, we show that both method and dataset mentions can be identified and correctly classified with respect to their usage to a high degree. Overall, our approach facilitates method and dataset recommendation, enhanced paper recommendation, and scientific impact quantification. It can be extended in such a way that it can identify mentions of any entity type (e.g., task). Copyright © 2021for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).;Scopus;2021;;Färber M., Albers A., Schüber F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103121171&partnerID=40&md5=498e688252287f4372805218fbb9eeca;Germany;"entity extraction; entity linking; semantic search";validation research;method;scholarly domain;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;ai 2000: a decade of artificial intelligence;"Artificial Intelligence; Data Mining; Machine Learning; Most Influential Scholars";In the past decades, artificial intelligence has dramatically changed the way we work and live. Moreover, it is increasingly becoming a national strategy for its rapid development and broad application in industries. However, the way artificial intelligence advances itself is sorely lacking until now. One of the most important reasons is the deficiency of timely and reliable knowledge graph in this field. To illustrate the problem, we introduce an academic knowledge graph of AI, named AI 2000, which combines techniques in data mining, bibliometrics, natural language processing, etc. In this work, we try to link the entities of scholars, academic papers, researches, etc. in the field of artificial intelligence. AI 2000 aims at serving as a medium for us to explore the evolution of artificial intelligence in the past decade and looking forward to its future trend. The methodology illustrates its timeliness and reliability, and analysis demonstrates high quality and availability. It is freely available at AMiner1. © 2020 ACM.;ACM;2020;10.1145/3394231.3397925;Shao Z., Shen Z., Yuan S., Tang J., Wang Y., Wu L., Zheng W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088390761&doi=10.1145%2f3394231.3397925&partnerID=40&md5=0beb2d8029f90c3ffef149bf0c59e569;China;semantic search;solution proposal;"tool; resource";scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;microsoft academic graph: when experts are not enough;"Citation networks; Eigenvector centrality measure; Knowledge graph; Research assessments; Saliency ranking; Scholarly database";An ongoing project explores the extent to which artificial intelligence (AI), specifically in the areas of natural language processing and semantic reasoning, can be exploited to facilitate the studies of science by deploying software agents equipped with natural language understanding capabilities to read scholarly publications on the web. The knowledge extracted by these AI agents is organized into a heterogeneous graph, called Microsoft Academic Graph (MAG), where the nodes and the edges represent the entities engaging in scholarly communications and the relationships among them, respectively. The frequently updated data set and a few software tools central to the underlying AI components are distributed under an open data license for research and commercial applications. This paper describes the design, schema, and technical and business motivations behind MAG and elaborates how MAG can be used in analytics, search, and recommendation scenarios. How AI plays an important role in avoiding various biases and human induced errors in other data sets and how the technologies can be further improved in the future are also discussed. © 2020 Kuansan Wang, Zhihong Shen, Chi-Yuan Huang, Chieh-Han Wu, Yuxiao Dong, and Anshul Kanakia.;Scopus;2020;10.1162/qss_a_00021;Wang K., Shen Z., Huang C., Wu C.-H., Dong Y., Kanakia A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090098906&doi=10.1162%2fqss_a_00021&partnerID=40&md5=09041be5f5714e2b799f073144d2720b;United States;semantic search;solution proposal;"method; resource";scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;ai-kg: an automatically generated knowledge graph of artificial intelligence;"Artificial Intelligence; Information Extraction; Knowledge graph; Natural Language Processing; Scholarly data";Scientific knowledge has been traditionally disseminated and preserved through research articles published in journals, conference proceedings, and online archives. However, this article-centric paradigm has been often criticized for not allowing to automatically process, categorize, and reason on this knowledge. An alternative vision is to generate a semantically rich and interlinked description of the content of research publications. In this paper, we present the Artificial Intelligence Knowledge Graph (AI-KG), a large-scale automatically generated knowledge graph that describes 820K research entities. AI-KG includes about 14M RDF triples and 1.2M reified statements extracted from 333K research publications in the field of AI, and describes 5 types of entities (tasks, methods, metrics, materials, others) linked by 27 relations. AI-KG has been designed to support a variety of intelligent services for analyzing and making sense of research dynamics, supporting researchers in their daily job, and helping to inform decision-making in funding bodies and research policymakers. AI-KG has been generated by applying an automatic pipeline that extracts entities and relationships using three tools: DyGIE++, Stanford CoreNLP, and the CSO Classifier. It then integrates and filters the resulting triples using a combination of deep learning and semantic technologies in order to produce a high-quality knowledge graph. This pipeline was evaluated on a manually crafted gold standard, yielding competitive results. AI-KG is available under CC BY 4.0 and can be downloaded as a dump or queried via a SPARQL endpoint. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-62466-8_9;Dessì D., Osborne F., Reforgiato Recupero D., Buscaldi D., Motta E., Sack H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096591173&doi=10.1007%2f978-3-030-62466-8_9&partnerID=40&md5=944ff4e0c33e5e22c91dff8992df7b9e;Germany, France, United Kingdom, Italy;"entity extraction; relation extraction; ontology construction";validation research;"method; resource";scholarly domain;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;on the utilization of structural and textual information of a scientific knowledge graph to discover future research collaborations: a link prediction perspective;"Document representation; Future research collaborations; Link prediction; Natural language processing; Research knowledge graphs";We consider the discovery of future research collaborations as a link prediction problem applied on scientific knowledge graphs. Our approach integrates into a single knowledge graph both structured and unstructured textual data through a novel representation of multiple scientific documents. The Neo4j graph database is used for the representation of the proposed scientific knowledge graph. For the implementation of our approach, we use the Python programming language and the scikit-learn ML library. We benchmark our approach against classical link prediction algorithms using accuracy, recall, and precision as our performance metrics. Our initial experimentations demonstrate a significant improvement of the accuracy of the future collaboration prediction task. The experimentations reported in this paper use the new COVID-19 Open Research Dataset. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-61527-7_29;Giarelis N., Kanakaris N., Karacapilidis N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094142033&doi=10.1007%2f978-3-030-61527-7_29&partnerID=40&md5=1c7c2e382f4f25258c14c99ddf4f90f3;Greece;link prediction;validation research;technique;scholarly domain;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;nlpcontributions: an annotation scheme for machine reading of scholarly contributions in natural language processing literature;"Annotation guidelines; Dataset; Digital libraries; Open science graphs; Scholarly knowledge graphs; Semantic publishing";"We describe an annotation initiative to capture the scholarly contributions in natural language processing (NLP) articles, particularly, for the articles that discuss machine learning (ML) approaches for various information extraction tasks. We develop the annotation task based on a pilot annotation exercise on 50 NLP-ML scholarly articles presenting contributions to five information extraction tasks 1. machine translation, 2. named entity recognition, 3. question answering, 4. relation classification, and 5. text classification. In this article, we describe the outcomes of this pilot annotation phase. Through the exercise we have obtained an annotation methodology; and found ten core information units that reflect the contribution of the NLP-ML scholarly investigations. The resulting annotation scheme we developed based on these information units is called NLPContributions. The overarching goal of our endeavor is four-fold: 1) to find a systematic set of patterns of subject-predicate-object statements for the semantic structuring of scholarly contributions that are more or less generically applicable for NLP-ML research articles; 2) to apply the discovered patterns in the creation of a larger annotated dataset for training machine readers [18] of research contributions; 3) to ingest the dataset into the Open Research Knowledge Graph (ORKG) infrastructure as a showcase for creating user-friendly state-of-the-art overviews; 4) to integrate the machine readers into the ORKG to assist users in the manual curation of their respective article contributions. We envision that the NLPContributions methodology engenders a wider discussion on the topic toward its further refinement and development. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).";Scopus;2020;;D'Souza J., Auer S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090918844&partnerID=40&md5=9cb6e55488d818c56b7307c5f2e45c37;Germany;"machine translation; question answering; relation classification; text classification";solution proposal;"resource; guidelines";scholarly domain;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;1;0;0;1;0;0;0;0;0;0;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;an automatic literature knowledge graph and reasoning network modeling framework based on ontology and natural language processing;"Knowledge graph; Knowledge reasoning; Natural language processing; Representation ontology";With the advancement of scientific and engineering research, a huge number of academic literature are accumulated. Manually reviewing the existing literature is the main way to explore embedded knowledge, and the process is quite time-consuming and labor intensive. As the quantity of literature is increasing exponentially, it would be more difficult to cover all aspects of the literature using the traditional manual review approach. To overcome this drawback, bibliometric analysis is used to analyze the current situation and trend of a specific research field. In the bibliometric analysis, only a few key phrases (e.g., authors, publishers, journals, and citations) are usually used as the inputs for analysis. Information other than those phrases is not extracted for analysis, while that neglected information (e.g., abstract) might provide more detailed knowledge in the article. To tackle with this problem, this study proposed an automatic literature knowledge graph and reasoning network modeling framework based on ontology and Natural Language Processing (NLP), to facilitate the efficient knowledge exploration from literature abstract. In this framework, a representation ontology is proposed to characterize the literature abstract data into four knowledge elements (background, objectives, solutions, and findings), and NLP technology is used to extract the ontology instances from the abstract automatically. Based on the representation ontology, a four-space integrated knowledge graph is built using NLP technology. Then, reasoning network is generated according to the reasoning mechanism defined in the proposed ontology model. To validate the proposed framework, a case study is conducted to analyze the literature in the field of construction management. The case study proves that the proposed ontology model can be used to represent the knowledge embedded in the literatures’ abstracts, and the ontology elements can be automatically extracted by NLP models. The proposed framework can be an enhancement for the bibliometric analysis to explore more knowledge from the literature. © 2019 Elsevier Ltd;ScienceDirect;2019;10.1016/j.aei.2019.100959;Chen H., Luo X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068231884&doi=10.1016%2fj.aei.2019.100959&partnerID=40&md5=4e626a3b1b7d05ff874d8290add23a74;China, Hong Kong;"entity extraction; relation extraction; entity classification; semantic search";solution proposal;method;scholarly domain;1;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;enabling search and collaborative assembly of causal interactions extracted from multilingual and multi-domain free text;"Climate change; Computational linguistics; Food supply; Collaborative assembly; Domain machines; Food security; Knowledge graphs; Multi-disciplinary collaborations; Multiple languages; Research problems; Scientific information; Data mining";Many of the most pressing current research problems (e.g., public health, food security, or climate change) require multi-disciplinary collaborations. In order to facilitate this process, we propose a system that incorporates multidomain extractions of causal interactions into a single searchable knowledge graph. Our system enables users to search iteratively over direct and indirect connections in this knowledge graph, and collaboratively build causal models in real time. To enable the aggregation of causal information from multiple languages, we extend an open-domain machine reader to Portuguese. The new Portuguese reader extracts over 600 thousand causal statements from 120 thousand Portuguese publications with a precision of 62%, which demonstrates the value of mining multilingual scientific information. © 2019 The Association for Computational Linguistics.;ACL;2019;;Barbosa G.C.G., Wong Z., Hahn-Powell G., Bell D., Sharp R., Valenzuela-Escarcega M.A., Surdeanu M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085641989&partnerID=40&md5=6d5935ab7701707075be83b7e9341332;Brazil, United States;semantic search;solution proposal;tool;scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;mining scholarly publications for scientific knowledge graph construction;"Deep learning; Knowledge representation; Learning systems; Natural language processing systems; Text mining; Automatically generated; Knowledge extraction; Learning methods; NAtural language processing; Preliminary approach; Scholarly publication; Scientific knowledge; State of the art; Semantic Web";In this paper, we present a preliminary approach that uses a set of NLP and Deep Learning methods for extracting entities and relationships from research publications and then integrates them in a Knowledge Graph. More specifically, we (i) tackle the challenge of knowledge extraction by employing several state-of-the-art Natural Language Processing and Text Mining tools, (ii) describe an approach for integrating entities and relationships generated by these tools, and (iii) analyse an automatically generated Knowledge Graph including 10, 425 entities and 25, 655 relationships in the field of Semantic Web. © Springer Nature Switzerland AG 2019.;Scopus;2019;10.1007/978-3-030-32327-1_2;Buscaldi D., Dessì D., Motta E., Osborne F., Reforgiato Recupero D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075566176&doi=10.1007%2f978-3-030-32327-1_2&partnerID=40&md5=145cac61036ad6ac137f15eeeba4d5cf;France, United Kingdom, Italy;"entity extraction; relation extraction; entity linking";solution proposal;method;scholarly domain;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Journal Article;understanding horizon 2020 data: a knowledge graph-based approach;"Graph analytics; Horizon 2020; Keyphrase extraction; Knowledge graph; Named entity recognition; Natural language processing; Text mining; Unsupervised learning";This paper aims to meaningfully analyse the Horizon 2020 data existing in the CORDIS repository of EU, and accordingly offer evidence and insights to aid organizations in the formulation of consortia that will prepare and submit winning research proposals to forthcoming calls. The analysis is performed on aggregated data concerning 32,090 funded projects, 34,295 organizations participated in them, and 87,067 public deliverables produced. The modelling of data is performed through a knowledge graph-based approach, aiming to semantically capture existing relationships and reveal hidden information. The main contribution of this work lies in the proper utilization and orchestration of keyphrase extraction and named entity recognition models, together with meaningful graph analytics on top of an efficient graph database. The proposed approach enables users to ask complex questions about the interconnection of various entities related to previously funded research projects. A set of representative queries demonstrating our data representation and analysis approach are given at the end of the paper. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Scopus;2021;10.3390/app112311425;Giarelis N., Karacapilidis N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120804638&doi=10.3390%2fapp112311425&partnerID=40&md5=d88d8948b6df9ecebd3d7aeebb369725;Greece;entity extraction;solution proposal;method;scholarly domain;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;knowledge graph construction and intelligent question answering on science and technology intermediary service;"Information overload; Information retrieval; Intelligent question answering technology; Knowledge graph; Natural language processing";With the rapid development of the Internet, while it facilitates users to obtain information, it also increases information overload. Although a lot of data have been divided into categories, it is still a big challenge to retrieve effective information from thousands of categories and their subcategories. For professional business, we need more efficient information organization and interactive interface to reduce the complexity of information retrieval. This paper designs an intelligent question-and-answer system for science and technology intermediary services based on knowledge graphs, which uses knowledge graphs to store domain data, combines intelligent question-and-answer technology and website design technology to realize efficient information query. On the basis of building the knowledge graph database of professional domain, the problem of information efficient search is effectively solved by combining natural language processing with relational graph. © 2021 IEEE.;IEEE;2021;10.1109/prai53619.2021.9551099;Feng S., Tu Z., Huang M., Wu Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117951124&doi=10.1109%2fPRAI53619.2021.9551099&partnerID=40&md5=f075c34b5d44f2b900f575d32428fa4c;China;question answering;solution proposal;tool;scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;intelligent question answering system based on entrepreneurial incubation knowledge graph;"Business incubation; Intelligent questions and answers; Knowledge graph; Natural language processing";With the development of science and technology, the importance of innovation for the development of science and technology has become more and more important. In the current era of information explosion, in order to meet the needs of existing enterprises and individuals for obtaining entrepreneurial information, this system has designed an intelligent question-and-answer system based on the entrepreneurial incubation knowledge graph. The system locates the field of innovation, uses crawler software to crawl data in the field of entrepreneurial incubation to construct a knowledge graph, and uses natural language to conduct man-machine dialogue to query and solve related problems of entrepreneurial incubation. The system stores massive amounts of data in the Neo4j graph database, and uses a pattern matching algorithm to connect the natural language input by the user with the knowledge base entity to classify and query the problem. This system has special practical value in the intelligent question answering system of the knowledge graph in the field of entrepreneurial incubation. © 2021 IEEE.;IEEE;2021;10.1109/prai53619.2021.9551028;Feng S., Chen H., Huang M., Wu Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117950989&doi=10.1109%2fPRAI53619.2021.9551028&partnerID=40&md5=2e295cc636cd7ccebba79863c0e65b62;China;question answering;solution proposal;tool;business;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;sentence, phrase, and triple annotations to build a knowledge graph of natural language processing contributions - a trial dataset;"Knowledge representation; Natural language processing; Open science graphs; Scholarly knowledge graphs; Semantic publishing";"This work aims to normalize the NlpContributions scheme (henceforward, NlpContributionGraph) to structure, directly from article sentences, the contributions information in Natural Language Processing (NLP) scholarly articles via a two-stage annotation methodology: 1) pilot stage - to define the scheme (described in prior work); and 2) adjudication stage - to normalize the graphing model (the focus of this paper). We re-annotate, a second time, the contributions-pertinent information across 50 prior-annotated NLP scholarly articles in terms of a data pipeline comprising: contribution-centered sentences, phrases, and triple statements. To this end, specifically, care was taken in the adjudication annotation stage to reduce annotation noise while formulating the guidelines for our proposed novel NLP contributions structuring and graphing scheme. The application of NlpContributionGraph on the 50 articles resulted finally in a dataset of 900 contribution-focused sentences, 4,702 contribution-information-centered phrases, and 2,980 surface-structured triples. The intra-annotation agreement between the first and second stages, in terms of F1-score, was 67.92% for sentences, 41.82% for phrases, and 22.31% for triple statements indicating that with increased granularity of the information, the annotation decision variance is greater. NlpContributionGraph has limited scope for structuring scholarly contributions compared with STEM (Science, Technology, Engineering, and Medicine) scholarly knowledge at large. Further, the annotation scheme in this work is designed by only an intra-annotator consensus - a single annotator first annotated the data to propose the initial scheme, following which, the same annotator reannotated the data to normalize the annotations in an adjudication stage. However, the expected goal of this work is to achieve a standardized retrospective model of capturing NLP contributions from scholarly articles. This would entail a larger initiative of enlisting multiple annotators to accommodate different worldviews into a ""single""set of structures and relationships as the final scheme. Given that the initial scheme is first proposed and the complexity of the annotation task in the realistic timeframe, our intra-annotation procedure is well-suited. Nevertheless, the model proposed in this work is presently limited since it does not incorporate multiple annotator worldviews. This is planned as future work to produce a robust model. We demonstrate NlpContributionGraph data integrated into the Open Research Knowledge Graph (ORKG), a next-generation KG-based digital library with intelligent computations enabled over structured scholarly knowledge, as a viable aid to assist researchers in their day-to-day tasks. NlpContributionGraph is a novel scheme to annotate research contributions from NLP articles and integrate them in a knowledge graph, which to the best of our knowledge does not exist in the community. Furthermore, our quantitative evaluations over the two-stage annotation tasks offer insights into task difficulty. © 2021 2021 Jennifer D'Souza et al., published by Sciendo.";Scopus;2021;10.2478/jdis-2021-0023;D'Souza J., Auer S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106371118&doi=10.2478%2fjdis-2021-0023&partnerID=40&md5=22f759dd00e93bc56353f741f8a1e3b3;Germany;ontology construction;solution proposal;method;scholarly domain;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;shall i work with them a knowledge graph-based approach for predicting future research collaborations;"Document representation; Future research collaborations; Graph kernels; Knowledge graph; Link prediction; Natural language processing; Word embeddings";We consider the prediction of future research collaborations as a link prediction problem applied on a scientific knowledge graph. To the best of our knowledge, this is the first work on the prediction of future research collaborations that combines structural and textual information of a scientific knowledge graph through a purposeful integration of graph algorithms and natural language processing techniques. Our work: (i) investigates whether the integration of unstructured textual data into a single knowledge graph affects the performance of a link prediction model, (ii) studies the effect of previously proposed graph kernels based approaches on the performance of an ML model, as far as the link prediction problem is concerned, and (iii) proposes a three-phase pipeline that enables the exploitation of structural and textual information, as well as of pre-trained word embeddings. We benchmark the proposed approach against classical link prediction algorithms using accuracy, recall, and precision as our performance metrics. Finally, we empirically test our approach through various feature combinations with respect to the link prediction problem. Our experimentations with the new COVID-19 Open Research Dataset demonstrate a significant improvement of the abovementioned performance metrics in the prediction of future research collaborations. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Scopus;2021;10.3390/e23060664;Kanakaris N., Giarelis N., Siachos I., Karacapilidis N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107448712&doi=10.3390%2fe23060664&partnerID=40&md5=1e3a4e14630a8d17f090bd1d110712bc;Greece;link prediction;validation research;method;scholarly domain;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;generating knowledge graphs by employing natural language processing and machine learning techniques within the scholarly domain;"Graphic methods; Hybrid systems; Knowledge representation; Machine learning; Text mining; Explicit representation; Machine learning methods; Machine learning techniques; NAtural language processing; Scientific knowledge; Scientific literature; Scientific researches; Technological infrastructure; Natural language processing systems";The continuous growth of scientific literature brings innovations and, at the same time, raises new challenges. One of them is related to the fact that its analysis has become difficult due to the high volume of published papers for which manual effort for annotations and management is required. Novel technological infrastructures are needed to help researchers, research policy makers, and companies to time-efficiently browse, analyse, and forecast scientific research. Knowledge graphs i.e., large networks of entities and relationships, have proved to be effective solution in this space. Scientific knowledge graphs focus on the scholarly domain and typically contain metadata describing research publications such as authors, venues, organizations, research topics, and citations. However, the current generation of knowledge graphs lacks of an explicit representation of the knowledge presented in the research papers. As such, in this paper, we present a new architecture that takes advantage of Natural Language Processing and Machine Learning methods for extracting entities and relationships from research publications and integrates them in a large-scale knowledge graph. Within this research work, we (i) tackle the challenge of knowledge extraction by employing several state-of-the-art Natural Language Processing and Text Mining tools, (ii) describe an approach for integrating entities and relationships generated by these tools, (iii) show the advantage of such an hybrid system over alternative approaches, and (vi) as a chosen use case, we generated a scientific knowledge graph including 109,105 triples, extracted from 26,827 abstracts of papers within the Semantic Web domain. As our approach is general and can be applied to any domain, we expect that it can facilitate the management, analysis, dissemination, and processing of scientific knowledge. © 2020 Elsevier B.V.;ScienceDirect;2021;10.1016/j.future.2020.10.026;Dessì D., Osborne F., Reforgiato Recupero D., Buscaldi D., Motta E.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095915737&doi=10.1016%2fj.future.2020.10.026&partnerID=40&md5=453481b30edbb795ab1ee9b9f6564330;Germany, France, United Kingdom, Italy;"entity extraction; relation extraction";solution proposal;method;scholarly domain;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;esra: explainable scientific research assistant;"Computational linguistics; Paper; Graph visualization; Knowledge graphs; Literature search; Query visualizations; Related entities; Scientific researches; Search process; Search system; WEB application; Web applications; Knowledge graph";We introduce Explainable Scientific Research Assistant (ESRA), a literature discovery platform that augments search results with relevant details and explanations, aiding users in understanding more about their queries and the returned papers beyond existing literature search systems. Enabled by a knowledge graph we extracted from abstracts of 23k papers on the arXiv’s cs.CL category, ESRA provides three main features: explanation (for why a paper is returned to the user), list of facts (that are relevant to the query), and graph visualization (drawing connections between the query and each paper with surrounding related entities). The experimental results with humans involved show that ESRA can accelerate the users’ search process with paper explanations and helps them better explore the landscape of the topics of interest by exploiting the underlying knowledge graph. We provide the ESRA web application at http://esra.cp.eng.chula.ac.th/. © 2021 Association for Computational Linguistics;ACL;2021;;Hongwimol P., Kehasukcharoen P., Laohawarutchai P., Lertvittayakumjorn P., Ng A.B., Lai Z., Liu T., Vateekul P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118942127&partnerID=40&md5=b67cdbd3d46527806d507dbc19ad92bf;United Kingdom, Thailand, United States;"entity extraction; relation extraction; semantic search";validation research;tool;scholarly domain;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;1
Conference Paper;entity-based knowledge graph information retrieval for biomedical articles;"BERT; Entity recognition; Knowledge graph; Natural language processing";In this paper, we present an information retrieval system on a corpus of scientific articles related to COVID-19 and biomedical. We build a heterogeneous entity-based knowledge graph network, where edges are shared between biomedical entities and paper names, where entities appear in abstract of the paper. The biomedical entities are derived from the abstract of the scientific articles using a fine-tuned Bio-BERT model. For a user query, entities are derived using a fine-tuned Bio-BERT model and then semantic similarity to query is employed for the return of the top-most relevant papers on the titles. We also provide a small set of results for the information retrieval system. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.;Scopus;2021;10.1007/978-981-16-1089-9_62;Prasad V.K., Bharti S., Koganti N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111957442&doi=10.1007%2f978-981-16-1089-9_62&partnerID=40&md5=f8c07eceb3d54c4596d7a4a702961339;India;semantic search;solution proposal;tool;"health; scholarly domain";0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;learning embeddings from scientific corpora using lexical, grammatical and semantic information;"Convolutional neural networks; Embeddings; Neural networks; NLP; Text classification";Natural language processing can assist scientists to leverage the increasing amount of information contained in scientific bibliography. The current trend, based on deep learning and embeddings, uses representations at the (sub)word level that require large amounts of training data and neural architectures with millions of parameters to learn successful language models, like BERT. However, these representations may not be well suited for the scientific domain, where it is common to find complex terms, e.g. multi-word, with a domain-specific meaning in a very specific context. In this paper we propose an approach based on a linguistic analysis of the corpus using a knowledge graph to learn representations that can unambiguously capture such terms and their meaning. We learn embeddings from different linguistic annotations on the text and evaluate them through a classification task over the SciGraph taxonomy, showing that our representations outperform (sub)word-level approaches. Copyright © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).;Scopus;2019;;Garcia-Silva A., Denaux R., Gomez-Perez J.M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077823532&partnerID=40&md5=532805ed6a552718a6e8de3f1b4c3abc;Spain;"augmented language models; text classification";validation research;technique;scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;mining scholarly data for fine-grained knowledge graph construction;"Knowledge extraction; Knowledge graph; Natural language processing; Scholarly data; Semantic web";Knowledge graphs (KG) are large networks of entities and relationships, typically expressed as RDF triples, relevant to a specific domain or an organization. Scientific Knowledge Graphs (SKGs) focus on the scholarly domain and typically contain metadata describing research publications such as authors, venues, organizations, research topics, and citations. The next big challenge in this field regards the generation of SKGs that also contain an explicit representation of the knowledge presented in research publications. In this paper, we present a preliminary approach that uses a set of NLP and Deep Learning methods for extracting entities and relationships from research publications, and then integrates them in a KG. More specifically, we i) tackle the challenge of knowledge extraction by employing several state-of-the-art Natural Language Processing and Text Mining tools, ii) describe an approach for integrating entities and relationships generated by these tools, iii) analyze an automatically generated Knowledge Graph including 10 425 entities and 25 655 relationships derived from 12 007 publications in the field of Semantic Web, and iv) discuss some open problems that have not been solved yet. © 2019 CEUR-WS. All rights reserved.;Scopus;2019;;Buscaldi D., Dessì D., Motta E., Osborne F., Recupero D.R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067893695&partnerID=40&md5=967dee119fdc7b631fbde9a4e7380e9f;France, United Kingdom, Italy;"entity extraction; relation extraction";solution proposal;method;scholarly domain;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;answering elementary science questions by constructing coherent scenes using background knowledge;"Natural language processing systems; Back-ground knowledge; Competitive algorithms; Elementary science; Implicit informations; Knowledge graphs; Linguistic resources; Mental pictures; Multiple choice questions; Knowledge management";"Much of what we understand from text is not explicitly stated. Rather, the reader uses his/her knowledge to fill in gaps and create a coherent, mental picture or ""scene"" depicting what text appears to convey. The scene constitutes an understanding of the text, and can be used to answer questions that go beyond the text. Our goal is to answer elementary science questions, where this requirement is pervasive; A question will often give a partial description of a scene and ask the student about implicit information. We show that by using a simple ""knowledge graph"" representation of the question, we can leverage several large-scale linguistic resources to provide missing background knowledge, somewhat alleviating the knowledge bottleneck in previous approaches. The coherence of the best resulting scene, built from a question/answer-candidate pair, reflects the confidence that the answer candidate is correct, and thus can be used to answer multiple choice questions. Our experiments show that this approach outperforms competitive algorithms on several datasets tested. The significance of this work is thus to show that a simple ""knowledge graph"" representation allows a version of ""interpretation as scene construction"" to be made viable. © 2015 Association for Computational Linguistics.";ACL;2015;10.18653/v1/d15-1236;Li Y., Clark P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959867303&doi=10.18653%2fv1%2fd15-1236&partnerID=40&md5=ca35d2968fd72770c7eabd9c013c4b46;United States;question answering;validation research;tool;scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;learning knowledge graphs for question answering through conversational dialog;"Computational linguistics; Domain model; General knowledge; Knowledge graphs; Natural languages; Query expansion; Question Answering; Question answering systems; Relation-based; Natural language processing systems";We describe how a question-answering system can learn about its domain from conversational dialogs. Our system learns to relate concepts in science questions to propositions in a fact corpus, stores new concepts and relations in a knowledge graph (KG), and uses the graph to solve questions. We are the first to acquire knowledge for question-answering from open, natural language dialogs without a fixed ontology or domain model that predetermines what users can say. Our relation-based strategies complete more successful dialogs than a query expansion baseline, our taskdriven relations are more effective for solving science questions than relations from general knowledge sources, and our method is practical enough to generalize to other domains. © 2015 Association for Computational Linguistics.;ACL;2015;10.3115/v1/n15-1086;Hixon B., Clark P., Hajishirzi H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959088414&doi=10.3115%2fv1%2fn15-1086&partnerID=40&md5=064a06b29ed8bf9c581f48ad5a1a98aa;United States;"conversational interfaces; question answering";validation research;tool;scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;on the impact of knowledge-based linguistic annotations in the quality of scientific embeddings;Natural language processing, Linguistic analysis, Knowledge graphs, Embeddings;In essence, embedding algorithms work by optimizing the distance between a word and its usual context in order to generate an embedding space that encodes the distributional representation of words. In addition to single words or word pieces, other features which result from the linguistic analysis of text, including lexical, grammatical and semantic information, can be used to improve the quality of embedding spaces. However, until now we did not have a precise understanding of the impact that such individual annotations and their possible combinations may have in the quality of the embeddings. In this paper, we conduct a comprehensive study on the use of explicit linguistic annotations to generate embeddings from a scientific corpus and quantify their impact in the resulting representations. Our results show how the effect of such annotations in the embeddings varies depending on the evaluation task. In general, we observe that learning embeddings using linguistic annotations contributes to achieve better evaluation results.;ScienceDirect;2021;10.1016/j.future.2021.02.019;Andres Garcia-Silva and Ronald Denaux and Jose Manuel Gomez-Perez;https://www.sciencedirect.com/science/article/pii/S0167739X21000716;Spain;augmented language models;validation research;technique;scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Journal Article;zero-shot text classification via knowledge graph embedding for social media data;"Bit error rate; Data models; Internet of Things; internet of things; knowledge graph; Natural language processing; Predictive models; Sensors; social media data analysis.; Social networking (online); Task analysis; zero-shot learning";"The idea of &#x2018;citizen sensing&#x2019; and &#x2018;human as sensors&#x2019; is crucial for social Internet of Things, an integral part of cyber-physical-social systems (CPSS). Social media data, which can be easily collected from the social world, has become a valuable resource for research in many different disciplines, e.g. crisis/disaster assessment, social event detection, or the recent COVID-19 analysis. Useful information, or knowledge derived from social data, could better serve the public if it could be processed and analyzed in more efficient and reliable ways. Advances in deep neural networks have significantly improved the performance of many social media analysis tasks. However, deep learning models typically require a large amount of labeled data for model training, while most CPSS data is not labeled, making it impractical to build effective learning models using traditional approaches. In addition, the current state-of-the-art, pre-trained Natural Language Processing (NLP) models do not make use of existing knowledge graphs, thus often leading to unsatisfactory performance in real-world applications. To address the issues, we propose a new zero-shot learning method which makes effective use of existing knowledge graphs for the classification of very large amounts of social text data. Experiments were performed on a large, real-world tweet dataset related to COVID-19, the evaluation results show that the proposed method significantly outperforms six baseline models implemented with state-of-the-art deep learning models for NLP. IEEE";IEEE;2021;10.1109/jiot.2021.3093065;Chen Q., Wang W., Huang K., Coenen F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112209978&doi=10.1109%2fJIOT.2021.3093065&partnerID=40&md5=d17737c7c4e4913b2482f18edd62be0a;China;"text classification; knowledge graph embedding";validation research;technique;social media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph analysis of russian trolls;"Entity extraction; Relationship analysis of troll tweets; Sentiment analysis; Triple extraction";Social media, such as Twitter, have been exploited by trolls to manipulate political discourse and spread disinformation during the 2016 US Presidential Election. Trolls are users of social media accounts created with intentions to influence the public opinion by posting or reposting messages containing misleading or inflammatory information with malicious intentions. There has been previous research that focused on troll detection using Machine Learning approaches, and troll understanding using visualizations, such as word clouds. In this paper, we focus on the content analysis of troll tweets to identify the major entities mentioned and the relationships among these entities, to understand the events and statements mentioned in Russian Troll tweets coming from the Internet Research Agency (IRA), a troll factory allegedly financed by the Russian government. We applied several NLP techniques to develop Knowledge Graphs to understand the relationships of entities, often mentioned by dispersed trolls, and thus hard to uncover. This integrated KG helped to understand the substance of Russian Trolls' influence in the election. We identified three clusters of troll tweet content: one consisted of information supporting Donald Trump, the second for exposing and attacking Hillary Clinton and her family, and the third for spreading other inflammatory content. We present the observed sentiment polarization using sentiment analysis for each cluster and derive the concern index for each cluster, which shows a measurable difference between the presidential candidates that seems to have been reflected in the election results. Copyright © 2021 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved;Scopus;2021;10.5220/0010605403350342;Li C.-Y., Chun S.A., Geller J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111720759&doi=10.5220%2f0010605403350342&partnerID=40&md5=818594d70343c5edec45007d1aa3d1c9;United States;"semantic search; text analysis";solution proposal;method;social media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;disbot: a portuguese disaster support dynamic knowledge chatbot;"Chatbots; Community resilience; Disaster management; Knowledge graphs; Natural language processing; Situational awareness";This paper presents DisBot, the first Portuguese speaking chatbot that uses social media retrieved knowledge to support citizens and first-responders in disaster scenarios, in order to improve community resilience and decision-making. It was developed and tested using Design Science Research Methodology (DSRM), being progressively matured with field specialists through several design and development iterations. DisBot uses a state-of-the-art Dual Intent Entity Transformer (DIET) architecture to classify user intents, and makes use of several dialogue policies for managing user conversations, as well as storing relevant information to be used in further dialogue turns. To generate responses, it uses real-world safety knowledge, and infers a dynamic knowledge graph that is dynamically updated in real-time by a disaster-related knowledge extraction tool, presented in previous works. Through its development iterations, DisBot has been validated by field specialists, who have considered it to be a valuable asset in disaster management. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.;Scopus;2020;10.3390/app10249082;Boné J., Ferreira J.C., Ribeiro R., Cadete G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098055192&doi=10.3390%2fapp10249082&partnerID=40&md5=ba86e8919d8fffabf70521c05b368405;Portugal;conversational interfaces;validation research;tool;"social media; public sector";0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;cometa: a corpus for medical entity linking in the social media;"Computational linguistics; Social networking (online); Terminology; Benchmark experiments; Complex nature; Knowledge graphs; Medical knowledge; Performance gaps; Property; SNOMED-CT; Social media; Knowledge graph";Whilst there has been growing progress in Entity Linking (EL) for general language, existing datasets fail to address the complex nature of health terminology in layman's language. Meanwhile, there is a growing need for applications that can understand the public's voice in the health domain. To address this we introduce a new corpus called COMETA, consisting of 20k English biomedical entity mentions from Reddit expert-annotated with links to SNOMED CT, a widely-used medical knowledge graph. Our corpus satisfies a combination of desirable properties, from scale and coverage to diversity and quality, that to the best of our knowledge has not been met by any of the existing resources in the field. Through benchmark experiments on 20 EL baselines from string- to neural-based models we shed light on the ability of these systems to perform complex inference on entities and concepts under 2 challenging evaluation scenarios. Our experimental results on COMETA illustrate that no golden bullet exists and even the best mainstream techniques still have a significant performance gap to fill, while the best solution relies on combining different views of data. © 2020 Association for Computational Linguistics;ACL;2020;;Basaldella M., Liu F., Shareghi E., Collier N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104050301&partnerID=40&md5=171cac0eda6616793ff18f4f90b8ac14;United Kingdom;entity linking;validation research;resource;"social media; health";0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;entity-aware image caption generation;"Convolutional neural networks; Graph algorithms; Graphic methods; Inference engines; Natural language processing systems; Benchmark datasets; Collective inference; Effective approaches; Evaluation metrics; Image descriptions; Knowledge graphs; Short term memory; Specific information; Long short-term memory";Current image captioning approaches generate descriptions which lack specific information, such as named entities that are involved in the images. In this paper we propose a new task which aims to generate informative image captions, given images and hashtags as input. We propose a simple but effective approach to tackle this problem. We first train a convolutional neural networks - long short term memory networks (CNN-LSTM) model to generate a template caption based on the input image. Then we use a knowledge graph based collective inference algorithm to fill in the template with specific named entities retrieved via the hashtags. Experiments on a new benchmark dataset collected from Flickr show that our model generates news-style image descriptions with much richer information. Our model outperforms unimodal baselines significantly with various evaluation metrics. 1 © 2018 Association for Computational Linguistics;ACL;2020;;Lu D., Whitehead S., Huang L., Ji H., Chang S.-F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067264580&partnerID=40&md5=c1864df7bbb9c6d1e6863614bad80a8c;United States;text generation;validation research;"technique; resource";social media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;zeroshot multimodal named entity disambiguation for noisy social media posts;"Computational linguistics; Knowledge based systems; External knowledge; Image caption; Knowledge graphs; Multimodal network; Named entities; Named entity disambiguations; State of the art; Training sets; Social networking (online)";We introduce the new Multimodal Named Entity Disambiguation (MNED) task for multimodal social media posts such as Snapchat or Instagram captions, which are composed of short captions with accompanying images. Social media posts bring significant challenges for disambiguation tasks because 1) ambiguity not only comes from polysemous entities, but also from inconsistent or incomplete notations, 2) very limited context is provided with surrounding words, and 3) there are many emerging entities often unseen during training. To this end, we build a new dataset called SnapCaptionsKB, a collection of Snapchat image captions submitted to public and crowd-sourced stories, with named entity mentions fully annotated and linked to entities in an external knowledge base. We then build a deep zeroshot multimodal network for MNED that 1) extracts contexts from both text and image, and 2) predicts correct entity in the knowledge graph embeddings space, allowing for zeroshot disambiguation of entities unseen in training set as well. The proposed model significantly outperforms the state-of-the-art text-only NED models, showing efficacy and potentials of the MNED task. © 2018 Association for Computational Linguistics;ACL;2018;;Moon S., Neves L., Carvalho V.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063072770&partnerID=40&md5=62fa27e5949feb05727ce374c5b53d84;United States;entity linking;validation research;"technique; resource";social media;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph construction for intelligent analysis of social networking user opinion;"Sentiment analysis; Natural language processing; Knowledge graph; User opinion";Microblogging is a popular social networking tool on which people tend to express their views and opinions. As such, the massive data on microblogging platforms mean abundant research value to social science researchers. To help them better analyze these data, a framework for understanding diverse user opinions and identifying complex relationships in the form of knowledge graphs is proposed in this paper. The two main tasks in the framework are sentiment analysis and knowledge graph construction. In the first task, the Skip-gram model is employed to obtain the word embedding matrix and the Bi-LSTM model is adopted to perform stance classification. It is found in this paper that Bi-LSTM showed better performance in classifying different sentiments, compared with Naive Bayes and SnowNLP. In the second task, relations between different users are extracted from their micro-blogs through recognizing specific strings, and on this basis user attitudes are integrated into the knowledge extracted. A knowledge graph of user opinions is constructed with the Neo4J tool. With the knowledge extracted by this framework, social science researchers can more easily observe rules of perspective communication and perform further analysis of the data.;WoS;2020;10.1007/978-3-030-34986-8_17;Xie T,Yang Y,Li Q,Liu X,Wang H;http://dx.doi.org/10.1007/978-3-030-34986-8_17;China;"text analysis; relation extraction";solution proposal;method;social media;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;automatic detection of covid-19 vaccine misinformation with graph link prediction;"COVID-19; knowledge graph embedding; Machine learning; Natural Language Processing; Social Media; vaccine misinformation";Enormous hope in the efficacy of vaccines became recently a successful reality in the fight against the COVID-19 pandemic. However, vaccine hesitancy, fueled by exposure to social media misinformation about COVID-19 vaccines became a major hurdle. Therefore, it is essential to automatically detect where misinformation about COVID-19 vaccines on social media is spread and what kind of misinformation is discussed, such that inoculation interventions can be delivered at the right time and in the right place, in addition to interventions designed to address vaccine hesitancy. This paper is addressing the first step in tackling hesitancy against COVID-19 vaccines, namely the automatic detection of known misinformation about the vaccines on Twitter, the social media platform that has the highest volume of conversations about COVID-19 and its vaccines. We present COVAXLIES, a new dataset of tweets judged relevant to several misinformation targets about COVID-19 vaccines on which a novel method of detecting misinformation was developed. Our method organizes COVAXLIES in a Misinformation Knowledge Graph as it casts misinformation detection as a graph link prediction problem. The misinformation detection method detailed in this paper takes advantage of the link scoring functions provided by several knowledge embedding methods. The experimental results demonstrate the superiority of this method when compared with classification-based methods, widely used currently. © 2021 Elsevier Inc.;ScienceDirect;2021;10.1016/j.jbi.2021.103955;Weinzierl M.A., Harabagiu S.M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119576283&doi=10.1016%2fj.jbi.2021.103955&partnerID=40&md5=a577d49a20361fe63db6c4e1c0c1b654;United States;"link prediction; knowledge graph embedding";validation research;"technique; resource";"social media; health";0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a framework to extract biomedical knowledge from gluten-related tweets: the case of dietary concerns in digital era;"Graph mining; Health for informatics; Machine learning; Social media; Sociome profiling; Text mining";"Big data importance and potential are becoming more and more relevant nowadays, enhanced by the explosive growth of information volume that is being generated on the Internet in the last years. In this sense, many experts agree that social media networks are one of the internet areas with higher growth in recent years and one of the fields that are expected to have a more significant increment in the coming years. Similarly, social media sites are quickly becoming one of the most popular platforms to discuss health issues and exchange social support with others. In this context, this work presents a new methodology to process, classify, visualise and analyse the big data knowledge produced by the sociome on social media platforms. This work proposes a methodology that combines natural language processing techniques, ontology-based named entity recognition methods, machine learning algorithms and graph mining techniques to: (i) reduce the irrelevant messages by identifying and focusing the analysis only on individuals and patient experiences from the public discussion; (ii) reduce the lexical noise produced by the different ways in how users express themselves through the use of domain ontologies; (iii) infer the demographic data of the individuals through the combined analysis of textual, geographical and visual profile information; (iv) perform a community detection and evaluate the health topic study combining the semantic processing of the public discourse with knowledge graph representation techniques; and (v) gain information about the shared resources combining the social media statistics with the semantical analysis of the web contents. The practical relevance of the proposed methodology has been proven in the study of 1.1 million unique messages from >400,000 distinct users related to one of the most popular dietary fads that evolve into a multibillion-dollar industry, i.e., gluten-free food. Besides, this work analysed one of the least research fields studied on Twitter concerning public health (i.e., the allergies or immunology diseases as celiac disease), discovering a wide range of health-related conclusions. © 2021 The Author(s)";ScienceDirect;2021;10.1016/j.artmed.2021.102131;Pérez-Pérez M., Igrejas G., Fdez-Riverola F., Lourenço A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114659514&doi=10.1016%2fj.artmed.2021.102131&partnerID=40&md5=f2518ad0b1f7b62c04cea3d38dff886f;Spain, Portugal;semantic search;solution proposal;method;"social media; health";0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;recognizing mentions of adverse drug reaction in social media using knowledge-infused recurrent models;"Computational linguistics; Recurrent neural networks; Social networking (online); Adverse drug reactions; Annotation tool; Context dependent; Expert annotations; Highly accurate; Knowledge graphs; Recurrent models; Recurrent neural network (RNN); Pharmacodynamics";Recognizing mentions of Adverse Drug Reactions (ADR) in social media is challenging: ADR mentions are contextdependent and include long, varied and unconventional descriptions as compared to more formal medical symptom terminology. We use the CADEC corpus to train a recurrent neural network (RNN) transducer, integrated with knowledge graph embeddings of DBpedia, and show the resulting model to be highly accurate (93.4 F1). Furthermore, even when lacking high quality expert annotations, we show that by employing an active learning technique and using purpose built annotation tools, we can train the RNN to perform well (83.9 F1). © 2017 Association for Computational Linguistics.;ACL;2017;10.18653/v1/e17-1014;Stanovsky G., Gruhl D., Mendes P.N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021649640&doi=10.18653%2fv1%2fe17-1014&partnerID=40&md5=be3fb20651f6379666265ea716297679;Israel, United States;"augmented language models; text classification";validation research;technique;"social media; health";0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;big open-source social science: capabilities and methodology for automating social science analytics;"automated social science; multi-modal data fusion; social network analysis; Social situational awareness";"Currently, obtaining reliable situational awareness of the social landscape is an arduous, lengthy process involving manual analyses by social scientists. These traditional methods do not scale to the speed and diversity required by DoD operations or the high-speed, international business model in today's corporate environment. Conversely, ""big data"" easily scales to meet these challenges but lacks the rigor of social science theory. We present Big Open-Source Social Science (BOSSS), a research and development project that leverages the strengths of social- and computer-science technology to address the operational need for rapid and reliable human-landscape situational-awareness. BOSSS iteratively filters, navigates, and summarizes diverse open-source data to characterize a local population's social structure, conflicts, cleavages, affinities, and animosities. BOSSS automatically scrapes open-access data from the web and performs natural language processing to populate a knowledge graph with a custom schema. BOSSS then mines the graph to extract key, theory-agnostic socialscience principles of human inter-relations and dynamics: Homophily, stratification, sentiment, and conflict. Automated quantitative social-network analysis provides up-to-date indicators of trends or anomalies within the local population's social landscape. BOSSS's emerging technology will provide a dramatic reduction in the cognitive workload for the next generation of analysts and will facilitate more rapid situational awareness both for deployed soldiers and private companies conducting operations abroad. © 2018 SPIE. Downloading of the abstract is permitted for personal use only.";Scopus;2018;10.1117/12.2306500;Palladino A., Bienenstock E.J., George C.A., Moore K.E.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049673329&doi=10.1117%2f12.2306500&partnerID=40&md5=d256fa38de4f87c28170e06232b570d6;United States;"entity extraction; relation extraction; semantic search";solution proposal;method;social science;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;implementation of intelligent question answering system based on basketball knowledge graph;"knowledge graph; NBA; question and answer";Currently most search engines query based on keywords or question-template matching. But for the retrieval about basketball or NBA, there are always too many feedback results, low accuracy and lack of intelligence. In this paper, an intelligent question answering system based on NBA basketball knowledge graph is implemented. Some methods are used in the question analysis module in the system, including question similarity calculation, named entity recognition, entity similarity calculation, and question-to-entity attribute mapping. In answer generation module of the system, a multi-strategy answer generation method is proposed. The experimental results show that our approach by combined with natural language processing technology and domain knowledge graph can well identify the input questions by user, and accurately feedback the answers to user queries. © 2019 IEEE.;IEEE;2019;10.1109/iaeac47372.2019.8997747;Li Y., Cao J., Wang Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081172990&doi=10.1109%2fIAEAC47372.2019.8997747&partnerID=40&md5=1d65134ce3afda9c04939a0ba7853928;China;question answering;solution proposal;method;sports;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;extending cross-domain knowledge bases with long tail entities using web table data;"Data integration; Database systems; Knowledge based systems; Natural language processing systems; Sports; Back-ground knowledge; Football players; Knowledge basis; Knowledge graphs; Natural language understanding; Question Answering; Schema matching; Unknown entities; Search engines";Cross-domain knowledge bases such as YAGO, DBpedia, or the Google Knowledge Graph are being used as background knowledge within an increasing range of applications including web search, data integration, natural language understanding, and question answering. The usefulness of a knowledge base for these applications depends on its completeness. Relational HTML tables from the Web cover a wide range of topics and describe very specific long tail entities, such as small villages, less-known football players, or obscure songs. This systems and applications paper explores the potential of web table data for the task of completing cross-domain knowledge bases with descriptions of formerly unknown entities. We present the first system that handles all steps that are necessary for this task: schema matching, row clustering, entity creation, and new detection. The evaluation of the system using a manually labeled gold standard shows that it can construct formerly unknown instances and their descriptions from table data with an average F1 score of 0.80. In a second experiment, we apply the system to a large corpus of web tables extracted from the Common Crawl. This experiment allows us to get an overall impression of the potential of web tables for augmenting knowledge bases with long tail entities. The experiment shows that we can augment the DBpedia knowledge base with descriptions of 14 thousand new football players as well as 187 thousand new songs. The accuracy of the facts describing these instances is 0.90. © 2019 Copyright held by the owner/author(s).;Scopus;2019;10.5441/002/edbt.2019.34;Oulabi Y., Bizer C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064894038&doi=10.5441%2f002%2fedbt.2019.34&partnerID=40&md5=bf85bd3debd53a39e154cd95e12ea48c;Germany;"entity extraction; entity classification";validation research;method;sports;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;question answering system based on tourism knowledge graph;"Big data; Graph Databases; Graphic methods; Information services; Knowledge representation; Natural language processing systems; Query processing; Tourism; User experience; Knowledge graphs; Named entity recognition; Natural language questions; Query statements; Question answering systems; Reasoning models; System performance evaluation; User satisfaction; Leisure industry";Nowadays tourism information services only provide users with massive and fragmented information returned by independent network search which makes users often need to spend a lot of time and energy to find what they really want from the massive data. As a result, route designing is very complicated. In view of this situation, this study builds a tourism knowledge graph based on neo4j and constructs a question answering system (QA). Also, we carry out the model and system performance evaluation, trying to improve the user satisfaction with query experience. According to the structure of question answering system (QA), this research designed and implemented named entity recognition (NER) model based on Bert-BiLSTM-CRF and matching reasoning model based on templates. With the above methods, natural language questions were successfully transformed into cypher query statements recognizable in graph database, and the corresponding answers will be captured and returned from tourism knowledge graph. According to the experiment, the method of Bert-BiLSTM-CRF obtains the state of art and QA system performs quickly and efficiently. For the purpose that artificial intelligence helps the development of tourism industry, this study has a certain significance. © Published under licence by IOP Publishing Ltd.;Scopus;2021;10.1088/1742-6596/1883/1/012064;Sui Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105480835&doi=10.1088%2f1742-6596%2f1883%2f1%2f012064&partnerID=40&md5=6424ea21c50ba1b4f92de5f8b4a59173;China;question answering;solution proposal;method;tourism;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;building a knowledge graph of vietnam tourism from text;"Co-reference resolution; Google search; Knowledge graph; Natural language processing; Triples extraction";Most data in the world is in form of text. Therefore, we can say text stores large amount of the knowledge of human beings. Extracting useful knowledge from text, however, is not a simple task. In this paper, we present a complete pipeline to extract knowledge from paragraph. This pipeline combines state-of-the-art systems in order to yield optimal results. There are some other Knowledge Graphs such as Google Knowledge Graph, YAGO, or DBpedia. Most of the data in these Knowledge Graphs is in English. On the other hand, the results from our system is used to build a new Knowledge Graph in Vietnamese of Vietnam Tourism. We use the rich resources language like English to process a low resources language like Vietnamese. We utilize the NLP tools of English such as Google translate, Stanford parser, Co-referencing, ClausIE, MinIE. We develop Google Search to find the text describing the entities in the Internet. This text is in Vietnamese. Then, we translate the Vietnamese text into English text and use English NLP tools to extract triples. Finally, we translate the triples back into Vietnamese and build the knowledge graph of Vietnam tourism. We conduct experiment and discover the advantages and disadvantages of our method. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.;Scopus;2021;10.1007/978-981-33-4069-5_1;Do P., Le H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103480870&doi=10.1007%2f978-981-33-4069-5_1&partnerID=40&md5=a009d3025a874d1a03d5478e9ec09636;Vietnam;"entity extraction; relation extraction; entity classification";solution proposal;method;tourism;1;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0
Conference Paper;research on tourism question answering system based on xi'an tourism knowledge graph;"Big data; Convolutional neural networks; Knowledge representation; Multilayer neural networks; Natural language processing systems; Attention mechanisms; Design and implements; Input layers; Knowledge graphs; Natural language questions; Professional fields; Question answering systems; Similarity calculation; Tourism";Question answering (QA) system provides a direct, efficient and accurate way for people to obtain information. At present, open domain QA systems such as Siri and Cortana are widely used in the general field, but they cannot meet the demand of some professional fields. This paper focuses on the background and needs of QA in the tourism field, researching the relevant technologies required for the implementation of QA system, and finally completes the construction of QA system based on the knowledge graph of tourism. The main research contents of this paper are as follows: 1.An algorithm to identify the tourism entities in questions is proposed according to the characteristics of the tourism entities. 2. Referring to the ideas of Liu et al., a convolutional neural network (CNN) model is introduced into attribute linking, but in order to improve the accuracy of attribute linking, we move the similarity calculation of questions and attributes from the outside of the model to the input layer of the model, and also introduce Attention mechanism. Integrate the technology of each module to design and implement a QA system for tourism. We experiment with the system on the constructed Xi'an tourism knowledge graph, and the results prove that the system we designed can answer the natural language questions raised by users about tourism. © Published under licence by IOP Publishing Ltd.;Scopus;2020;10.1088/1742-6596/1616/1/012090;Yang L., Cao H., Hao F., Zhang W., Ahmad M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090498054&doi=10.1088%2f1742-6596%2f1616%2f1%2f012090&partnerID=40&md5=474d6f60380c783424e083b07d32a932;China;question answering;solution proposal;tool;tourism;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;bert+vnkg: using deep learning and knowledge graph to improve vietnamese question answering system;"Bidirectional encoder representation from transformer (BERT); Deep learning; Knowledge graph; Long short-term memory (LSTM); Natural language processing; Question answering (QA); Vietnamese tourism";A question answering (QA) system based on natural language processing and deep learning is a prominent area and is being researched widely. The Long Short-Term Memory (LSTM) model that is a variety of Recurrent Neural Network (RNN) used to be popular in machine translation, and question answering system. However, that model still has certainly limited capabilities, so a new model named Bidirectional Encoder Representation from Transformer (BERT) emerged to solve these restrictions. BERT has more advanced features than LSTM and shows state-of-the-art results in many tasks, especially in multilingual question answering system over the past few years. Nevertheless, we tried applying multilingual BERT model for a Vietnamese QA system and found that BERT model still has certainly limitation in term of time and precision to return a Vietnamese answer. The purpose of this study is to propose a method that solved above restriction of multilingual BERT and applied for question answering system about tourism in Vietnam. Our method combined BERT and knowledge graph to enhance accurately and find quickly for an answer. We experimented our crafted QA data about Vietnam tourism on three models such as LSTM, BERT fine-tuned multilingual for QA (BERT for QA), and BERT+vnKG. As a result, our model outperformed two previous models in terms of accuracy and time. This research can also be applied to other fields such as finance, e-commerce, and so on. © 2020 Science and Information Organization.;Scopus;2020;10.14569/ijacsa.2020.0110761;Phan T.H.V., Do P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088985283&doi=10.14569%2fIJACSA.2020.0110761&partnerID=40&md5=a42476a896ca180e281da94e02c20014;Vietnam;"augmented language models; question answering";validation research;technique;tourism;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0
Conference Paper;dbtravel: a tourism-oriented semantic graph;"DBpedia; Name entity recognition; Wikitravel";We present DBtravel, a tourism-oriented knowledge graph generated from the collaborative travel site Wikitravel. Our approach takes advantage of the recommended guideline for contributors provided by Wikitravel and extracts the named entities available in Wikitravel Spanish entries by using a NLP pipeline. Compared to a manually annotated gold standard, results show that our approach reaches values for precision and recall around 80% for some sections of Wikitravel for the Spanish language. © Springer Nature Switzerland AG 2018.;Scopus;2018;10.1007/978-3-030-03056-8_19;Calleja P., Priyatna F., Mihindukulasooriya N., Rico M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058284497&doi=10.1007%2f978-3-030-03056-8_19&partnerID=40&md5=42a71f4bfde83c4de026726dfcf11402;Spain;"entity extraction; relation extraction; ontology construction";solution proposal;"tool; resource";tourism;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Journal Article;developing a vietnamese tourism question answering system using knowledge graph and deep learning;"Question answering system; Knowledge graph; Natural language processing; Deep learning; Graph query; Vietnamese tourism";In recent years, Question Answering (QA) systems have increasingly become very popular in many sectors. This study aims to use a knowledge graph and deep learning to develop a QA system for tourism in Vietnam. First, the QA system replies to a user's question about a place in Vietnam. Then, the QA describes it in detail such as when the place was discovered, why the place's name was called like that, and so on. Finally, the system recommends some related tourist attractions to users. Meanwhile, deep learning is used to solve a simple natural language answer, and a knowledge graph is used to infer a natural language answering list related to entities in the question. The study experiments on a manual dataset collected from Vietnamese tourism websites. As a result, the QA system combining the two above approaches provides more information than other systems have done before. Besides that, the system gets 0.83 F1, 0.87 precision on the test set.;WoS;2021;10.1145/3453651;Do P,Phan V TH,Gupta BB;http://dx.doi.org/10.1145/3453651;India;question answering;solution proposal;tool;tourism;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a knowledge graph embedding approach for metaphor processing;"Knowledge graph embedding; Metaphor detection; Metaphor generation; Metaphor interpretation; Metaphor processing";Metaphor is a figure of speech that describes one thing (a target) by mentioning another thing (a source) in a way that is not literally true. Metaphor understanding is an interesting but challenging problem in natural language processing. This paper presents a novel method for metaphor processing based on knowledge graph (KG) embedding. Conceptually, we abstract the structure of a metaphor as an attribute-dependent relation between the target and the source. Each specific metaphor can be represented as a metaphor triple (target, attribute, source). Therefore, we can model metaphor triples just like modeling fact triples in a KG and exploit KG embedding techniques to learn better representations of concepts, attributes and concept relations. In this way, metaphor interpretation and generation could be seen as KG completion, while metaphor detection could be viewed as a representation learning enhanced concept pair classification problem. Technically, we build a Chinese metaphor KG in the form of metaphor triples based on simile recognition, and also extract concept-attribute collocations to help describe concepts and measure concept relations. We extend the translation-based and the rotation-based KG embedding models to jointly optimize metaphor KG embedding and concept-attribute collocation embedding. Experimental results demonstrate the effectiveness of our method. Simile recognition is feasible for building the metaphor triple resource. The proposed models improve the performance on metaphor interpretation and generation, and the learned representations also benefit nominal metaphor detection compared with strong baselines. © 2014 IEEE.;ACM;2021;10.1109/taslp.2020.3040507;Song W., Guo J., Fu R., Liu T., Liu L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097935158&doi=10.1109%2fTASLP.2020.3040507&partnerID=40&md5=67852f0b08e3cbfc28ce33a0b4e4e50b;China;"knowledge graph embedding; entity classification";validation research;technique;;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;webisagraph: a very large hypernymy graph from a web corpus;"Computational linguistics; Knowledge graphs; Large graphs; Plug-ins; Web Corpora; Web texts; Large dataset";In this paper, we present WebIsAGraph, a very large hypernymy graph compiled from a dataset of is-a relationships extracted from the CommonCrawl. We provide the resource together with a Neo4j plugin to enable efficient searching and querying over such large graph. We use WebIsAGraph to study the problem of detecting polysemous terms in a noisy terminological knowledge graph, thus quantifying the degree of polysemy of terms found in is-a extractions from Web text. Copyright © 2019 for this paper by its authors.;Scopus;2019;;Faralli S., Finocchi I., Ponzetto S.P., Velardi P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074808871&partnerID=40&md5=eca0a652e88be374a3995f78c37590b0;Germany, Italy;"entity extraction; relation extraction";validation research;resource;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;framester: a wide coverage linguistic linked data hub;"Frame detection; Frame semantics; FrameNet; Framenet coverage; Framester; Knowledge graphs; Linguistic linked data";Semantic web applications leveraging NLP can benefit from easy access to expressive lexical resources such as FrameNet. However, the usefulness of FrameNet is affected by its limited coverage and nonstandard semantics. The access to existing linguistic resources is also limited because of poor connectivity among them. We present some strategies based on Linguistic Linked Data to broaden FrameNet coverage and formal linkage of lexical and factual resources. We created a novel resource, Framester, which acts as a hub between FrameNet, Word- Net, VerbNet, BabelNet, DBpedia, Yago, DOLCE-Zero, as well as other resources. Framester is not only a strongly connected knowledge graph, but also applies a rigorous formal treatment for Fillmore’s frame semantics, enabling full-fledged OWL querying and reasoning on a large framebased knowledge graph. We also describe Word Frame Disambiguation, an application that reuses Framester data as a base in order to perform frame detection from text, with results comparable in precision to the state of the art, but with a much higher coverage. © Springer International Publishing AG 2016.;Scopus;2016;10.1007/978-3-319-49004-5_16;Gangemi A., Alam M., Asprino L., Presutti V., Recupero D.R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997124448&doi=10.1007%2f978-3-319-49004-5_16&partnerID=40&md5=cdc7212b9de89606b0d5a31cdceae74c;France, Italy;"ontology construction; entity alignment";validation research;resource;;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;sakg-bert: enabling language representation with knowledge graphs for chinese sentiment analysis;"car reviews; deep learning; knowledge graph; pretraining model; Sentiment analysis";Sentiment analysis of online reviews is an important task in natural language processing. It has received much attention not only in academia but also in industry. Data have become an important source of competitive intelligence. Various pretraining models such as BERT and ERNIE have made great achievements in the task of natural language processing, but lack domain-specific knowledge. Knowledge graphs can enhance language representation. Furthermore, knowledge graphs have high entity / concept coverage and strong semantic expression ability. We propose a sentiment analysis knowledge graph (SAKG)-BERT model that combines sentiment analysis knowledge and the language representation model BERT. To improve the interpretability of the deep learning algorithm, we construct an SAKG in which triples are injected into sentences as domain knowledge. Our investigation reveals promising results in sentence completion and sentiment analysis tasks. © 2013 IEEE.;IEEE;2021;10.1109/access.2021.3098180;Yan X., Jian F., Sun B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111005493&doi=10.1109%2fACCESS.2021.3098180&partnerID=40&md5=3f5f88fa988192c739fbbd47eef64e36;China;"augmented language models; text analysis";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;an entity linking model based on candidate features;"Entity disambiguation; Entity linking; Knowledge graph";Entity linking is a key step for automatic question and answering with knowledge graph. It has broad application prospects in Natural Language Processing, Information Retrieval and other fields. This paper constructed an entity linking model based on candidate features. Firstly, it proposed a candidate entities generation algorithm that combines knowledge base matching and word vector similarity calculation and then put forward a suitable entity disambiguation algorithm for different candidate entity generation features, so as to the linked entity is matched to the correct knowledge base entity. We did experiments on the Chinese Weibo Entity Linking data set released by NLPCC in 2013. The results showed that our model can achieve better F1 scores and recall rate than the traditional entity linking methods. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.;Scopus;2021;10.1007/s13278-021-00761-z;Li D., Fu Z., Zheng Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107375872&doi=10.1007%2fs13278-021-00761-z&partnerID=40&md5=c332fb90e33c1955e882663e36b36a46;China;entity linking;validation research;technique;;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;hornet: enriching pre-trained language representations with heterogeneous knowledge sources;"heterogeneous graph attention network; knowledge graph; natural language processing; pre-trained language model";"Knowledge-Enhanced Pre-trained Language Models (KEPLMs) improve the language understanding abilities of deep language models by leveraging the rich semantic knowledge from knowledge graphs, other than plain pre-training texts. However, previous efforts mostly use homogeneous knowledge (especially structured relation triples in knowledge graphs) to enhance the context-aware representations of entity mentions, whose performance may be limited by the coverage of knowledge graphs. Also, it is unclear whether these KEPLMs truly understand the injected semantic knowledge due to the ""black-box'' training mechanism. In this paper, we propose a novel KEPLM named HORNET, which integrates Heterogeneous knowledge from various structured and unstructured sources into the Roberta NETwork and hence takes full advantage of both linguistic and factual knowledge simultaneously. Specifically, we design a hybrid attention heterogeneous graph convolution network (HaHGCN) to learn heterogeneous knowledge representations based on the structured relation triplets from knowledge graphs and the unstructured entity description texts. Meanwhile, we propose the explicit dual knowledge understanding tasks to help induce a more effective infusion of the heterogeneous knowledge, promoting our model for learning the complicated mappings from the knowledge graph embedding space to the deep context-aware embedding space and vice versa. Experiments show that our HORNET model outperforms various KEPLM baselines on knowledge-aware tasks including knowledge probing, entity typing and relation extraction. Our model also achieves substantial improvement over several GLUE benchmark datasets, compared to other KEPLMs. © 2021 ACM.";Scopus;2021;10.1145/3459637.3482436;Zhang T., Cai Z., Wang C., Li P., Li Y., Qiu M., Tang C., He X., Huang J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119181897&doi=10.1145%2f3459637.3482436&partnerID=40&md5=04aecaaa3d768ded99a4db0e0108b8c9;China;"augmented language models; knowledge graph embedding";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;multimodal language modelling on knowledge graphs for deep video understanding;"intent detection; knowledge graphs; language model; scene description; slot filling; speaker diarization; transformers";The natural language processing community has had a major interest in auto-regressive [4, 13] and span-prediction based language models [7] recently, while knowledge graphs are often referenced for common-sense based reasoning and fact-checking models. In this paper, we present an equivalence representation of span-prediction based language models and knowledge-graphs to better leverage recent developments of language modelling for multi-modal problem statements. Our method performed well, especially with sentiment understanding for multi-modal inputs, and discovered potential bias in naturally occurring videos when compared with movie-data interaction-understanding. We also release a dataset of an auto-generated questionnaire with ground-truths consisting of labels spanning across 120 relationships, 99 sentiments, and 116 interactions, among other labels for finer-grained analysis of model comparisons in the community. © 2021 ACM.;Scopus;2021;10.1145/3474085.3479220;Anand V., Ramesh R., Jin B., Wang Z., Lei X., Lin C.-Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119362395&doi=10.1145%2f3474085.3479220&partnerID=40&md5=0f6c2c4ebc8eb5060ace30f8ebd1967a;United States;"augmented language models; text analysis";validation research;"technique; resource";;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;relation-based multi-type aware knowledge graph embedding;"Graph attention network; Knowledge graph embedding; Multi-type; Ontology; Taxonomy tree";Knowledge graph (KG) embedding projects the graph into a low-dimensional space and preserves the graph information. An essential part of a KG is the ontology, which always is organized as a taxonomy tree, depicting the type (or multiple types) of each entity and the hierarchical relationships among these types. The importance of considering the ontology during KG embedding lies in its ability to provide side-information, improving the downstream applications’ accuracy (e.g., link prediction, entity alignment or recommendation). However, the ontology has yet to receive adequate attention during the KG embedding, especially for instances where each entity may belong to multiple types. This ontology-enhanced KG embedding's main challenges are twofold: determining how to discover the relationships among these types and how to integrate them with the entities’ relationship network. Although it is common to see attention-based models used in KG embedding, they cannot settle the issues raised simultaneously. Only a single type is assigned to each entity and the correlation among types are ignored in those models, leading to information loss and encumbered downstream tasks. To overcome these challenges, we propose a composite multi-type aware KG embedding model, whose main components are a multi-type layer and entity embedding layer. We model it as a natural language processing task at the multi-type layer to discover each entity's multi-type feature and automatically capture their correlations. Additionally, a relation-based attention mechanism is conducted at the entity embedding layer, which aggregates neighborhoods’ information and integrates the multi-type layer's information through common entities of these two layers. Through extensive experiments on two real KGs, we demonstrate that, compared to several state-of-the-art baselines, our Multi-Type aware Embedding (MTE) model achieves substantial gain in both Mean Rank and Hit@N for the link prediction task and accuracy for multi-type classification. © 2021;ScienceDirect;2021;10.1016/j.neucom.2021.05.021;Xue Y., Jin J., Song A., Zhang Y., Liu Y., Wang K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108708387&doi=10.1016%2fj.neucom.2021.05.021&partnerID=40&md5=aafc431ce41a560e0bbf2ce1b33073ad;China;"knowledge graph embedding; link prediction";validation research;technique;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;text-graph enhanced knowledge graph representation learning;"graph; graph neural networks; knowledge graph; representation learning; structure sparsity";Knowledge Graphs (KGs) such as Freebase and YAGO have been widely adopted in a variety of NLP tasks. Representation learning of Knowledge Graphs (KGs) aims to map entities and relationships into a continuous low-dimensional vector space. Conventional KG embedding methods (such as TransE and ConvE) utilize only KG triplets and thus suffer from structure sparsity. Some recent works address this issue by incorporating auxiliary texts of entities, typically entity descriptions. However, these methods usually focus only on local consecutive word sequences, but seldom explicitly use global word co-occurrence information in a corpus. In this paper, we propose to model the whole auxiliary text corpus with a graph and present an end-to-end text-graph enhanced KG embedding model, named Teger. Specifically, we model the auxiliary texts with a heterogeneous entity-word graph (called text-graph), which entails both local and global semantic relationships among entities and words. We then apply graph convolutional networks to learn informative entity embeddings that aggregate high-order neighborhood information. These embeddings are further integrated with the KG triplet embeddings via a gating mechanism, thus enriching the KG representations and alleviating the inherent structure sparsity. Experiments on benchmark datasets show that our method significantly outperforms several state-of-the-art methods. © Copyright © 2021 Hu, Zhang, Li, Shi, Shi, Yang and Liu.;Scopus;2021;10.3389/frai.2021.697856;Hu L., Zhang M., Li S., Shi J., Shi C., Yang C., Liu Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117892748&doi=10.3389%2ffrai.2021.697856&partnerID=40&md5=bc8398a036288bce8427cd3734aecb00;China, Singapore;knowledge graph embedding;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;explainable zero-shot topic extraction using a common-sense knowledge graph;"Explainable NLP; Knowledge graph; Topic extraction; Zero-shot classification";"Pre-trained word embeddings constitute an essential building block for many NLP systems and applications, notably when labeled data is scarce. However, since they compress word meanings into a fixed-dimensional representation, their use usually lack interpretability beyond a measure of similarity and linear analogies that do not always reflect real-world word relatedness, which can be important for many NLP applications. In this paper, we propose a model which extracts topics from text documents based on the common-sense knowledge available in ConceptNet [24] - a semantic concept graph that explicitly encodes real-world relations between words - and without any human supervision. When combining both ConceptNet's knowledge graph and graph embeddings, our approach outperforms other baselines in the zero-shot setting, while generating a human-understandable explanation for its predictions through the knowledge graph. We study the importance of some modeling choices and criteria for designing the model, and we demonstrate that it can be used to label data for a supervised classifier to achieve an even better performance without relying on any humanly-annotated training data. We publish the code of our approach at https://github.com/D2KLab/ZeSTE and we provide a user friendly demo at https://zeste.tools.eurecom.fr/. © Ismail Harrando and Raphaël Troncy; licensed under Creative Commons License CC-BY 4.0";Scopus;2021;10.4230/oasics.ldk.2021.17;Harrando I., Troncy R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115072891&doi=10.4230%2fOASIcs.LDK.2021.17&partnerID=40&md5=b88159d302a5184b02f48e0d8fac176d;France;text classification;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;deep learning for knowledge graph completion with xlnet;"GRU; KG Completion; Knowledge Graph; LSTM; XLNet";Knowledge Graph is a graph knowledge base composed of fact entities and relations. Recently, the adoption of Knowledge Graph in Natural Language Processing tasks has proved the efficiency and convenience of KG. Therefore, the plausibility of Knowledge Graph become an import subject, which is also named as KG Completion or Link Prediction. The plausibility of Knowledge Graph reflects in the validness of triples which is structured representation of the entities and relations of Knowledge Graph. Some research work has devoted to KG Completion tasks. The typical methods include semantic matching models like TransE or TransH and Pre-trained models like KG-BERT. In this article, we propose a novel method based on the pre-trained model XLNET and the classification model to verify whether the triples of Knowledge Graph are valid or not. This method takes description of entities or relations as the input sentence text for fine-tuning. Meanwhile contextualized representations with rich semantic information can be obtained by XLNET, avoiding limitations and shortcomings of other typical neural network models. Then these representations are fed into a classifier for classification. Experimental results show that there is an improvement in KG Completion Tasks that the proposed method has achieved. © 2021 ACM.;ACM;2021;10.1145/3480001.3480022;Su M., Su H., Zheng H., Yan B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119835760&doi=10.1145%2f3480001.3480022&partnerID=40&md5=2eb410cadcee0ff9cd2a634ed98a016b;China;"error detection; link prediction";validation research;technique;;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;cost-effective knowledge graph reasoning for complex factoid questions;"Factoid Question Answering; Knowledge Graph; Reasoning";The task of reasoning over knowledge graph for factoid questions has received significant interest from the research community of natural language processing. Performing this task inevitably faces the issues of question complexity and reasoning efficiency. In this paper, we investigate modern reasoning approaches over knowledge graph to tackle complex factoid questions of diverse reasoning schemas with attractive speedup in computational efficiency. To this end, we propose two evidence retrieval strategies to generate concise and informative evidence graph of high semantic-relevance and factual coverage to the question. Then, we adopt DELFT, a graph neural networks based framework that takes the linguistic structure representation of a question and the evidence graph as input, to predict the answer by reasoning over the evidence graph. We evaluate the performance across several baselines in terms of effectiveness and efficiency on two real-world datasets, MOOCQA and MetaQA. The results show the superiority of message passing paradigm in delivering a robust reasoner with better answer quality and significantly improved computational efficiency. © 2021 IEEE.;IEEE;2021;10.1109/ijcnn52387.2021.9533753;Yang X., Chiang M.-F., Lee W.-C., Chang Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116430716&doi=10.1109%2fIJCNN52387.2021.9533753&partnerID=40&md5=dca9c8e035cec9968d2ecb18867c18ff;China, New Zealand, United States;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;exploring sentence embedding structures for semantic relation extraction;"knowledge graph embedding; semantic relation extraction; sentence embeddings";Sentence embeddings encode natural language sentences as low-dimensional, dense vectors and have improved NLP tasks, including relation extraction, which aims at identifying structured relations defined in a knowledge base from unstructured text. A promising and more efficient approach would be to embed both the text and structured knowledge in low-dimensional spaces and discover alignments between them. We develop such an alignment procedure and evaluate the extent to which sentences carrying similar senses are embedded in close proximity sub-spaces, using that structure to align them to a knowledge graph. Our experimental results show that embedding spaces generated from simple models outperform those from more complicated approaches for the alignment and relation extraction task. We also show that clusterability can serve as a proxy for alignment accuracy, leading us to conclude that better structured spaces drive better semantic applications. © 2021 IEEE.;IEEE;2021;10.1109/ijcnn52387.2021.9534215;Kalinowski A., An Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116419054&doi=10.1109%2fIJCNN52387.2021.9534215&partnerID=40&md5=3d43052877a8b6499c13a4ac4d25bed1;United States;relation extraction;validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;fine-grained evaluation of knowledge graph embedding model in knowledge enhancement downstream tasks;"Embedding model; Evaluation; Knowledge graph";Knowledge graph (KG) embedding models are proposed to encode entities and relations into a low-dimensional vector space, in turn, can support various machine learning models on KG completion with good performance and robustness. However, the current entity ranking protocol about KG completion cannot adequately evaluate the impacts of KG embedding models in real-world applications. However, KG embeddings are not widely used as word embeddings. An asserted powerful KG embedding model may not be effective in downstream tasks. So in this paper, we commit to finding the answers by using downstream tasks instead of entity ranking protocol to evaluate the effectiveness of KG embeddings. Specifically, we conduct comprehensive experiments on different KG embedding models in KG based question answering, recommendation and natural language processing tasks. Utilizing different genre of downstream tasks, we try to mine the characteristics of each KGE model in actual application scenarios, and provide guidance for the research of KGE models and knowledge-enhanced downstream tasks. © 2021 Elsevier Inc.;ScienceDirect;2021;10.1016/j.bdr.2021.100218;Zhang Y., Li B., Gao H., Ji Y., Yang H., Wang M., Chen W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102311321&doi=10.1016%2fj.bdr.2021.100218&partnerID=40&md5=02b03a3afd3100142fd90cff66c30475;Australia, China;knowledge graph embedding;validation research;guidelines;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;research on improved intelligent generative dialogue algorithm based on knowledge graph;"Deep learning; Engineering education; Graph algorithms; Industrial robots; Intelligent robots; Knowledge representation; Social robots; Speech processing; Artificial intelligence technologies; Back-ground knowledge; Dialogue modeling; Intelligent dialogue; Intelligent dialogue systems; Knowledge graphs; NAtural language processing; Typical application; Natural language processing systems";The rise of a new generation of artificial intelligence technology, represented by deep learning, has promoted the vigorous development of natural language processing technology. As a typical application of natural language processing technology, human-machine intelligent dialogue system, coupled with its commercial value in the fields of voice assistants and chat robots, has become a hot topic in the current academic and industrial circles. In the past, the responses generated by intelligent dialogue robots is single and universal, and even the content is inappropriate. Therefore, this study proposes to use the knowledge graph as the background knowledge when the dialogue model generates the responses[1]. In order to meet the needs of users more closely, it also proposes to introduce the user information participating in the dialogue and the dialogue scene into the model. The model is trained and evaluated on the DuRecDial public dataset, and the optimized model is compared with the original model. The experimental results show that the model with these two modules has better effect than the original model, especially in the generation index, the F1, BLEU2 and DIST-2 indexes have been improved by 0.91%, 0.5% and 0.9% respectively. © Published under licence by IOP Publishing Ltd.;Scopus;2021;10.1088/1742-6596/1966/1/012015;Liu C., Li Y., Chen B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110792830&doi=10.1088%2f1742-6596%2f1966%2f1%2f012015&partnerID=40&md5=4c41faae41d7762ef3511312060813f4;China;conversational interfaces;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;dozen: cross-domain zero shot named entity recognition with knowledge graph;"cross-domain machine learning; knowledge graph; named entity recognition; natural language processing; zero-shot learning";With the new developments of natural language processing, increasing attention has been given to the task of Named Entity Recognition (NER). However, the vast majority of work focus on a small number of large-scale annotated datasets with a limited number of entities such as person, location and organization. While other datasets have been introduced with domain-specific entities, the smaller size of these largely limits the applicability of state-of-the-art deep models. Even if there are promising new approaches for performing zero-shot learning (ZSL), they are not designed for a cross-domain settings. We propose Cross Domain Zero Shot Named Entity Recognition with Knowledge Graph (DOZEN), which learns the relations between entities across different domains from an existing ontology of external knowledge and a set of analogies linking entities and domains. Experiments performed on both large scale and domain-specific datasets indicate that DOZEN is the most suitable option to extracts unseen entities in a target dataset from a different domain. © 2021 Owner/Author.;Scopus;2021;10.1145/3404835.3463113;Nguyen H.-V., Gelli F., Poria S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111631359&doi=10.1145%2f3404835.3463113&partnerID=40&md5=13d14a306f649d107b8a45a11edecc1b;Singapore;entity extraction;validation research;technique;;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;bio-soda: enabling natural language question answering over knowledge graphs without training data;"Knowledge Graphs; Question Answering; Ranking";The problem of natural language processing over structured data has become a growing research field, both within the relational database and the Semantic Web community, with significant efforts involved in question answering over knowledge graphs (KGQA). However, many of these approaches are either specifically targeted at open-domain question answering using DBpedia, or require large training datasets to translate a natural language question to SPARQL in order to query the knowledge graph. Hence, these approaches often cannot be applied directly to complex scientific datasets where no prior training data is available. In this paper, we focus on the challenges of natural language processing over knowledge graphs of scientific datasets. In particular, we introduce Bio-SODA, a natural language processing engine that does not require training data in the form of question-Answer pairs for generating SPARQL queries. Bio-SODA uses a generic graph-based approach for translating user questions to a ranked list of SPARQL candidate queries. Furthermore, Bio-SODA uses a novel ranking algorithm that includes node centrality as a measure of relevance for selecting the best SPARQL candidate query. Our experiments with real-world datasets across several scientific domains, including the official bioinformatics Question Answering over Linked Data (QALD) challenge, as well as the CORDIS dataset of European projects, show that Bio-SODA outperforms publicly available KGQA systems by an F1-score of least 20% and by an even higher factor on more complex bioinformatics datasets. © 2021 Owner/Author.;ACM;2021;10.1145/3468791.3469119;Sima A.C., Mendes De Farias T., Anisimova M., Dessimoz C., Robinson-Rechavi M., Zbinden E., Stockinger K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112749774&doi=10.1145%2f3468791.3469119&partnerID=40&md5=7dd1a4f7df7992cd50f585e8f4e09851;Switzerland, United Kingdom;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;1
Conference Paper;enabling language representation with knowledge graph and structured semantic information;"knowledge graph; language model; semantic information";Pre-trained language models have been widely recognized and applied. While common pre-training language representation models(PLMs) usually focus on grasping the co-occurrence of words or sentences in simple tasks, more and more researchers realize that external information, i.e., knowledge graph (KG) and clear structured semantics, can be vital in natural language understanding tasks. Therefore, using external information to enhance PLMs (such as BERT) has gradually become a popular direction. However, the existing improvement methods often only use a certain type of external information, and it is difficult to solve the problems of common PLMs that lack common sense and semantic incompleteness in one fell swoop. Suppose the model wants to integrate multiple external information. In that case, it not only requires the model to deal with the noise problem that external information may bring but also requires the model to ensure that different information can work together effectively. In this paper, we propose Sem-K-BERT, which integrates the information of KG and semantic role labeling(SRL) before and after the BERT encoding layer, and introduces a context-aware knowledge screening mechanism based on semantic correlation calculation and a text-semantic alignment mechanism to effectively integrate the two external information and reduce the impact of noise. Experiments and analysis on 8 different Chinese natural language processing tasks show that Sem-K-BERT has better performance than BERT and the BERT model that only incorporates KG. This indicates that the simultaneous use of knowledge graph and SRL information offers a promising solution to improve the performance of PLMs. © 2021 IEEE.;IEEE;2021;10.1109/ccai50917.2021.9447453;Xu W., Fang M., Yang L., Jiang H., Liang G., Zuo C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111426193&doi=10.1109%2fCCAI50917.2021.9447453&partnerID=40&md5=a69b1fc7624afe01cfd28fd4e42465dc;China;augmented language models;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;structure-augmented text representation learning for efficient knowledge graph completion;"Contextualized Representation; Knowledge Graph Completion; Knowledge Graph Embedding; Link Prediction; Structured Knowledge";Human-curated knowledge graphs provide critical supportive information to various natural language processing tasks, but these graphs are usually incomplete, urging auto-completion of them (a.k.a. knowledge graph completion). Prevalent graph embedding approaches, e.g., TransE, learn structured knowledge via representing graph elements (i.e., entities/relations) into dense embeddings and capturing their triple-level relationship with spatial distance. However, they are hardly generalizable to the elements never visited in training and are intrinsically vulnerable to graph incompleteness. In contrast, textual encoding approaches, e.g., KG-BERT, resort to graph triple's text and triple-level contextualized representations. They are generalizable enough and robust to the incompleteness, especially when coupled with pre-trained encoders. But two major drawbacks limit the performance: (1) high overheads due to the costly scoring of all possible triples in inference, and (2) a lack of structured knowledge in the textual encoder. In this paper, we follow the textual encoding paradigm and aim to alleviate its drawbacks by augmenting it with graph embedding techniques - a complementary hybrid of both paradigms. Specifically, we partition each triple into two asymmetric parts as in translation-based graph embedding approach, and encode both parts into contextualized representations by a Siamese-style textual encoder. Built upon the representations, our model employs both deterministic classifier and spatial measurement for representation and structure learning respectively. It thus reduces the overheads by reusing graph elements' embeddings to avoid combinatorial explosion, and enhances structured knowledge by exploring the spatial characteristics. Moreover, we develop a self-adaptive ensemble scheme to further improve the performance by incorporating triple scores from an existing graph embedding model. In experiments, we achieve state-of-the-art performance on three benchmarks and a zero-shot dataset for link prediction, with highlights of inference costs reduced by 1-2 orders of magnitude compared to a sophisticated textual encoding method. Â© 2021 ACM.;Scopus;2021;10.1145/3442381.3450043;Wang B., Shen T., Long G., Zhou T., Wang Y., Chang Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107988657&doi=10.1145%2f3442381.3450043&partnerID=40&md5=c207e1dcc2f6229d2728e1be9c86cc6d;Australia, China, United States;"link prediction; knowledge graph embedding; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;1;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a joint model for representation learning of tibetan knowledge graph based on encyclopedia;"encyclopedia; joint model; knowledge graph; representation learning; Tibetan";Learning the representation of a knowledge graph is critical to the field of natural language processing. There is a lot of research for English knowledge graph representation. However, for the low-resource languages, such as Tibetan, how to represent sparse knowledge graphs is a key problem. In this article, aiming at scarcity of Tibetan knowledge graphs, we extend the Tibetan knowledge graph by using the triples of the high-resource language knowledge graphs and Point of Information map information. To improve the representation learning of the Tibetan knowledge graph, we propose a joint model to merge structure and entity description information based on the Translating Embeddings and Convolution Neural Networks models. In addition, to solve the segmentation errors, we use character and word embedding to learn more complex information in Tibetan. Finally, the experimental results show that our model can make a better representation of the Tibetan knowledge graph than the baseline. © 2021 Association for Computing Machinery.;ACM;2021;10.1145/3447248;Sun Y., Chen A., Chen C., Xia T., Zhao X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105736079&doi=10.1145%2f3447248&partnerID=40&md5=ec1145a61467f2bf4e7a4f8ccd6e87ad;China;knowledge graph embedding;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;farsbase-kbp: a knowledge base population system for the persian knowledge graph;"Canonicalization; Knowledge extraction; Knowledge Graph; Natural Language Processing; Persian language";While most of the knowledge bases already support the English language, there is only one knowledge base for the Persian language, known as FarsBase, which is automatically created via semi-structured web information. Unlike English knowledge bases such as Wikidata, which have tremendous community support, the population of a knowledge base like FarsBase must rely on automatically extracted knowledge. Knowledge base population can let FarsBase keep growing in size, as the system continues working. In this paper, we present a knowledge base population system for the Persian language, which extracts knowledge from unlabelled raw text, crawled from the Web. The proposed system consists of a set of state-of-the-art modules such as an entity linking module as well as information and relation extraction modules designed for FarsBase. Moreover, a canonicalization system is introduced to link extracted relations to FarsBase properties. Then, the system uses knowledge fusion techniques with minimal intervention of human experts to integrate and filter the proper knowledge instances, extracted by each module. To evaluate the performance of the presented knowledge base population system, we present the first gold dataset for benchmarking knowledge base population in the Persian language, which consisting of 22015 FarsBase triples and verified by human experts. The evaluation results demonstrate the efficiency of the proposed system. © 2021 Elsevier B.V.;ScienceDirect;2021;10.1016/j.websem.2021.100638;Asgari-Bidhendi M., Janfada B., Minaei-Bidgoli B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103692386&doi=10.1016%2fj.websem.2021.100638&partnerID=40&md5=6f45b35d1f537ef77283ea160e9c010e;Iran;"entity linking; entity extraction; relation extraction";solution proposal;"tool; resource";;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;applying curriculum learning on path-based knowledge graph reasoning algorithems;"Curriculum Learning; Knowledge Graph Reasoning; Natural Language Processing; Path-based Inferencing";In the field of knowledge graph reasoning, path reasoning based on reinforcement learning avoids using random walking methods and the inefficient search, but what follows is the false path problem. The amount of false paths is more than that of correct ones. The agent would usually reach the correct entity from the wrong paths first, and be more inclined to them in subsequent exploration. We propose to use curriculum learning to solve this problem: assuming that in the environment corresponding to the simple samples, the proportion of correct paths and the quality of paths are higher. The agent counters the sensitivity of RL models to false paths in the strategy by learning the basics knowledge out of simple sample sets. After a comprehensive evaluation on three KG datasets, our method is highly versatile and improves performance in knowledge-based question answering with almost no additional training time. And taking MINERVA as the baseline, the MRR index has increased by 1.3%, 3.7% on datasets WN18RR, NELL-995 respectively. © 2021 IEEE.;IEEE;2021;10.1109/icnlp52887.2021.00019;Jia H., Luo L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116154828&doi=10.1109%2fICNLP52887.2021.00019&partnerID=40&md5=ade73f64787a204652e47a171d0b44b3;China;semantic search;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;research on automatic question answering of generative knowledge graph based on pointer network;"Answer generative model; Entity recognition; Knowledge base question answering; Pointer generator network; Pre-trained language model";Question-answering systems based on knowledge graphs are extremely challenging tasks in the field of natural language processing. Most of the existing Chinese Knowledge Base Question Answering(KBQA) can only return the knowledge stored in the knowledge base by extractive methods. Nevertheless, this processing does not conform to the reading habits and cannot solve the Outof- vocabulary(OOV) problem. In this paper, a new generative question answering method based on knowledge graph is proposed, including three parts of knowledge vocabulary construction, data pre-processing, and answer generation. In the word list construction, BiLSTM-CRF is used to identify the entity in the source text, finding the triples contained in the entity, counting the word frequency, and constructing it. In the part of data pre-processing, a pre-trained language model BERT combining word frequency semantic features is adopted to obtain word vectors. In the answer generation part, one combination of a vocabulary constructed by the knowledge graph and a pointer generator network(PGN) is proposed to point to the corresponding entity for generating answer. The experimental results show that the proposed method can achieve superior performance on WebQA datasets than other methods. © 2021 by the authors.;Scopus;2021;10.3390/info12030136;Liu S., Tan N., Ge Y., Lukač N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103184572&doi=10.3390%2finfo12030136&partnerID=40&md5=b7d6f1efbcf602de7ad7684072584228;China, Slovenia;"question answering; augmented language models";validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1
Journal Article;time-aware polarisx: auto-growing knowledge graph;"Information extraction; Knowledge graph; Machine learning; Natural language processing; Time-aware";A knowledge graph is a structured graph in which data obtained frommultiple sources are standardized to acquire and integrate human knowledge. Research is being actively conducted to cover a wide variety of knowledge, as it can be applied to applications that help humans. However, existing researches are constructing knowledge graphs without the time information that knowledge implies. Knowledge stored without time information becomes outdated over time, and in the future, the possibility of knowledge being false or meaningful changes is excluded. As a result, they can't reFFect information that changes dynamically, and they can't accept information that has newly emerged. To solve this problem, this paper proposes Time-Aware PolarisX, an automatically extended knowledge graph including time information. Time-Aware PolarisX constructed a BERT model with a relation extractor and an ensemble NER model including a time tag with an entity extractor to extract knowledge consisting of subject, relation, and object from unstructured text. Through two application experiments, it shows that the proposed system overcomes the limitations of existing systems that do not consider time information when applied to an application such as a chatbot. Also, we verify that the accuracy of the extraction model is improved through a comparative experiment with the existing model. © 2021 Tech Science Press. All rights reserved.;Scopus;2021;10.32604/cmc.2021.015636;Ahn Y.-S., Jeong O.-R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102500723&doi=10.32604%2fcmc.2021.015636&partnerID=40&md5=7a3b42f9492ab3017c59448caf134f9c;South Korea;"entity extraction; relation extraction";validation research;technique;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;entity-centric fully connected gcn for relation classification;"Graph convolutional network; Natural language processing; Relation classification";Relation classification is an important task in the field of natural language processing, and it is one of the important steps in constructing a knowledge graph, which can greatly reduce the cost of constructing a knowledge graph. The Graph Convolutional Network (GCN) is an effective model for accurate relation classification, which models the dependency tree of textual instances to extract the semantic features of relation mentions. Previous GCN based methods treat each node equally. However, the contribution of different words to express a certain relation is different, especially the entity mentions in the sentence. In this paper, a novel GCN based relation classifier is propose, which treats the entity nodes as two global nodes in the dependency tree. These two global nodes directly connect with other nodes, which can aggregate information from the whole tree with only one convolutional layer. In this way, the method can not only simplify the complexity of the model, but also generate expressive relation representation. Experimental results on two widely used data sets, SemEval-2010 Task 8 and TACRED, show that our model outperforms all the compared baselines in this paper, which illustrates that the model can effectively utilize the dependencies between nodes and improve the performance of relation classification. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Scopus;2021;10.3390/app11041377;Long J., Wang Y., Wei X., Ding Z., Qi Q., Xie F., Qian Z., Huang W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100688691&doi=10.3390%2fapp11041377&partnerID=40&md5=f1e0a3b96549637d36bdfb20bfb890a9;China;relation classification;validation research;technique;;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;knowledge graph embedding based on multi-view clustering framework;"Knowledge graph; knowledge representation; multi-view clustering; semantic analysis";Knowledge representation is one of the critical problems in knowledge engineering and artificial intelligence, while knowledge embedding as a knowledge representation methodology indicates entities and relations in knowledge graph as low-dimensional, continuous vectors. In this way, knowledge graph is compatible with numerical machine learning models. Major knowledge embedding methods employ geometric translation to design score function, which is weak-semantic for natural language processing. To overcome this disadvantage, in this paper, we propose our model based on multi-view clustering framework, which could generate semantic representations of knowledge elements (i.e., entities/relations). With our semantic model, we also present an empowered solution to entity retrieval with entity description. Extensive experiments show that our model achieves substantial improvements against baselines on the task of knowledge graph completion, triple classification, entity classification, and entity retrieval. © 1989-2012 IEEE.;IEEE;2021;10.1109/tkde.2019.2931548;Xiao H., Chen Y., Shi X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091483090&doi=10.1109%2fTKDE.2019.2931548&partnerID=40&md5=f2c9a44444e11f9e77252536c480beb6;China;knowledge graph embedding;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph augmented advanced learning models for commonsense reasoning;"Artificial Intelligence; Commonsense QA; ConceptNet; Hierarchical attention mechanism; Knowledge graphs; LSTM; Machine learning; Natural language processing; Neural networks";Machine learning is the key solution to many AI issues, but learning models rely heavily on specific training data. While a Bayesian setup can be used to incorporate some learning patterns with previous knowledge, those patterns can not access any organized world knowledge on requirements. The primary objective is to enable human-capable machines in ordinary everyday circumstances to estimate and make presumptions. In this paper we propose to respond to such common sense issues through a textual inference system with external, organized common sense graphs for explanatory inferences. The framework is based on a schematic map as a pair of questions and answers, a linked subgraph from the semantine to the symbolic space of knowledge-based external information. It displays a schematic map with a new network graphic module for information knowledge and performance with graph representations. LSTMs and graphical networks with a hierarchical attention-based direction are the basis of our model. It is flexible and understandable from the intermediate attention scores, leading to confident results. We also achieved state-of-the-art reliability on CommonsenseQA, a broad database of common sense reasoning utilizing ConceptNet as the only external tool for BERT-based models. © 2021 Institute of Physics Publishing. All rights reserved.;Scopus;2021;10.1088/1757-899x/1022/1/012038;Pothuri A., Veeramallu H.S.R., Malik P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100733787&doi=10.1088%2f1757-899X%2f1022%2f1%2f012038&partnerID=40&md5=e45908062dccf8cdbc1c140ef091e6dd;India;"augmented language models; question answering";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;graph-based reasoning model for multiple relation extraction;"Information extraction; Natural language processing; Neural networks; Relation extraction";Linguistic knowledge is useful for various NLP tasks, but the difficulty lies in the representation and application. We consider that linguistic knowledge is implied in a large-scale corpus, while classification knowledge, the knowledge related to the definitions of entity and relation types, is implied in the labeled training data. Therefore, a corpus subgraph is proposed to mine more linguistic knowledge from the easily accessible unlabeled data, and sentence subgraphs are used to acquire classification knowledge. They jointly constitute a relation knowledge graph (RKG) to extract relations from sentences in this paper. On RKG, entity recognition can be regarded as a property value filling problem and relation classification can be regarded as a link prediction problem. Thus, the multiple relation extraction can be treated as a reasoning process for knowledge completion. We combine statistical reasoning and neural network reasoning to segment sentences into entity chunks and non-entity chunks, then propose a novel Chunk Graph LSTM network to learn the representations of entity chunks and infer the relations among them. The experiments on two standard datasets demonstrate our model outperforms the previous models for multiple relation extraction. © 2020 Elsevier B.V.;ScienceDirect;2021;10.1016/j.neucom.2020.09.025;Huang H., Lei M., Feng C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092253997&doi=10.1016%2fj.neucom.2020.09.025&partnerID=40&md5=9f9d541afc98a60e2a8c0c34dd11f21d;China;relation extraction;validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;exploiting non-taxonomic relations for measuring semantic similarity and relatedness in wordnet;"Information content; Knowledge graph; Semantic similarity and relatedness; WordNet";Various applications in computational linguistics and artificial intelligence employ semantic similarity to solve challenging tasks, such as word sense disambiguation, text classification, information retrieval, machine translation, and document clustering. To our knowledge, research to date rely solely on the taxonomic relation “ISA” to evaluate semantic similarity and relatedness between terms. This paper explores the benefits of using all types of non-taxonomic relations in large linked data, such as WordNet knowledge graph, to enhance existing semantic similarity and relatedness measures. We propose a holistic poly-relational approach based on a new relation-based information content and non-taxonomic-based weighted paths to devise a comprehensive semantic similarity and relatedness measure. To demonstrate the benefits of exploiting non-taxonomic relations in a knowledge graph, we used three strategies to deploy non-taxonomic relations at different granularity levels. We conduct experiments on four well-known gold standard datasets. The results of our proposed method demonstrate an improvement over the benchmark semantic similarity methods, including the state-of-the-art knowledge graph embedding techniques, that ranged from 3.8%–23.8%, 1.3%–18.3%, 31.8%–117.2%, and 19.1%–111.1%, on all gold standard datasets MC, RG, WordSim, and Mturk, respectively. These results demonstrate the robustness and scalability of the proposed semantic similarity and relatedness measure, significantly improving existing similarity measures. © 2020 Elsevier B.V.;ScienceDirect;2021;10.1016/j.knosys.2020.106565;AlMousa M., Benlamri R., Khoury R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095852763&doi=10.1016%2fj.knosys.2020.106565&partnerID=40&md5=5573a5a128dd93ea1e4d6a4101770633;Canada;semantic similarity;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;when external knowledge does not aggregate in named entity recognition;"Information extraction; Knowledge embeddings; Named entity recognition";In the different areas of knowledge, textual data are important sources of information. This way, Information Extraction methods have been developed to identify and structure information present in textual documents. In particular there is the Named Entity Recognition (NER) task, which consists of using methods to identify Named Entities, such as Person, Place, among others, in texts, using techniques from Natural Language Processing and Machine Learning. Recent works explored the use of external sources of knowledge to boost the Machine Learning models with sets of domain specific relevant information for the NER task. This work aims to evaluate the aggregation of external knowledge, in the form of Gazetter and Knowledge Graphs, for NER task. Our approach is composed of two steps: i) generation of embeddings, ii) definition and training of the Machine Learning methods. The experiments were conducted on four English datasets, and their results show that the applied strategies for external knowledge integration did not bring great gains to the models, as expressed by F1-Score metric. In the performed experiments, there was an F1-score increase in 17 of the 32 cases where external knowledge was used, but in most cases the gains were lesser than 0.5% in F1-score. In some scenarios the aggregated external knowledge does not capture relevant content, thus not being necessarily beneficial to the methodology. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-91699-2_42;Privatto P.I.M., Guilherme I.R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121798857&doi=10.1007%2f978-3-030-91699-2_42&partnerID=40&md5=bad2a6e5bb987adcff21253fc63ca748;Brazil;entity extraction;validation research;method;;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an italian question answering system based on grammars automatically generated from ontology lexica;"Knowledge graph; Natural language processing systems; Automatically generated; Dbpedia; Knowledge graphs; Model based approach; Ontology's; Question Answering; Question answering systems; Ontology";The paper presents an Italian question answering system over linked data. We use a model-based approach to question answering based on an ontology lexicon in lemon format. The system exploits an automatically generated lexicalized grammar that can then be used to interpret and transform questions into SPARQL queries. We apply the approach for the Italian language and implement a question answering system that can answer more than 1.6 million questions over the DBpedia knowledge graph. © 2021 for this paper by its author. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).;Scopus;2021;;Nolano G., Elahi M.F., di Buono M.P., Ell B., Cimiano P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121222253&partnerID=40&md5=f725c57161f77956b7b474537756fec9;Germany, Italy, Norway;question answering;solution proposal;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;knowledge augmented language models for causal question answering;"Causal knowledge graphs; Causal question answering; Causal reasoning; Language models";The task of causal question answering broadly involves reasoning about causal relations and causality over a provided premise. Causal question answering can be expressed across a variety of tasks including commonsense question answering, procedural reasoning, reading comprehension, and abductive reasoning. Transformer-based pretrained language models have shown great promise across many natural language processing (NLP) applications. However, these models are reliant on distributional knowledge learned during the pretraining process and are limited in their causal reasoning capabilities. Causal knowledge, often represented as cause-effect triples in a knowledge graph, can be used to augment and improve the causal reasoning capabilities of language models. There is limited work exploring the efficacy of causal knowledge for question answering tasks. We consider the challenge of structuring causal knowledge in language models and developing a unified model that can solve a broad set of causal question answering tasks. Copyright © 2021 for this paper by its authors.;Scopus;2021;;Dalal D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121137603&partnerID=40&md5=a2b76c001813760b3b290b87017964b3;Ireland;"augmented language models; question answering";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;cbench: demonstrating comprehensive evaluation of questianswering systems over knowledge graphs through deep analysis of benchmarks;"Knowledge graph; Natural language processing systems; Structural properties; Syntactics; Comprehensive evaluation; Excel; Fine grained; Knowledge graphs; Natural language questions; Property; Question answering systems; Benchmarking";A plethora of question answering (QA) systems that retrieve answers to natural language questions from knowledge graphs have been developed in recent years. However, choosing a benchmark to accurately assess the quality of a question answering system is a challenging task due to the high degree of variations among the available benchmarks with respect to their fine-grained properties. In this demonstration, we introduce CBench, an extensible, and more informative benchmarking suite for analyzing benchmarks and evaluating QA systems. CBench can be used to analyze existing benchmarks with respect to several fine-grained linguistic, syntactic, and structural properties of the questions and queries in the benchmarks. Moreover, CBench can be used to facilitate the evaluation of QA systems using a set of popular benchmarks that can be augmented with other user-provided benchmarks. CBench not only evaluates a QA system based on popular single-number metrics but also gives a detailed analysis of the linguistic, syntactic, and structural properties of answered and unanswered questions to help the developers of QA systems to better understand where their system excels and where it struggles. © The authors.;Scopus;2021;10.14778/3476311.3476326;Orogat A., El-Roby A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119964973&doi=10.14778%2f3476311.3476326&partnerID=40&md5=fc7681a9f7ee0026a1f009cff40527ed;Canada;question answering;solution proposal;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;contextual language models for knowledge graph completion;"GPT-2; Knowledge graph embedding; Triple classification";Knowledge Graphs (KGs) have become the backbone of various machine learning based applications over the past decade. However, the KGs are often incomplete and inconsistent. Several representation learning based approaches have been introduced to complete the missing information in KGs. Besides, Neural Language Models (NLMs) have gained huge momentum in NLP applications. However, exploiting the contextual NLMs to tackle the Knowledge Graph Completion (KGC) task is still an open research problem. In this paper, a GPT-2 based KGC model is proposed and is evaluated on two benchmark datasets. The initial results obtained from the fine-tuning of the GPT-2 model for triple classification strengthens the importance of usage of NLMs for KGC. Also, the impact of contextual language models for KGC has been discussed. © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).;Scopus;2021;;Biswas R., Sofronova R., Alam M., Sack H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119402984&partnerID=40&md5=da78ec552b908dc18a2356ad70666ff0;Germany;"triple classification; augmented language models; knowledge graph embedding";validation research;technique;;0;0;0;0;0;0;0;0;0;0;1;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;space efficient context encoding for non-task-oriented dialogue generation with graph attention transformer;"Cell proliferation; Computational linguistics; Encoding (symbols); Knowledge graph; Speech processing; Dialogue generations; Dialogue systems; Human evaluation; Knowledge graphs; Knowledge retrieval; Space efficient; Space requirements; Task-oriented; Signal encoding";To improve the coherence and knowledge retrieval capabilities of non-task-oriented dialogue systems, recent Transformer-based models aim to integrate fixed background context. This often comes in the form of knowledge graphs, and the integration is done by creating pseudo utterances through paraphrasing knowledge triples, added into the accumulated dialogue context. However, the context length is fixed in these architectures, which restricts how much background or dialogue context can be kept. In this work, we propose a more concise encoding for background context structured in the form of knowledge graphs, by expressing the graph connections through restrictions on the attention weights. The results of our human evaluation show that this encoding reduces space requirements without negative effects on the precision of reproduction of knowledge and perceived consistency. Further, models trained with our proposed context encoding generate dialogues that are judged to be more comprehensive and interesting. © 2021 Association for Computational Linguistics;ACL;2021;;Galetzka F., Rose J., Schlangen D., Lehmann J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118958237&partnerID=40&md5=ac84d066e7f640f139f6346ae3f79290;Germany;"conversational interfaces; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;employing argumentation knowledge graphs for neural argument generation;"Computational linguistics; Encoding (symbols); Graphic methods; Search engines; Downstream applications; High quality; Knowledge graphs; Text generations; Wikipedia; Knowledge graph";Generating high-quality arguments, while being challenging, may benefit a wide range of downstream applications, such as writing assistants and argument search engines. Motivated by the effectiveness of utilizing knowledge graphs for supporting general text generation tasks, this paper investigates the usage of argumentation-related knowledge graphs to control the generation of arguments. In particular, we construct and populate three knowledge graphs, employing several compositions of them to encode various knowledge into texts of debate portals and relevant paragraphs from Wikipedia. Then, the texts with the encoded knowledge are used to fine-tune a pre-trained text generation model, GPT-2. We evaluate the newly created arguments manually and automatically, based on several dimensions important in argumentative contexts, including argumentativeness and plausibility. The results demonstrate the positive impact of encoding the graphs' knowledge into debate portal texts for generating arguments with superior quality than those generated without knowledge. © 2021 Association for Computational Linguistics;ACL;2021;;Al-Khatib K., Trautner L., Wachsmuth H., Hou Y., Stein B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118945370&partnerID=40&md5=e5502312ee82e85a5b249ec70dca3fb5;Germany, Ireland;text generation;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;robust knowledge graph completion with stacked convolutions and a student re-ranking network;"Computational linguistics; Convolution; Benchmark datasets; Commonsense knowledge; Completion methods; Convolutional networks; Encyclopedic knowledge; Knowledge graphs; Modeling performance; Performance; Re-ranking; Student network; Knowledge graph";Knowledge Graph (KG) completion research usually focuses on densely connected benchmark datasets that are not representative of real KGs. We curate two KG datasets that include biomedical and encyclopedic knowledge and use an existing commonsense KG dataset to explore KG completion in the more realistic setting where dense connectivity is not guaranteed. We develop a deep convolutional network that utilizes textual entity representations and demonstrate that our model outperforms recent KG completion methods in this challenging setting. We find that our model's performance improvements stem primarily from its robustness to sparsity. We then distill the knowledge from the convolutional network into a student network that re-ranks promising candidate entities. This re-ranking stage leads to further improvements in performance and demonstrates the effectiveness of entity re-ranking for KG completion. © 2021 Association for Computational Linguistics;ACL;2021;;Lovelace J., Newman-Griffis D., Vashishth S., Lehman J.F., Rosé C.P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118936605&partnerID=40&md5=b6284df2ab42d3d9861f9514700dc6f4;United States;triple classification;validation research;"technique; resource";;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;km-bart: knowledge enhanced multimodal bart for visual commonsense generation;"Computational linguistics; Image enhancement; Knowledge based systems; Knowledge management; Commonsense knowledge; Knowledge based; Knowledge graphs; Language model; Modeling performance; Multi-modal; Multimodal inputs; Multimodal models; Pre-training; Sequence models; Knowledge graph";We present Knowledge Enhanced Multimodal BART (KM-BART), which is a Transformer-based sequence-to-sequence model capable of reasoning about commonsense knowledge from multimodal inputs of images and texts. We adapt the generative BART architecture (Lewis et al., 2020) to a multimodal model with visual and textual inputs. We further develop novel pretraining tasks to improve the model performance on the Visual Commonsense Generation (VCG) task. In particular, our pretraining task of Knowledge-based Commonsense Generation (KCG) boosts model performance on the VCG task by leveraging commonsense knowledge from a large language model pretrained on external commonsense knowledge graphs. To the best of our knowledge, we are the first to propose a dedicated task for improving model performance on the VCG task. Experimental results show that our model reaches state-of-the-art performance on the VCG task (Park et al., 2020) by applying these novel pretraining tasks. © 2021 Association for Computational Linguistics;ACL;2021;;Xing Y., Shi Z., Meng Z., Lakemeyer G., Ma Y., Wattenhofer R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118931504&partnerID=40&md5=6ac5818aafafe229bb12cfbe8bfddc02;Switzerland, Germany;augmented language models;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1
Conference Paper;stage-wise fine-tuning for graph-to-text generation;"Computational linguistics; Embeddings; Knowledge graph; Fine tuning; Input graphs; Language model; Performance; Structure information; Structured graphs; Text generations; Text modeling; Tuning mechanism; Wikipedia; Trees (mathematics)";Graph-to-text generation has benefited from pre-trained language models (PLMs) in achieving better performance than structured graph encoders. However, they fail to fully utilize the structure information of the input graph. In this paper, we aim to further improve the performance of the pre-trained language model by proposing a structured graph-to-text model with a two-step fine-tuning mechanism which first fine-tunes the model on Wikipedia before adapting to the graph-to-text generation. In addition to using the traditional token and position embeddings to encode the knowledge graph (KG), we propose a novel tree-level embedding method to capture the interdependency structures of the input graph. This new approach has significantly improved the performance of all text generation metrics for the English WebNLG 2017 dataset. © 2021 Association for Computational Linguistics.;ACL;2021;;Wang Q., Yavuz S., Lin X.V., Ji H., Rajani N.F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118925579&partnerID=40&md5=a1a35b41bc9a9938a14327a42fe16431;United States;"data-to-text generation; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;cori: collective relation integration with data augmentation for open information extraction;"Computational linguistics; Data integration; Forecasting; Integration; Open Data; Data augmentation; Free texts; Integration models; Knowledge graphs; Object extraction; Question Answering; Knowledge graph";Integrating extracted knowledge from the Web to knowledge graphs (KGs) can facilitate tasks like question answering. We study relation integration that aims to align free-text relations in subject-relation-object extractions to relations in a target KG. To address the challenge that free-text relations are ambiguous, previous methods exploit neighbor entities and relations for additional context. However, the predictions are made independently, which can be mutually inconsistent. We propose a two-stage Collective Relation Integration (CoRI) model, where the first stage independently makes candidate predictions, and the second stage employs a collective model that accesses all candidate predictions to make globally coherent predictions. We further improve the collective model with augmented data from the portion of the target KG that is otherwise unused. Experiment results on two datasets show that CoRI can significantly outperform the baselines, improving AUC from.677 to.748 and from.716 to.780, respectively. © 2021 Association for Computational Linguistics;ACL;2021;;Jiang Z., Han J., Sisman B., Dong X.L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118924156&partnerID=40&md5=52901fd9d1dbc55fe9040f4e8adcee72;United States;"entity extraction; relation extraction";validation research;technique;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;learning event graph knowledge for abductive reasoning;"Computational linguistics; Learning systems; Abductive reasoning; Auto encoders; Commonsense knowledge; Event graphs; Language model; Latent variable; Question Answering; Reading comprehension; Reasoning framework; Reasoning tasks; Knowledge graph";Abductive reasoning aims at inferring the most plausible explanation for observed events, which would play critical roles in various NLP applications, such as reading comprehension and question answering. To facilitate this task, a narrative text based abductive reasoning task aNLI is proposed, together with explorations about building reasoning framework using pretrained language models. However, abundant event commonsense knowledge is not well exploited for this task. To fill this gap, we propose a variational autoencoder based model ege-RoBERTa, which employs a latent variable to capture the necessary commonsense knowledge from event graph for guiding the abductive reasoning task. Experimental results show that through learning the external event graph knowledge, our approach outperforms the baseline methods on the aNLI task. © 2021 Association for Computational Linguistics;ACL;2021;;Du L., Ding X., Liu T., Qin B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118921647&partnerID=40&md5=f752f2d33a418531b0826cedefd96ca0;China;"natural language inference; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;lnn-el: a neuro-symbolic approach to short-text entity linking;"Computational linguistics; Computer circuits; Formal logic; Heuristic methods; Natural language processing systems; Black boxes; Conversational systems; First order logic; Interpretable rules; Knowledge graphs; Neural learning; Performance; Question answering systems; Rule based; Short texts; Knowledge graph";Entity linking (EL), the task of disambiguating mentions in text by linking them to entities in a knowledge graph, is crucial for text understanding, question answering or conversational systems. Entity linking on short text (e.g., single sentence or question) poses particular challenges due to limited context. While prior approaches use either heuristics or black-box neural methods, here we propose LNN-EL, a neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. Even though constrained to using rules, LNN-EL performs competitively against SotA black-box neural approaches, with the added benefits of extensibility and transferability. In particular, we show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, BERT encodings, box embeddings, etc), and even scores resulting from previous EL methods, thus improving on such methods. For instance, on the LC-QuAD-1.0 dataset, we show more than 4% increase in F1 score over previous SotA. Finally, we show that the inductive bias offered by using logic results in learned rules that transfer well across datasets, even without fine tuning, while maintaining high accuracy. © 2021 Association for Computational Linguistics;ACL;2021;;Jiang H., Gurajada S., Lu Q., Neelam S., Popa L., Sen P., Li Y., Gray A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118921105&partnerID=40&md5=574c8cee5c137482019988dffa5bacea;United States;entity linking;validation research;technique;;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;how knowledge graph and attention help a quantitative analysis into bag-level relation extraction;"Computational linguistics; Extraction; Attention mechanisms; Distribution patterns; Knowledge graphs; Modeling abilities; Noise distribution; Performance; Qualitative analysis; Real-world datasets; Relation extraction; Supervised methods; Knowledge graph";"Knowledge Graph (KG) and attention mechanism have been demonstrated effective in introducing and selecting useful information for weakly supervised methods. However, only qualitative analysis and ablation study are provided as evidence. In this paper, we contribute a dataset and propose a paradigm to quantitatively evaluate the effect of attention and KG on bag-level relation extraction (RE). We find that (1) higher attention accuracy may lead to worse performance as it may harm the model's ability to extract entity mention features; (2) the performance of attention is largely influenced by various noise distribution patterns, which is closely related to real-world datasets; (3) KG-enhanced attention indeed improves RE performance, while not through enhanced attention but by incorporating entity prior; and (4) attention mechanism may exacerbate the issue of insufficient training data. Based on these findings, we show that a straightforward variant of RE model can achieve significant improvements (6% AUC on average) on two real-world datasets as compared with three state-of-the-art baselines. Our codes and datasets are available at https://github.com/zigkwin-hu/how-KG-ATT-help. © 2021 Association for Computational Linguistics";ACL;2021;;Hu Z., Cao Y., Huang L., Chua T.-S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118918083&partnerID=40&md5=1922ab36dc0690e7e80b7f56f3bf47f8;Singapore, United States;relation extraction;validation research;"resource; method";;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;bert-kg: a short text classification model based on knowledge graph and deep semantics;"Artificialintelligence; BERT-based model; Computermethodologies; Knowledge graph; Lexicalsemantics; Natural languageprocessing; Short textclassification";Chinese short textclassification is one of the increasingly significant tasks inNatural Language Processing (NLP). Different from documents andparagraphs, short text faces the problems of shortness, sparseness,non-standardization, etc., which brings enormous challenges fortraditional classification methods. In this paper, we propose anovel model named BERT-KG, which can classify Chinese short textpromptly and accurately andovercome the difficulty of short text classification. BERT-KGenriches short text features by obtaining background knowledge fromthe knowledge graph and further embeds the three-tuple informationof the target entity into a BERT-based model. Then we fusethe dynamic word vector with the knowledge of the short text to forma feature vector for short text. And finally, the learned featurevector is input into the Softmax classifier to obtain a target labelfor short text. Extensive experiments conducted on two real-worlddatasets demonstrate that BERT-KG significantly improves theclassification performance compared with state-of-the-artbaselines. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-88480-2_58;Zhong Y., Zhang Z., Zhang W., Zhu J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118190056&doi=10.1007%2f978-3-030-88480-2_58&partnerID=40&md5=64c160df8300fa0dc98e0fa25883787c;China;"text classification; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;wikidatacomplete: knowledge graph completion using question-answering;"Human in the loop; Knowledge Graph Completion; Natural Language Processing; Question Answering";In this demonstration, we showcase WikidataComplete, a KG completion system for Wikidata based on Question Answering (QA). We showcase (https://wikidatacomplete.org) that it is possible to leverage Ques-tion Answering to extract new facts from Wikipedia and jointly provide explanations for these extracted facts. Providing explanations has two ad-vantage: first it helps human annotators to verify if the generated facts are correct, second it allows ingesting the approved facts in the KG together with provenance information. Ultimately, we measure the accuracy of such a system for the first time on a real scenario including human annotations. © 2021 CEUR-WS. All rights reserved.;Scopus;2021;;Guo K., Kratzwald B., Diefenbach D., Gravier C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117736958&partnerID=40&md5=ae242d49e56c5f6fcdaaaafa7766c09e;Switzerland, France;"entity linking; link prediction; question answering";solution proposal;tool;;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1
Conference Paper;bert-based semantic query graph extraction for knowledge graph question answering;"Complex networks; Natural language processing systems; Pipelines; Query processing; Recurrent neural networks; Semantics; Complex questions; Entity detection; Graph construction; Graph extractions; Knowledge graphs; Multi tasks; Query graph; Question Answering; Question Answering Task; Semantic query; Knowledge graph";Answering complex questions involving multiple entities and relations remains a challenging Knowledge Graph Question Answering (KGQA) task. To extract a Semantic Query Graph (SQG), we propose a BERT-based decoder that is capable of jointly performing multi-Tasks for SQG construction, such as entity detection, relation prediction, output variable selection, query type classification and ordinal constraint detection. The outputs of our model can be seamlessly integrated with downstream components (e.g. entity linking) of a KGQA pipeline to construct a formal query. The results of our experiments show that our proposed BERT-based semantic query graph extractor achieves better performance than traditional recurrent neural network based extractors. Meanwhile, the KGQA pipeline based on our model outperforms baseline approaches on two benchmark datasets (LC-QuAD, WebQSP) containing complex questions. © 2021 CEUR-WS. All rights reserved.;Scopus;2021;;Liang Z., Peng Z., Yang X., Zhao F., Liu Y., McGuinness D.L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117715122&partnerID=40&md5=401d5c9034f3970acc506efaa3a1d10e;China, United States;"question answering; relation classification";validation research;technique;;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a knowledge graph question-answering platform trained independently of the graph;"Natural language processing systems; Dbpedia; Existing systems; Knowledge graphs; Natural language model; Question Answering; Three phase; Three phasis; Knowledge graph";We will demonstrate KGQAn, a question-Answering platform trained independently of KGs. KGQAn transforms a question into semantically equivalent SPARQL queries via a novel three-phase strategy based on natural language models trained generally for understanding and leveraging short English text. Without preprocessing or annotated questions on KGs, KGQAn outperformed the existing systems in KG question answering by an improvement of at least 33% in F1-measure and 61% in precision. During the demo, the audience will experience KGQAn for question answering on real KGs of topics of interest to them, such as DBpedia and OpenCitations Graph, and review the generated SPARQL queries and answers. A demo video is available online. © 2021 CEUR-WS. All rights reserved.;Scopus;2021;;Omar R., Dhall I., Sheikh N., Mansour E.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117682227&partnerID=40&md5=f983e996d9e20138bcab8939a67e8b75;Canada;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;graphhopper: multi-hop scene graph reasoning for visual question answering;"Knowledge graph reasoning; Multi-modal reasoning; Reinforcement learning; Scene graph reasoning; Visual Question Answering (VQA)";Visual Question Answering (VQA) is concerned with answering free-form questions about an image. Since it requires a deep semantic and linguistic understanding of the question and the ability to associate it with various objects that are present in the image, it is an ambitious task and requires multi-modal reasoning from both computer vision and natural language processing. We propose Graphhopper, a novel method that approaches the task by integrating knowledge graph reasoning, computer vision, and natural language processing techniques. Concretely, our method is based on performing context-driven, sequential reasoning based on the scene entities and their semantic and spatial relationships. As a first step, we derive a scene graph that describes the objects in the image, as well as their attributes and their mutual relationships. Subsequently, a reinforcement learning agent is trained to autonomously navigate in a multi-hop manner over the extracted scene graph to generate reasoning paths, which are the basis for deriving answers. We conduct an experimental study on the challenging dataset GQA, based on both manually curated and automatically generated scene graphs. Our results show that we keep up with human performance on manually curated scene graphs. Moreover, we find that Graphhopper outperforms another state-of-the-art scene graph reasoning model on both manually curated and automatically generated scene graphs by a significant margin. © 2021, The Author(s).;Scopus;2021;10.1007/978-3-030-88361-4_7;Koner R., Li H., Hildebrandt M., Das D., Tresp V., Günnemann S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116858375&doi=10.1007%2f978-3-030-88361-4_7&partnerID=40&md5=f0f5cc665dc9f46cc1c8a83af67176b1;Germany;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;do judge an entity by its name entity typing using language models;"Deep neural networks; Entity type prediction; Knowledge graph completion";The entity type information in a Knowledge Graph (KG) plays an important role in a wide range of applications in Natural Language Processing such as entity linking, question answering, relation extraction, etc. However, the available entity types are often noisy and incomplete. Entity Typing is a non-trivial task if enough information is not available for the entities in a KG. In this work, neural language models and a character embedding model are exploited to predict the type of an entity from only the name of the entity without any other information from the KG. The model has been successfully evaluated on a benchmark dataset. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-80418-3_12;Biswas R., Sofronova R., Alam M., Heist N., Paulheim H., Sack H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115845674&doi=10.1007%2f978-3-030-80418-3_12&partnerID=40&md5=d4b7cc03fa214a9c6a9b54d6d76ee668;Germany;entity classification;validation research;guidelines;;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;combining knowledge graph and word embeddings for spherical topic modeling;"Analytical models; Data models; Integrated circuit modeling; Knowledge graph (KG) embedding; Mathematical models; Probabilistic logic; representation learning; Semantics; Task analysis; topic modeling; von Mises-Fisher (vMF) distribution; word embedding.";Probabilistic topic models are considered as an effective framework for text analysis that uncovers the main topics in an unlabeled set of documents. However, the inferred topics by traditional topic models are often unclear and not easy to interpret because they do not account for semantic structures in language. Recently, a number of topic modeling approaches tend to leverage domain knowledge to enhance the quality of the learned topics, but they still assume a multinomial or Gaussian document likelihood in the Euclidean space, which often results in information loss and poor performance. In this article, we propose a Bayesian embedded spherical topic model (ESTM) that combines both knowledge graph and word embeddings in a non-Euclidean curved space, the hypersphere, for better topic interpretability and discriminative text representations. Extensive experimental results show that our proposed model successfully uncovers interpretable topics and learns high-quality text representations useful for common natural language processing (NLP) tasks across multiple benchmark datasets. IEEE;IEEE;2021;10.1109/tnnls.2021.3112045;Ennajari H., Bouguila N., Bentahar J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115694717&doi=10.1109%2fTNNLS.2021.3112045&partnerID=40&md5=5cf7516967e1be91eb22e3d31399d4de;Canada;text analysis;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;natural language inference using evidence from knowledge graphs;"Knowledge graphs; Natural Language Inference; Natural language processing; Neural networks";Knowledge plays an essential role in inference, but is less explored by previous works in the Natural Language Inference (NLI) task. Although traditional neural models obtained impressive performance on standard benchmarks, they often encounter performance degradation when being applied to knowledge-intensive domains like medicine and science. To address this problem and further fill the knowledge gap, we present a simple Evidence-Based Inference Model (EBIM) to integrate clues collected from knowledge graphs as evidence for inference. To effectively incorporate the knowledge, we propose an efficient approach to retrieve paths in knowledge graphs as clues and then prune them to avoid involving too much irrelevant noise. In addition, we design a specialized CNN-based encoder according to the structure of clues to better model them. Experiments show that the proposed encoder outperforms strong baselines, and our EBIM model outperforms other knowledge-based approaches on the SciTail benchmark and establishes a new state-of-the-art performance on the MedNLI dataset. © 2021, Springer Nature Singapore Pte Ltd.;Scopus;2021;10.1007/978-981-16-5943-0_1;Jia B., Xu H., Guo M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115693431&doi=10.1007%2f978-981-16-5943-0_1&partnerID=40&md5=39cef3af4016f1cedf2f9a2873da531c;China;natural language inference;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;cbench: towards better evaluation of question answering knowledge graphs;"Artificial intelligence; Benchmarking; Graphic methods; Natural language processing systems; Quality control; Query languages; Query processing; Structural properties; Syntactics; Expert users; Fine grained; Knowledge graphs; Natural languages; Property; QA system; Question Answering; Question answering systems; Structured queries; Structured Query Language; Knowledge graph";Recently, there has been an increase in the number of knowledge graphs that can be only queried by experts. However, describing questions using structured queries is not straightforward for non-expert users who need to have sufficient knowledge about both the vocabulary and the structure of the queried knowledge graph, as well as the syntax of the structured query language used to describe the user’s information needs. The most popular approach introduced to overcome the aforementioned challenges is to use natural language to query these knowledge graphs. Although several question answering benchmarks can be used to evaluate question-answering systems over a number of popular knowledge graphs, choosing a benchmark to accurately assess the quality of a question answering system is a challenging task. In this paper, we introduce CBench, an extensible, and more informative benchmarking suite for analyzing benchmarks and evaluating question answering systems. CBench can be used to analyze existing benchmarks with respect to several fine-grained linguistic, syntactic, and structural properties of the questions and queries in the benchmark. We show that existing benchmarks vary significantly with respect to these properties deeming choosing a small subset of them unreliable in evaluating QA systems. Until further research improves the quality and comprehensiveness of benchmarks, CBench can be used to facilitate this evaluation using a set of popular benchmarks that can be augmented with other user-provided benchmarks. CBench not only evaluates a question answering system based on popular single-number metrics but also gives a detailed analysis of the linguistic, syntactic, and structural properties of answered and unanswered questions to better help the developers of question answering systems to better understand where their system excels and where it struggles. © 2021, VLDB Endowment. All rights reserved.;Scopus;2021;10.14778/3457390.3457398;Orogat A., Liu I., El-Roby A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115299221&doi=10.14778%2f3457390.3457398&partnerID=40&md5=166f214eb8cc635f55359211a1100b16;Canada;question answering;validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;tebc-net: an effective relation extraction approach for simple question answering over knowledge graphs;"Deep learning; Knowledge graph simple question answering; Natural language processing; Relation extraction; TEBC-Net";Knowledge graph simple question answering (KGSQA) aims on answering natural language questions by the lookup of a single fact over a knowledge graph. As one of the core tasks in the scenarios, relation extraction is critical for the quality of final answers. To improve the accuracy of relation extraction in KGSQA, in this paper, we propose a new deep neural network model called TEBC-Net, which is constructed based on the combination of Transformer Encoder, BiLSTM and CNN Net in a seamless way. We give the detailed design of our approach and have conducted an experimental evaluation with a benchmark test. Our results demonstrate that TEBC-Net can achieve higher accuracy on relation extraction and question answering tasks in KGSQA, compared to some current methods including the state-of-the-art. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-82136-4_13;Li J., Qu K., Yan J., Zhou L., Cheng L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113775264&doi=10.1007%2f978-3-030-82136-4_13&partnerID=40&md5=29b4838537e397a9335822e376fa67ec;China, Ireland;"relation extraction; question answering";validation research;tool;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;semantic data transformation;"Knowledge creation; Knowledge graph; Machine learning; RDF; Semantic data";Data transformation from diverse formats to semantic data is a major challenge that is being addressed by commercial products available in the market to some extent. However, the transformation process still requires considerable effort from users. Knowledge creation, which is one of the major steps in knowledge graph (KG) maintenance, needs existing data transformation from various formats to RDF (Resource Description Framework) data. Current data transformation approaches are either manual or through mappings. This work presents a semantic data transformation approach for knowledge creation that is semi-automatic requiring minimum possible input from users and does so with machine learning and natural language processing techniques. © 2021 CEUR-WS. All rights reserved.;Scopus;2021;;De Oliveira J., Khan H.A., Curé O., Calvez P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112110912&partnerID=40&md5=620af872d2c17d4ed8348a8100fae4ef;France;"relation extraction; entity extraction";solution proposal;method;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;chinese verb-object collocation knowledge graph construction and application;"Ontology construction; Semantic relational framework; Verb-object collocation extraction; Verb-Object Collocation Knowledge Graph";Verb is the core of a sentence. It can not only reflect the syntactic structure and semantic framework of the whole sentence, but also restrict the nominal elements which co-exist with them. They play a significant role in sentence. Verb-Object Collocation has received more and more attention owing to its high frequency, complexity and flexibility of using. Domestic researches on verb object collocation mainly focus on automatic recognition and construction of corresponding collocation knowledge base. Nevertheless, most of the existing Verb-Object Collocation knowledge base lacks semantic information and classification information. Thus, the application scenarios will be greatly limited. It cannot meet the semantic needs of natural language processing, either. In view of this situation, this paper deeply analyzes the semantic relationship of Verb-Object Collocation, and uses the related technology of knowledge graph to construct a Verb-Object Collocation Knowledge Graph, which obtains 40704 specific examples of Verb-Object Collocation and 20000 extraction templates of Verb-Object Collocation. At the same time, this paper constructs a Verb-Object Collocation Knowledge Graph to manage and maintain our knowledge through two parts: ontology layer and data layer. Finally, the effectiveness of the Verb-Object Collocation Knowledge Graph is verified on the task of entity recognition. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-78615-1_19;Zhao Y., Li Y., Shao Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112033341&doi=10.1007%2f978-3-030-78615-1_19&partnerID=40&md5=8071b36663a80aae8ee6ece7c2b1399e;China;"entity extraction; relation extraction; ontology construction";solution proposal;"method; resource";;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;extracting relations in texts with concepts of neighbours;"Deep learning; Information analysis; Knowledge representation; Learning systems; Natural language processing systems; Syntactics; Human interactions; Knowledge graphs; Learning methods; Named entities; NAtural language processing; Relation extraction; State-of-the-art performance; Syntactic structure; Formal concept analysis";During the last decade, the need for reliable and massive Knowledge Graphs (KG) increased. KGs can be created in several ways: manually with forms or automatically with Information Extraction (IE), a natural language processing task for extracting knowledge from text. Relation Extraction is the part of IE that focuses on identifying relations between named entities in texts, which amounts to find new edges in a KG. Most recent approaches rely on deep learning, achieving state-of-the-art performances. However, those performances are still too low to fully automatize the construction of reliable KGs, and human interaction remains necessary. This is made difficult by the statistical nature of deep learning methods that makes their predictions hardly interpretable. In this paper, we present a new symbolic and interpretable approach for Relation Extraction in texts. It is based on a modeling of the lexical and syntactic structure of text as a knowledge graph, and it exploits Concepts of Neighbours, a method based on Graph-FCA for computing similarities in knowledge graphs. An evaluation has been performed on a subset of TACRED (a relation extraction benchmark), showing promising results. © 2021, Springer Nature Switzerland AG.;Scopus;2021;10.1007/978-3-030-77867-5_10;Ayats H., Cellier P., Ferré S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111431238&doi=10.1007%2f978-3-030-77867-5_10&partnerID=40&md5=ce822622c48091c74f8d2d72475eb3f6;France;relation extraction;validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;graph-assisted attention for path finding in question answering task;"Attention; bAbI dataset; Dynamic memory network; End to end memory network; Graph linearization; Knowledge graph; Path finding task; Question answering";Attention-based memory networks, a class of deep learning algorithms in Natural Language Processing (NLP), capture long-range dependencies present in text data and is a popular recipe in currently available question answering (QA) systems. However, multi-hop QA systems pose additional challenges that these memory networks cannot comfortably handle with their attention spans. Path-finding tasks are a flavor of such multi-hop QA, and it does not have the additional complexity of implicit reasoning. A directed knowledge graph of entities, built from any text corpus, can capture both direction and implicit reasoning. This work attempts to address the bottleneck faced by sophisticated memory network implementations on a dataset that is appropriate for solving such path-finding tasks over multiple hops. It uses the knowledge graph approach for the directional information to address the search challenge in path finding. The experiments conducted using this approach have produced impressive results and can be extended in the future for higher-order challenges that consist of implicit reasoning. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.;Scopus;2021;10.1007/978-981-15-9774-9_68;Guruprasad M., Agarwal J., Lokesh Kumar T.N., Das B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109013013&doi=10.1007%2f978-981-15-9774-9_68&partnerID=40&md5=ea99cb535839584c8326f98fbfef9d17;India;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;two training strategies for improving relation extraction over universal graph;"Computational linguistics; Extraction; Knowledge representation; Attention mechanisms; Knowledge graphs; Neural modeling; Pre-training; Relation extraction; State of the art; Text collection; Training strategy; Arts computing";"This paper explores how the Distantly Supervised Relation Extraction (DS-RE) can benefit from the use of a Universal Graph (UG), the combination of a Knowledge Graph (KG) and a large-scale text collection. A straightforward extension of a current state-of-the-art neural model for DS-RE with a UG may lead to degradation in performance. We first report that this degradation is associated with the difficulty in learning a UG and then propose two training strategies: (1) Path Type Adaptive Pretraining, which sequentially trains the model with different types of UG paths so as to prevent the reliance on a single type of UG path; and (2) Complexity Ranking Guided Attention mechanism, which restricts the attention span according to the complexity of a UG path so as to force the model to extract features not only from simple UG paths but also from complex ones. Experimental results on both biomedical and NYT10 datasets prove the robustness of our methods and achieve a new state-ofthe-art result on the NYT10 dataset. The code and datasets used in this paper are available at https://github.com/baodaiqin/ UGDSRE. © 2021 Association for Computational Linguistics";ACL;2021;;Dai Q., Inoue N., Takahashi R., Inui K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107315579&partnerID=40&md5=c424387b6941ddb1decdff3e741a8211;Japan, United States;relation extraction;validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;conversational question answering over knowledge graphs with transformer and graph attention networks;"Computational linguistics; Knowledge representation; Semantics; Attention model; Entity recognition; Knowledge graphs; Logical forms; Question Answering; Semantic parsing; State of the art; Transformer modeling; Complex networks";"This paper addresses the task of (complex) conversational question answering over a knowledge graph. For this task, we propose LASAGNE (muLti-task semAntic parSing with trAnsformer and Graph atteNtion nEtworks). It is the first approach, which employs a transformer architecture extended with Graph Attention Networks for multi-task neural semantic parsing. LASAGNE uses a transformer model for generating the base logical forms, while the Graph Attention model is used to exploit correlations between (entity) types and predicates to produce node representations. LASAGNE also includes a novel entity recognition module which detects, links, and ranks all relevant entities in the question context. We evaluate LASAGNE on a standard dataset for complex sequential question answering, on which it outperforms existing baseline averages on all question types. Specifically, we show that LASAGNE improves the F1-score on eight out of ten question types; in some cases, the increase in F1-score is more than 20% compared to the state of the art. © 2021 Association for Computational Linguistics";ACL;2021;;Kacupaj E., Plepi J., Singh K., Thakkar H., Lehmann J., Maleshkova M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107293854&partnerID=40&md5=815093af9a707bd0294af27c66c66de1;Germany;"conversational interfaces; question answering; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;joint learning of representations for web-tables, entities and types using graph convolutional network;"Benchmarking; Computational linguistics; Convolution; Embeddings; Knowledge representation; Syntactics; Benchmark datasets; Convolutional networks; GraphicaL model; Joint learning; Knowledge graphs; Multiple state; Syntactic structure; Web tables; Convolutional neural networks";Existing approaches for table annotation with entities and types either capture the structure of table using graphical models, or learn embeddings of table entries without accounting for the complete syntactic structure. We propose TabGCN, which uses Graph Convolutional Networks to capture the complete structure of tables, knowledge graph and the training annotations, and jointly learns embeddings for table elements as well as the entities and types. To account for knowledge incompleteness, TabGCN's embeddings can be used to discover new entities and types. Using experiments on 5 benchmark datasets, we show that TabGCN significantly outperforms multiple state-of-the-art baselines for table annotation, while showing promising performance on downstream table-related applications. © 2021 Association for Computational Linguistics;ACL;2021;;Pramanick A., Bhattacharya I.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107282503&partnerID=40&md5=6fb6b4f0ff73a69c338af18f7347d97e;;entity classification;validation research;technique;;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;coco-ex: a tool for linking concepts from texts to conceptnet;"Computational linguistics; Graph structures; Graph theory; Knowledge representation; ConceptNet; Extracting concept; Freeforms; Knowledge graphs; Natural language text; String matching; Data mining";"In this paper we present COCO-EX, a tool for Extracting Concepts from texts and linking them to the ConceptNet knowledge graph. COCO-EX extracts meaningful concepts from natural language texts and maps them to conjunct concept nodes in ConceptNet, utilizing the maximum of relational information stored in the ConceptNet knowledge graph. COCO-EX takes into account the challenging characteristics of ConceptNet, namely that - unlike conventional knowledge graphs - nodes are represented as non-canonicalized, free-form text. This means that i) concepts are not normalized; ii) they often consist of several different, nested phrase types; and iii) many of them are uninformative, over-specific, or misspelled. A commonly used shortcut to circumvent these problems is to apply string matching. We compare COCO-EX to this method and show that COCO-EX enables the extraction of meaningful, important rather than overspecific or uninformative concepts, and allows to assess more relational information stored in the knowledge graph. © 2021 Association for Computational Linguistics";ACL;2021;;Becker M., Korfhage K., Frank A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107282443&partnerID=40&md5=bf9c125f24319e7264ffc336123d4791;Germany;"entity extraction; entity linking";validation research;tool;;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;lome: large ontology multilingual extraction;"Knowledge representation; Co-reference resolutions; Knowledge graphs; Multilingual trainings; Relation extraction; State of the art; Temporal relation; Text document; Third parties; Computational linguistics";We present Lome, a system for performing multilingual information extraction. Given a text document as input, our core system identifies spans of textual entity and event mentions with a FrameNet (Baker et al., 1998) parser. It subsequently performs coreference resolution, fine-grained entity typing, and temporal relation prediction between events. By doing so, the system constructs an event and entity focused knowledge graph. We can further apply third-party modules for other types of annotation, like relation extraction. Our (multilingual) first-party modules either outperform or are competitive with the (monolingual) state-of-the-art. We achieve this through the use of multilingual encoders like XLM-R (Conneau et al., 2020) and leveraging multilingual training data. Lome is available as a Docker container on Docker Hub. In addition, a lightweight version of the system is accessible as a web demo. © 2021 Association for Computational Linguistics;ACL;2021;;Xia P., Qin G., Vashishtha S., Chen Y., Chen T., May C., Harman C., Rawlins K., White A.S., van Durme B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107282328&partnerID=40&md5=0d2242fdaff90b4f240f8baae701e87a;United States;"entity extraction; entity classification; relation extraction; relation classification";validation research;tool;;1;1;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;identify, align, and integrate: matching knowledge graphs to commonsense reasoning tasks;"Computational linguistics; Integration; Commonsense reasoning; External knowledge; Human evaluation; Knowledge gaps; Knowledge graphs; Knowledge integration; Knowledge tasks; Peak performance; Knowledge representation";Integrating external knowledge into commonsense reasoning tasks has shown progress in resolving some, but not all, knowledge gaps in these tasks. For knowledge integration to yield peak performance, it is critical to select a knowledge graph (KG) that is well-aligned with the given task's objective. We present an approach to assess how well a candidate KG can correctly identify and accurately fill in gaps of reasoning for a task, which we call KG-to-task match. We show this KG-to-task match in 3 phases: knowledge-task identification, knowledge-task alignment, and knowledge-task integration. We also analyze our transformer-based KG-to-task models via commonsense probes to measure how much knowledge is captured in these models before and after KG integration. Empirically, we investigate KG matches for the SocialIQA (SIQA) (Sap et al., 2019b), Physical IQA (PIQA) (Bisk et al., 2020), and MCScript2.0 (Ostermann et al., 2019) datasets with 3 diverse KGs: ATOMIC (Sap et al., 2019a), ConceptNet (Speer et al., 2017), and an automatically constructed instructional KG based on WikiHow (Koupaee and Wang, 2018). With our methods we are able to demonstrate that ATOMIC, an event-inference focused KG, is the best match for SIQA and MCScript2.0, and that the taxonomic ConceptNet and WikiHow-based KGs are the best matches for PIQA across all 3 analysis phases. We verify our methods and findings with human evaluation. © 2021 Association for Computational Linguistics;ACL;2021;;Bauer L., Bansal M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107268857&partnerID=40&md5=1a3d30a6d333c1d466373512665e1c17;United States;"augmented language models; natural language inference";validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;complex question answering on knowledge graphs using machine translation and multi-task learning;"Computational linguistics; Computer aided language translation; Knowledge representation; Multi-task learning; Natural language processing systems; Complex questions; Experimental analysis; Industrial settings; Machine translations; Natural languages; Question Answering; Sequential manners; Traditional approaches; Learning systems";Question answering (QA) over a knowledge graph (KG) is a task of answering a natural language (NL) query using the information stored in KG. In a real-world industrial setting, this involves addressing multiple challenges including entity linking, multi-hop reasoning over KG, etc. Traditional approaches handle these challenges in a modularized sequential manner where errors in one module lead to the accumulation of errors in downstream modules. Often these challenges are inter-related and the solutions to them can reinforce each other when handled simultaneously in an end-to-end learning setup. To this end, we propose a multi-task BERT based Neural Machine Translation (NMT) model to address these challenges. Through experimental analysis, we demonstrate the efficacy of our proposed approach on one publicly available and one proprietary dataset. © 2021 Association for Computational Linguistics;ACL;2021;;Srivastava S., Patidar M., Chowdhury S., Agarwal P., Bhattacharya I., Shroff G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107260439&partnerID=40&md5=c373d59afaff7a0f2c643c3999a4ce8c;India;"question answering; machine translation";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;cross-lingual entity alignment with incidental supervision;"Alignment; Computational linguistics; Iterative methods; Knowledge representation; Learning systems; Benchmark datasets; Embedding method; Knowledge graphs; Learning process; Monolingual texts; Real-world objects; Research efforts; State-of-the-art methods; Embeddings";Much research effort has been put to multilingual knowledge graph (KG) embedding methods to address the entity alignment task, which seeks to match entities in different language-specific KGs that refer to the same real-world object. Such methods are often hindered by the insufficiency of seed alignment provided between KGs. Therefore, we propose an incidentally supervised model, JEANS, which jointly represents multilingual KGs and text corpora in a shared embedding scheme, and seeks to improve entity alignment with incidental supervision signals from text. JEANS first deploys an entity grounding process to combine each KG with the monolingual text corpus. Then, two learning processes are conducted: (i) an embedding learning process to encode the KG and text of each language in one embedding space, and (ii) a self-learning based alignment learning process to iteratively induce the matching of entities and that of lexemes between embeddings. Experiments on benchmark datasets show that JEANS leads to promising improvement on entity alignment with incidental supervision, and significantly outperforms state-of-the-art methods that solely rely on internal information of KGs. © 2021 Association for Computational Linguistics;ACL;2021;;Chen M., Shi W., Zhou B., Roth D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106367685&partnerID=40&md5=6ce87ce9d8dab67a1d80ecba9685f668;United States;"entity alignment; knowledge graph embedding";validation research;technique;;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;cogcn: combining co-attention with graph convolutional network for entity linking with knowledge graphs;"co-attention mechanism; entity linking; graph convolutional network; knowledge graphs";Entity linking is a fundamental task in natural language processing. The task of entity linking with knowledge graphs aims at linking mentions in text to their correct entities in a knowledge graph like DBpedia or YAGO2. Most of existing methods rely on hand-designed features to model the contexts of mentions and entities, which are sparse and hard to calibrate. In this paper, we present a neural model that first combines co-attention mechanism with graph convolutional network for entity linking with knowledge graphs, which extracts features of mentions and entities from their contexts automatically. Specifically, given the context of a mention and one of its candidate entities' context, we introduce the co-attention mechanism to learn the relatedness between the mention context and the candidate entity context, and build the mention representation in consideration of such relatedness. Moreover, we propose a context-aware graph convolutional network for entity representation, which takes both the graph structure of the candidate entity and its relatedness with the mention context into consideration. Experimental results show that our model consistently outperforms the baseline methods on five widely used datasets. © 2020 John Wiley & Sons Ltd;Scopus;2021;10.1111/exsy.12606;Jia N., Cheng X., Su S., Ding L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089248180&doi=10.1111%2fexsy.12606&partnerID=40&md5=a1fae4689af755a2ea63a664542f010a;China;entity linking;validation research;technique;;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;relation extraction using language model based on knowledge graph;"Knowledge graph; Language model; Relation extraction";Relation extraction is an important task in natural language processing (NLP). The existing methods generally pay more attention on extracting textual semantic information from text, but ignore the relation contextual information from existed relations in datasets, which is very important for the performance of relation extraction task. In this paper, we represent each individual entity as a embedding based on entities and relations knowledge graph, which encodes the relation contextual information between the given entity pairs and relations. Besides, inspired by the impressive performance of language models recently, we used the language model to leverage word semantic information, in which word semantic information can be better captured than word embedding. The experimental results on SemEval2010 Task 8 dataset showed that the F1-score of our proposed method improved nearly 3% compared with the previous methods. © 2020 Institute of Physics Publishing. All rights reserved.;Scopus;2020;10.1088/1742-6596/1624/2/022037;Xing C., Liu X., Du D., Hu W., Zhang M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096414931&doi=10.1088%2f1742-6596%2f1624%2f2%2f022037&partnerID=40&md5=8dabd909fb79c05a8f685bdafcfba007;China;"relation extraction; augmented language models";validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a review of knowledge graph technology in the field of automatic question answering;"automatic question answering system; knowledge graph; knowledge system; natural language processing";The automatic question answering (QA) system is a typical natural language processing task. How to make the automatic question answering system more intelligent is a popular research direction in the field of natural language processing. In this era of information explosion, the multisource of data itself makes it difficult to integrate and manage. To solve such problems, it is particularly important to construct and present a complete knowledge system. The knowledge graph (KG) shows real-world knowledge through highly structured graphs. Based on the concept of KG, this paper introduces the classification and research status of KG, focuses on the application of knowledge graph in the field of automatic QA, explains the key technologies in the process of constructing knowledge graph, and finally shows the application of knowledge graph in other fields. © 2020 IEEE.;IEEE;2020;10.1109/ispcem52197.2020.00042;Zhang F., Zhang Y., Xu T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114208400&doi=10.1109%2fISPCEM52197.2020.00042&partnerID=40&md5=e400a205a6e5615e7fd8af8e585a9864;China;question answering;secondary research;"method; guidelines";;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;kbaa: an adversarial example generation method for kbqa task;"adversarial example generation; KBQA task; Knowledge based adversarial attack; NLP model";The adversarial example generation algorithm is currently a very popular algorithm for deceiving machine learning. The main method is to change the original sample in a way that is almost imperceptible to the user, and cause an obvious error in the result returned by the model. At present, there are many adversarial algorithms for computer vision, but there are few for NLP models, and there is almost no algorithm for Question Answer task. This paper designs a framework of adversarial example generation algorithm KBAA(Knowledge-based Adversarial Attack), which is a black box attack, and is against KBQA (Knowledge-based Question Answer). By extracting the knowledge graph of the original sample (attribute value is null, Entity-Attribute-(null)), the algorithm chooses the more important one of Entity and Attribute in the original sample and generates an adversarial example in order to deceive the KBQA model. © 2020 IEEE.;IEEE;2020;10.1109/dsa51864.2020.00056;Guo S., Wang S., Liu B., Shi T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100577390&doi=10.1109%2fDSA51864.2020.00056&partnerID=40&md5=69daa994567a2ecaaa3f213d97fc9def;China;"question generation; question answering";solution proposal;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a study of pre-trained language models in natural language processing;"BERT; Cross-modal; Embedding; KG; Natural Language Generation; Pre-trained";Pre-trained Language Model (PLM) is a very popular topic in natural language processing (NLP). It is the rapid development of pre-trained language models (PLMs) that has led to the achievements of natural language today. In this article, we give a review of important PLMs. First, we generally introduce the development history and achievements of PLMs. Second, we present several extraordinary PLMs, including BERT, the variants of BERT, Multimodal PLMs, PLMs combined with Knowledge Graph and PLMs applied to natural language generation. In the end, we summarize and look into the future of PLMs. We expect this article will provide a practical guide for learners to understanding, using and developing PLMs with the abundant literature existing for various NLP tasks. © 2020 IEEE.;IEEE;2020;10.1109/smartcloud49737.2020.00030;Duan J., Zhao H., Zhou Q., Qiu M., Liu M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098480175&doi=10.1109%2fSmartCloud49737.2020.00030&partnerID=40&md5=4a4a4dbd5141f5b890522c963ff07ad1;China, United States;"augmented language models; text generation";secondary research;guidelines;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;winfra: a web-based platform for semantic data retrieval and data analytics;"Association rules; Data mining; Heterogeneous data federation; Knowledge graph; Natural language processing; RDF";Given the huge amount of heterogeneous data stored in different locations, it needs to be federated and semantically interconnected for further use. This paper introduces WINFRA, a comprehensive open-access platform for semantic web data and advanced analytics based on natural language processing (NLP) and data mining techniques (e.g., association rules, clustering, classification based on associations). The system is designed to facilitate federated data analysis, knowledge discovery, information retrieval, and new techniques to deal with semantic web and knowledge graph representation. The processing step integrates data from multiple sources virtually by creating virtual databases. Afterwards, the developed RDF Generator is built to generate RDF files for different data sources, together with SPARQL queries, to support semantic data search and knowledge graph representation. Furthermore, some application cases are provided to demonstrate how it facilitates advanced data analytics over semantic data and showcase our proposed approach toward semantic association rules. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.;Scopus;2020;10.3390/math8112090;Ait-Mlouk A., Vu X.-S., Jiang L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096502286&doi=10.3390%2fmath8112090&partnerID=40&md5=7d7621948f38b3dbe5c2d4dccf37e982;Sweden;"entity extraction; entity linking; semantic search";solution proposal;tool;;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1
Journal Article;relation classification via knowledge graph enhanced transformer encoder;"Knowledge graph embedding; Relation classification; Transformer";Relation classification is an important task in natural language processing fields. The goal is to predict predefined relations for the marked nominal pairs in given sentences. State-of-the-art works usually focus on using deep neural networks as classifier to conduct the relation prediction. The rich semantic information of relationships in the triples of existing knowledge graph (KG) can be used as additional supervision for relation classification. However, these relationships were simply used as labels to specify the class of sentences in previous works, and their semantic information was completely ignored. In this paper, a novel approach is proposed for relation classification, which jointly uses information from textual sentences and knowledge graphs. To this end, we introduce a Transformer encoder to measure the semantic similarity between sentences and relation types. Besides, we connect the semantic information of marked nominals in sentences with that of the corresponding entities in knowledge graph to generate the semantic matching information between textual relations and KG relations. The matching information can provide additional supervision for relation classification. Since the words and entities are used interactively with each other in our work, we propose an embedding translating strategy to handle the semantic gap problem between word embeddings and entity embeddings. Experimental results on two widely used datasets, SemEval-2010 Task 8 and TACRED, show that our approach is able to efficiently use the semantic information from the knowledge graph to enhance the performance of the Transformer encoder for relation classification. © 2020 Elsevier B.V.;ScienceDirect;2020;10.1016/j.knosys.2020.106321;Huang W., Mao Y., Yang Z., Zhu L., Long J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089218225&doi=10.1016%2fj.knosys.2020.106321&partnerID=40&md5=86586076140461c8cbd7c95cd7997255;China;"relation classification; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;uncovering semantic bias in neural network models using a knowledge graph;"explainable AI; knowledge graphs; neural networks; rule mining";While neural networks models have shown impressive performance in many NLP tasks, lack of interpretability is often seen as a disadvantage. Individual relevance scores assigned by post-hoc explanation methods are not sufficient to show deeper systematic preferences and potential biases of the model that apply consistently across examples. In this paper we apply rule mining using knowledge graphs in combination with neural network explanation methods to uncover such systematic preferences of trained neural models and capture them in the form of conjunctive rules. We test our approach in the context of text classification tasks and show that such rules are able to explain a substantial part of the model behaviour as well as indicate potential causes of misclassifications when the model is applied outside of the initial training context. © 2020 Owner/Author.;Scopus;2020;10.1145/3340531.3412009;Nikolov A., D'Aquin M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095864404&doi=10.1145%2f3340531.3412009&partnerID=40&md5=83d27193d26e776ef22a6c22710015e8;Ireland;text classification;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;evaluating the impact of knowledge graph context on entity disambiguation models;"context; knowledge graph; named entity disambiguation; pretrained transformers; roberta; wikidata; xlnet";Pretrained Transformer models have emerged as state-of-the-art approaches that learn contextual information from the text to improve the performance of several NLP tasks. These models, albeit powerful, still require specialized knowledge in specific scenarios. In this paper, we argue that context derived from a knowledge graph (in our case: Wikidata) provides enough signals to inform pretrained transformer models and improve their performance for named entity disambiguation (NED) on Wikidata KG. We further hypothesize that our proposed KG context can be standardized for Wikipedia, and we evaluate the impact of KG context on the state of the art NED model for the Wikipedia knowledge base. Our empirical results validate that the proposed KG context can be generalized (for Wikipedia), and providing KG context in transformer architectures considerably outperforms the existing baselines, including the vanilla transformer models. © 2020 Owner/Author.;Scopus;2020;10.1145/3340531.3412159;Mulang I.O., Singh K., Prabhu C., Nadgeri A., Hoffart J., Lehmann J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095864148&doi=10.1145%2f3340531.3412159&partnerID=40&md5=0aae68a7daecda8963eaa1d41d366119;Germany, India;entity linking;validation research;technique;;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;denert-kg: named entity and relation extraction model using dqn, knowledge graph, and bert;"BERT; DQN; Knowledge graph; Named entity recognition; Relation extraction";Along with studies on artificial intelligence technology, research is also being carried out actively in the field of natural language processing to understand and process people's language, in other words, natural language. For computers to learn on their own, the skill of understanding natural language is very important. There are a wide variety of tasks involved in the field of natural language processing, but we would like to focus on the named entity registration and relation extraction task, which is considered to be the most important in understanding sentences. We propose DeNERT-KG, a model that can extract subject, object, and relationships, to grasp the meaning inherent in a sentence. Based on the BERT language model and Deep Q-Network, the named entity recognition (NER) model for extracting subject and object is established, and a knowledge graph is applied for relation extraction. Using the DeNERT-KG model, it is possible to extract the subject, type of subject, object, type of object, and relationship from a sentence, and verify this model through experiments. © 2020 by the authors.;Scopus;2020;10.3390/app10186429;Yang S., Yoo S., Jeong O.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092060828&doi=10.3390%2fAPP10186429&partnerID=40&md5=1c93446f778509abe38cf70c4e55d18f;South Korea;"entity extraction; relation extraction; augmented language models";validation research;technique;;1;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;research on key technologies of knowledge graph construction based on natural language processing;"Character recognition; Data mining; Extraction; Knowledge representation; Entity disambiguation; Entity recognition; Keyword extraction; NAtural language processing; Natural Language Processing Tools; Relationship extraction; Word discoveries; Word segmentation; Natural language processing systems";As we all know, building a domain knowledge graph from a large amount of text requires a very large amount of work, including entity recognition, entity disambiguation, relationship extraction, and event extraction, etc. It is difficult to build a very comprehensive domain knowledge graph from scratch. Fortunately, with the rapid progress of natural language processing technology, we can use a large number of natural language processing tools to help us build a domain knowledge graph. This article mainly studies the extraction of domain terms in the process of constructing the knowledge graph. The natural language processing techniques used are mainly new word discovery, word segmentation, and keyword extraction. This paper improves the existing imperfect natural language processing technologies and applies them to the process of constructing the domain knowledge graph in order to construct the domain knowledge graph accurately and efficiently. © Published under licence by IOP Publishing Ltd.;Scopus;2020;10.1088/1742-6596/1601/3/032057;Wang G., Tao Y., Ma H., Bao T., Yang J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091287524&doi=10.1088%2f1742-6596%2f1601%2f3%2f032057&partnerID=40&md5=8136a7566a17df25bc8e470ca2a3eb12;China;entity extraction;validation research;technique;;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;bakgrastec: a background knowledge graph based method for short text classification;"Attention mechanism; Graph neural network; Knowledge graph; Short text";Short text classification is an important task in the area of natural language processing. Recent studies attempt to employ external knowledge to improve classification performance, but they ignore the correlation between external knowledge and have poor interpretability. This paper proposes a novel Background Knowledge Graph based method for Short Text Classification called BaKGraSTeC for short, which can not only employ external knowledge from a knowledge graph to enrich text information, but also utilize its structural information through a graph neural network to promote the understanding of texts. Specifically, we construct a background knowledge graph based on training data, then we propose a novel architecture that integrates background knowledge graph into a graph neural network to model and capture implicit interactions between its concepts and classes. Besides, we propose an attention mechanism considering both similarity and co-occurrence between concepts and classes to identify the informative concepts in texts. Our experimental results demonstrate the effectiveness with good interpretability of BaKGraSTeC through using external knowledge and their structural information for short text classification. © 2020 IEEE.;IEEE;2020;10.1109/icbk50248.2020.00058;Jiang X., Shen Y., Wang Y., Jin X., Cheng X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092540204&doi=10.1109%2fICBK50248.2020.00058&partnerID=40&md5=28597b162dad397d1f03954097471c75;China;text classification;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a knowledge graph embedding method based on neural network;"Knowledge graph; Knowledge graph embedding; Link prediction; Neural network";As the basis of many knowledge graph completion tasks, the embedding representation of entities and relations in knowledge graph (KG) is an important task in the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI). While most of the existing knowledge graph embedding (KGE) models based on convolutional neural network (CNN) can obtain abundant feature embedding, they may ignore an important fact that the triples in the KG come from the text, as they simply learn about the feature embedding of entities and relations without considering contextual information. Therefore, in this paper, we propose an effective KGE model based on neural network. First of all, we convert the triple (h, r, t) of the KG into a sentence [h r t]. Then, the LSTM neural network is used to learn the long-term dependence of sentences from the input feature vectors. Then, on this basis, the two-layer convolutional neural network with several different filters is used to extract different local features. Finally, the obtained feature vectors are connected together, and the inner product is carried out with the weight vectors to obtain the score of the triple, so as to judge the validity of the given triple. We evaluate our model on two benchmark datasets FB15k-237 and WN18RR, the experimental results show that the model can effectively improve the accuracy of link prediction, achieving better results compared with other baseline models. © 2020 IEEE.;IEEE;2020;10.1109/dsc50466.2020.00057;Li C., Li A., Tu H., Wang Y., Wang C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092048856&doi=10.1109%2fDSC50466.2020.00057&partnerID=40&md5=545749b4ee55b53f50734d4c1d62ab15;China;"knowledge graph embedding; link prediction";validation research;technique;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;nmt enhancement based on knowledge graph mining with pre-trained language model;"Knowledge Graph; NMT; Pre-trained Language Model";Pre-trained language models like Bert, RoBERTa, GPT, etc. have achieved SOTA effects on multiple NLP tasks (e.g. sentiment classification, information extraction, event extraction, etc.). We propose a simple method based on knowledge graph to improve the quality of machine translation. First, we propose a multi-task learning model that learns subjects, objects, and predicates at the same time. Second, we treat different predicates as different fields, and improve the recognition ability of NMT models in different fields through classification labels. Finally, beam search combined with L2R, R2L rearranges results through entities. Based on the CWMT2018 experimental data, using the predicate's domain classification identifier, the BLUE score increased from 33.58% to 37.63%, and through L2R, R2L rearrangement, the BLEU score increased to 39.25%, overall improvement is more than 5 percentage. © 2020 Global IT Research Institute - GIRI.;IEEE;2020;10.23919/icact48636.2020.9061292;Yang H., Qin Y., Deng Y., Wang M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083976347&doi=10.23919%2fICACT48636.2020.9061292&partnerID=40&md5=cc951d3c317a2158323411691da1d742;China;"machine translation; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;greg: a global level relation extraction with knowledge graph embedding;"Knowledge graph; Machine learning; Meta learning; Natural language processing; Relation extraction; Text summarization";In an age overflowing with information, the task of converting unstructured data into structured data are a vital task of great need. Currently, most relation extraction modules are more focused on the extraction of local mention-level relations-usually from short volumes of text. However, in most cases, the most vital and important relations are those that are described in length and detail. In this research, we propose GREG: A Global level Relation Extractor model using knowledge graph embeddings for document-level inputs. The model uses vector representations of mention-level 'local' relation's to construct knowledge graphs that can represent the input document. The knowledge graph is then used to predict global level relations from documents or large bodies of text. The proposed model is largely divided into two modules which are synchronized during their training. Thus, each of the model's modules is designed to deal with local relations and global relations separately. This allows the model to avoid the problem of struggling against loss of information due to too much information crunched into smaller sized representations when attempting global level relation extraction. Through evaluation, we have shown that the proposed model yields high performances in both predicting global level relations and local level relations consistently. © 2020 by the author.;Scopus;2020;10.3390/app10031181;Kim K., Hur Y., Kim G., Lim H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081533252&doi=10.3390%2fapp10031181&partnerID=40&md5=a501a8e89d0ee5616b3f9462a8daade1;South Korea;"relation extraction; knowledge graph embedding";validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;discovering knowledge graph schema from short natural language text via dialog;"Computational linguistics; Active Learning; Dialogue strategy; Generalized binary searches; Knowledge graphs; Language statements; Multi-turn; Natural languages; Natural languages texts; Uncertainty; Uncertainty samplings; Knowledge graph";We study the problem of schema discovery for knowledge graphs. We propose a solution where an agent engages in multi-turn dialog with an expert for this purpose. Each minidialog focuses on a short natural language statement, and looks to elicit the expert's desired schema-based interpretation of that statement, taking into account possible augmentations to the schema. The overall schema evolves by performing dialog over a collection of such statements. We take into account the probability that the expert does not respond to a query, and model this probability as a function of the complexity of the query. For such mini-dialogs with response uncertainty, we propose a dialog strategy that looks to elicit the schema over as short a dialog as possible. By combining the notion of uncertainty sampling from active learning with generalized binary search, the strategy asks the query with the highest expected reduction of entropy. We show that this significantly reduces dialog complexity while engaging the expert in meaningful dialog. © 2020 Association for Computational Linguistics.;ACL;2020;;Ghosh S., Kundu A., Pramanick A., Bhattacharya I.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118464513&partnerID=40&md5=4f8afa6b778a6d12087b213c9aa77ae4;India;"conversational interfaces; ontology construction";validation research;method;;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge-guided open attribute value extraction with reinforcement learning;"Computational linguistics; Natural language processing systems; Reinforcement learning; Attribute values; Extraction accuracy; Information extraction systems; Knowledge graphs; Question Answering Task; Updated informations; Web Corpora; Knowledge graph";Open attribute value extraction for emerging entities is an important but challenging task. A lot of previous works formulate the problem as a question-answering (QA) task. While the collections of articles from web corpus provide updated information about the emerging entities, the retrieved texts can be noisy, irrelevant, thus leading to inaccurate answers. Effectively filtering out noisy articles as well as bad answers is the key to improving extraction accuracy. Knowledge graph (KG), which contains rich, well organized information about entities, provides a good resource to address the challenge. In this work, we propose a knowledge-guided reinforcement learning (RL) framework for open attribute value extraction. Informed by relevant knowledge in KG, we trained a deep Q-network to sequentially compare extracted answers to improve extraction accuracy. The proposed framework is applicable to different information extraction system. Our experimental results show that our method outperforms the baselines by 16.5 - 27.8%. © 2020 Association for Computational Linguistics.;ACL;2020;;Liu Y., Zhang S., Song R., Feng S., Xiao Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118453193&partnerID=40&md5=784222ec90b38b7904c3cce7994ec32e;China, United States;attribute extraction;validation research;technique;;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;conceptbert: concept-aware representation for visual question answering;"Computational linguistics; Natural language processing systems; Visual languages; 'current; Common sense; Direct analysis; Factual knowledge; Knowledge graphs; Modal representation; Multi-modal; Natural languages; Question Answering; Visual elements; Knowledge graph";Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. Current works in VQA focus on questions which are answerable by direct analysis of the question and image alone. We present a concept-aware algorithm, ConceptBert, for questions which require common sense, or basic factual knowledge from external structured content. Given an image and a question in natural language, ConceptBert requires visual elements of the image and a Knowledge Graph (KG) to infer the correct answer. We introduce a multi-modal representation which learns a joint Concept-Vision-Language embedding. We exploit ConceptNet KG for encoding the common sense knowledge and evaluate our methodology on the Outside Knowledge-VQA (OK-VQA) and VQA datasets. Our code is available at https://github.com/ZiaMaryam/ConceptBERT © 2020 Association for Computational Linguistics;ACL;2020;;Gardères F., Ziaeefard M., Abeloos B., Lecue F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118430585&partnerID=40&md5=8fe1049edc7798b913b187323616fe35;Canada, France;"question answering; augmented language models";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;commonsense evidence generation and injection in reading comprehension;"Computational linguistics; Semantics; 'current; Commonsense knowledge; Commonsense reasoning; High-accuracy; Knowledge graphs; Language model; Linguistic units; Reading comprehension; Reasoning models; Semantic relationships; Knowledge graph";"Human tackle reading comprehension not only based on the given context itself but often rely on the commonsense beyond. To empower the machine with commonsense reasoning, in this paper, we propose a Commonsense Evidence Generation and Injection framework in reading comprehension, named CEGI. The framework injects two kinds of auxiliary commonsense evidence into comprehensive reading to equip the machine with the ability of rational thinking. Specifically, we build two evidence generators: one aims to generate textual evidence via a language model; the other aims to extract factual evidence (automatically aligned text-triples) from a commonsense knowledge graph after graph completion. Those evidences incorporate contextual commonsense and serve as the additional inputs to the reasoning model. Thereafter, we propose a deep contextual encoder to extract semantic relationships among the paragraph, question, option, and evidence. Finally, we employ a capsule network to extract different linguistic units (word and phrase) from the relations, and dynamically predict the optimal option based on the extracted units. Experiments on the CosmosQA dataset demonstrate that the proposed CEGI model outperforms the current state-ofthe- art approaches and achieves the highest accuracy (83.6%) on the leaderboard. © 2020 Association for Computational Linguistics.";ACL;2020;;Liu Y., Yang T., You Z., Fan W., Yu P.S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112400683&partnerID=40&md5=beb4c3d7e5ce103f367754e3f5ac9179;United States;"natural language inference; question answering";validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;pathqg: neural question generation from facts;"Computational linguistics; Query processing; End to end; Human evaluation; Knowledge graphs; Novel task; Performance; Query paths; Query representations; Sequence Labeling; State-of-the-art approach; Variational framework; Knowledge graph";Existing research for question generation encodes the input text as a sequence of tokens without explicitly modeling fact information. These models tend to generate irrelevant and uninformative questions. In this paper, we explore to incorporate facts in the text for question generation in a comprehensive way. We present a novel task of question generation given a query path in the knowledge graph constructed from the input text. We divide the task into two steps, namely, query representation learning and query-based question generation. We formulate query representation learning as a sequence labeling problem for identifying the involved facts to form a query and employ an RNN-based generator for question generation. We first train the two modules jointly in an end-to-end fashion, and further enforce the interaction between these two modules in a variational framework. We construct the experimental datasets on top of SQuAD and results show that our model outperforms other state-of-the-art approaches, and the performance margin is larger when target questions are complex. Human evaluation also proves that our model is able to generate relevant and informative questions. © 2020 Association for Computational Linguistics.;ACL;2020;;Wang S., Wei Z., Fan Z., Huang Z., Sun W., Zhang Q., Huang X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109540289&partnerID=40&md5=0858e6c6c56ce1069bcc3c7d8ce02c56;China;"question answering; question generation";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a sentiment-controllable topic-to-essay generator with topic knowledge graph;"Computational linguistics; Decoding; Natural language processing systems; Semantics; Auto encoders; Automatic evaluation; Human evaluation; Knowledge graphs; Natural language generation; Semantics Information; State-of-the-art approach; Topic diversity; Topic relevance; Topic words; Knowledge graph";Generating a vivid, novel, and diverse essay with only several given topic words is a challenging task of natural language generation. In previous work, there are two problems left unsolved: neglect of sentiment beneath the text and insufficient utilization of topic-related knowledge. Therefore, we propose a novel Sentiment-Controllable topic-to-essay generator with a Topic Knowledge Graph enhanced decoder, named SCTKG, which is based on the conditional variational autoencoder (CVAE) framework. We firstly inject the sentiment information into the generator for controlling sentiment for each sentence, which leads to various generated essays. Then we design a Topic Knowledge Graph enhanced decoder. Unlike existing models that use knowledge entities separately, our model treats knowledge graph as a whole and encodes more structured, connected semantic information in the graph to generate a more relevant essay. Experimental results show that our SCTKG can generate sentiment controllable essays and outperform the state-of-the-art approach in terms of topic relevance, fluency, and diversity on both automatic and human evaluation. © 2020 Association for Computational Linguistics;ACL;2020;;Qiao L., Yan J., Meng F., Yang Z., Zhou J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108643415&partnerID=40&md5=4bba9f75387d4fc4e1315fe19d27810e;China;"text generation; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;k-bert: enabling language representation with knowledge graph;"Artificial intelligence; Domain knowledge; Domain specific; Domain-specific knowledge; Knowledge graphs; Knowledge incorporation; Loading models; Pre-training; Representation model; Knowledge representation";Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by being equipped with a KG without pre-training by itself because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;Scopus;2020;;Liu W., Zhou P., Zhao Z., Wang Z., Ju Q., Deng H., Wang P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106402604&partnerID=40&md5=f871a87e7bb104c4921c1497e39c8366;China;augmented language models;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;pretrain-kge: learning knowledge representation from pretrained language models;"Computational linguistics; Knowledge graph; Knowledge management; Knowledge representation; Semantics; Graph embeddings; Knowledge graphs; Knowledge-representation; Language model; Performance degradation; Phase semantics; Three phase; Three phasis; Training framework; World knowledge; Graph embeddings";Conventional knowledge graph embedding (KGE) often suffers from limited knowledge representation, leading to performance degradation especially on the low-resource problem. To remedy this, we propose to enrich knowledge representation via pretrained language models by leveraging world knowledge from pretrained models. Specifically, we present a universal training framework named Pretrain-KGE consisting of three phases: semantic-based fine-tuning phase, knowledge extracting phase and KGE training phase. Extensive experiments show that our proposed Pretrain-KGE can improve results over KGE models, especially on solving the low-resource problem. © 2020 Association for Computational Linguistics;ACL;2020;;Zhang Z., Liu X., Zhang Y., Su Q., Sun X., He B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106358658&partnerID=40&md5=e5da2b0b8b86d1fae0a8ebde4a62aff9;China;knowledge graph embedding;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;exploiting structured knowledge in text via graph-guided representation learning;"Benchmarking; Computational linguistics; Knowledge based systems; Learning systems; Entity-level; Knowledge graphs; Language model; Learn+; Masking schemes; Performance; Pre-training; Question Answering; Structured knowledge; Task learning; Knowledge graph";In this work, we aim at equipping pre-trained language models with structured knowledge. We present two self-supervised tasks learning over raw text with the guidance from knowledge graphs. Building upon entity-level masked language models, our first contribution is an entity masking scheme that exploits relational knowledge underlying the text. This is fulfilled by using a linked knowledge graph to select informative entities and then masking their mentions. In addition, we use knowledge graphs to obtain distractors for the masked entities, and propose a novel distractor-suppressed ranking objective that is optimized jointly with masked language model. In contrast to existing paradigms, our approach uses knowledge graphs implicitly, only during pre-training, to inject language models with structured knowledge via learning from raw text. It is more efficient than retrieval-based methods that perform entity linking and integration during finetuning and inference, and generalizes more effectively than the methods that directly learn from concatenated graph triples. Experiments show that our proposed model achieves improved performance on five benchmarks, including question answering and knowledge base completion. © 2020 Association for Computational Linguistics.;ACL;2020;;Shen T., Mao Y., He P., Long G., Trischler A., Chen W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106164020&partnerID=40&md5=8e6384fcca0ff56f309431419ac32f17;Australia, Canada;augmented language models;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;scalable multi-hop relational reasoning for knowledge-aware question answering;"Computational linguistics; Graph neural networks; Graph theory; Natural language processing systems; Scalability; Based reasonings; External knowledge; Knowledge graphs; Language model; Model prediction; Multi-hops; Path-based; Question Answering; Relational reasoning; Subgraphs; Knowledge graph";Existing work that augment question answering (QA) models with external knowledge (e.g., knowledge graphs) either struggle to model multi-hop relations efficiently, or lack transparency into the model's prediction rationale. In this paper, we propose a novel knowledge-aware approach that equips pretrained language models (PTLMs) with a multi-hop relational reasoning module, named multi-hop graph relation network (MHGRN). It performs multi-hop, multi-relational reasoning over subgraphs extracted from external knowledge graphs. The proposed reasoning module unifies path-based reasoning methods and graph neural networks and results in better interpretability and scalability. We also empirically show its effectiveness and scalability on CommonsenseQA and OpenbookQA datasets, and interpret its behaviors with case studies, with the code for experiments released. © 2020 Association for Computational Linguistics;ACL;2020;;Feng Y., Chen X., Lin B.Y., Wang P., Yan J., Ren X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106108628&partnerID=40&md5=1de6dd7317d0329648c9dd14d033d6a0;China, United States;question answering;validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;seq2kg: an end-to-end neural model for domain agnostic knowledge graph (not text graph) construction from text;"Classification (of information); Deep learning; Deep neural networks; Knowledge based systems; Natural language processing systems; Semantics; Annotated datasets; Downstream applications; Evaluation metrics; Learning neural networks; Multi label classification; NAtural language processing; Statistical pattern; Unstructured texts; Knowledge representation";"Knowledge Graph Construction (KGC) from text unlocks information held within unstructured text and is critical to a wide range of downstream applications. General approaches to KGC from text are heavily reliant on the existence of knowledge bases, yet most domains do not even have an external knowledge base readily available. In many situations this results in information loss as a wealth of key information is held within ""non-entities"". Domain-specific approaches to KGC typically adopt unsupervised pipelines, using carefully crafted linguistic and statistical patterns to extract co-occurred noun phrases as triples, essentially constructing text graphs rather than true knowledge graphs. In this research, for the first time, in the same flavour as Collobert et al.'s seminal work of ""Natural language processing (almost) from scratch"" in 2011, we propose a Seq2KG model attempting to achieve ""Knowledge graph construction (almost) from scratch"". An end-to-end Sequence to Knowledge Graph (Seq2KG) neural model jointly learns to generate triples and resolves entity types as a multi-label classification task through deep learning neural networks. In addition, a novel evaluation metric that takes both semantic and structural closeness into account is developed for measuring the performance of triple extraction. We show that our end-toend Seq2KG model performs on par with a state of the art rule-based system which outperformed other neural models and won the first prize of the first Knowledge Graph Contest in 2019. A new annotation scheme and three high-quality manually annotated datasets are available to help promote this direction of research. © 2020 17th International Conference on Principles of Knowledge Representation and Reasoning, KR 2020. All rights reserved.";Scopus;2020;;Stewart M., Liu W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104651859&partnerID=40&md5=b6bc02d172c25b1db434ecd16ac178c4;Australia;"entity extraction; relation extraction; entity linking";validation research;"tool; resource";;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;combining embedding methods for a word intrusion task;"Embeddings; Knowledge representation; Byte-pair encoding; Embedding method; Individual modeling; Knowledge graphs; Sub words; Natural language processing systems";We report a new baseline for a Danish word intrusion task by combining pre-trained off-the-shelf word, subword and knowledge graph embedding models. We test fastText, Byte-Pair Encoding, BERT and the knowledge graph embedding in Wembedder, finding fastText as the individual model with the superior performance, while a simple combination of the fastText with other models can slightly improve the accuracy of finding the odd-one-out words in the word intrusion task. © 2020 German Society for Computational Linguistics & Language Technology. All Rights Reserved.;Scopus;2020;;Nielsen F.Å., Hansen L.K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103456037&partnerID=40&md5=092fa30e2c207e995d08d3a929692aba;Denmark;"augmented language models; knowledge graph embedding";solution proposal;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;open domain question answering based on text enhanced knowledge graph with hyperedge infusion;"Computational linguistics; Convolution; Convolutional neural networks; Semantics; Convolutional networks; Hyper graph; Hyperedges; Incomplete knowledge; Knowledge graphs; Open domain question answering; Performance; Question Answering; Semantics Information; Text information; Knowledge based systems";The incompleteness of knowledge base (KB) is a vital factor limiting the performance of question answering (QA). This paper proposes a novel QA method by leveraging text information to enhance the incomplete KB. The model enriches the entity representation through semantic information contained in the text, and employs graph convolutional networks to update the entity status. Furthermore, to exploit the latent structural information of text, we treat the text as hyperedges connecting entities among it to complement the deficient relations in KB, and hypergraph convolutional networks are further applied to reason on the hypergraph-formed text. Extensive experiments on the WebQuestionsSP benchmark with different KB settings prove the effectiveness of our model. ©2020 Association for Computational Linguistics;ACL;2020;;Han J., Cheng B., Wang X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103277164&partnerID=40&md5=886b09d592842d3691336ab2d1cbd5fc;China;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;entity hierarchical clustering method based on multi-channel and t-sne dimension reduction;"BERT; Improved hierarchical clustering; Multi-channel; Network embedding; T-SNE";Named entity clustering is a basic work in the field of natural language processing, which is helpful to excavate the implicit relationship between entities. Most of the existing clustering algorithms are unable to combine various features of entities and have some problems such as poor hierarchical clustering analysis. Based on this, this paper proposes a multi-channel dimensionless entity clustering method and carries out experimental verification. A multi-channel framework is constructed, and channels based on knowledge graph, language model and statistics are respectively set up to express the features of entities in objective knowledge, co-existing relationship and different texts. Network embedding method, BERT model and automatic coding machine are respectively used to convert the entities into vector forms. The t-SNE algorithm is used to reduce the dimension and map it to the two-dimensional space, so that it can be expressed visually in the low-dimensional space. An improved hierarchical clustering method is proposed to cluster entities in two-dimensional space and construct hierarchical clustering trees. Experiments show that the F1 value of this algorithm can reach 78.72% at most under the test set. At the same time, through analysis, the algorithm has a strong ability of expansion and generalization. © 2020 IEEE.;IEEE;2020;10.1109/itaic49862.2020.9339166;Feng H., Duan L., Liu S., Liu S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101438555&doi=10.1109%2fITAIC49862.2020.9339166&partnerID=40&md5=698ae7f0dde97b95a1e2fa8ca1f4c30e;China;augmented language models;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an unsupervised joint system for text generation from knowledge graphs and semantic parsing;"Computational linguistics; Graphic methods; Semantics; Different domains; Domain specific; Graph parsing; Joint system; Knowledge extraction; Knowledge graphs; Large amounts; Semantic parsing; Text data; Text generations; Knowledge graph";"Knowledge graphs (KGs) can vary greatly from one domain to another. Therefore supervised approaches to both graph-to-text generation and text-to-graph knowledge extraction (semantic parsing) will always suffer from a shortage of domain-specific parallel graph-text data; at the same time, adapting a model trained on a different domain is often impossible due to little or no overlap in entities and relations. This situation calls for an approach that (1) does not need large amounts of annotated data and thus (2) does not need to rely on domain adaptation techniques to work well in different domains. To this end, we present the first approach to unsupervised text generation from KGs and show simultaneously how it can be used for unsupervised semantic parsing. We evaluate our approach on WebNLG v2.1 and a new benchmark leveraging scene graphs from Visual Genome. Our system outperforms strong baselines for both text↔graph conversion tasks without any manual adaptation from one dataset to the other. In additional experiments, we investigate the impact of using different unsupervised objectives. © 2020 Association for Computational Linguistics.";ACL;2020;;Schmitt M., Sharifzadeh S., Tresp V., Schütze H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100496876&partnerID=40&md5=101d4042f2154ace4ce11f4a68a0b908;Germany;"text generation; semantic parsing";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;self-supervised knowledge triplet learning for zero-shot question answering;"Computational linguistics; 'current; Commonsense knowledge; Data annotation; Knowledge graphs; Question Answering; Question answering systems; Scientific knowledge; Supervised methods; Synthetic graphs; System focus; Knowledge graph";The aim of all Question Answering (QA) systems is to generalize to unseen questions. Current supervised methods are reliant on expensive data annotation. Moreover, such annotations can introduce unintended annotator bias, making systems focus more on the bias than the actual task. This work proposes Knowledge Triplet Learning (KTL), a self-supervised task over knowledge graphs. We propose heuristics to create synthetic graphs for commonsense and scientific knowledge. We propose using KTL to perform zero-shot question answering, and our experiments show considerable improvements over large pre-trained transformer language models. © 2020 Association for Computational Linguistics;ACL;2020;;Banerjee P., Baral C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099810077&partnerID=40&md5=923557d7b4307909d7280409e37ea35d;United States;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;language generation with multi-hop reasoning on commonsense knowledge graph;"Computational linguistics; Flow graphs; Semantics; Commonsense knowledge; Knowledge graphs; Language generation; Language model; Multi-hops; Semantics Information; Structural information; Text generations; Knowledge graph";Despite the success of generative pre-trained language models on a series of text generation tasks, they still suffer in cases where reasoning over underlying commonsense knowledge is required during generation. Existing approaches that integrate commonsense knowledge into generative pre-trained language models simply transfer relational knowledge by post-training on individual knowledge triples while ignoring rich connections within the knowledge graph. We argue that exploiting both the structural and semantic information of the knowledge graph facilitates commonsense-aware text generation. In this paper, we propose Generation with Multi-Hop Reasoning Flow (GRF) that enables pre-trained models with dynamic multi-hop reasoning on multi-relational paths extracted from the external commonsense knowledge graph. We empirically show that our model outperforms existing baselines on three text generation tasks that require reasoning over commonsense knowledge. We also demonstrate the effectiveness of the dynamic multi-hop reasoning module with reasoning paths inferred by the model that provide rationale to the generation. © 2020 Association for Computational Linguistics;ACL;2020;;Ji H., Ke P., Huang S., Wei F., Zhu X., Huang M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098817089&partnerID=40&md5=80402872e9e00ba5fec13b8a9d624528;China;"augmented language models; text generation";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;ent-desc: entity description generation by exploring knowledge graph;"Computational linguistics; Large dataset; Natural language processing systems; 'current; Graph information; Key-value pairs; Knowledge graphs; Language description; Large-scales; Natural languages; RDF triples; Sequence models; Text generations; Knowledge graph";Previous works on knowledge-to-text generation take as input a few RDF triples or key-value pairs conveying the knowledge of some entities to generate a natural language description. Existing datasets, such as WIKIBIO, WebNLG, and E2E, basically have a good alignment between an input triple/pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of information loss and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original graph information more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture. © 2020 Association for Computational Linguistics;ACL;2020;;Cheng L., Wu D., Bing L., Zhang Y., Jie Z., Lu W., Si L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098436623&partnerID=40&md5=8ab49be60e4ae7b308d8bbbec1cd8093;Canada, China, Singapore;data-to-text generation;validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;enriching bert with knowledge graph embeddings for document classification;"Embeddings; Knowledge representation; Metadata; Natural language processing systems; Classification tasks; Coarse-grained; Detailed classification; Document Classification; Knowledge graphs; Language model; Source codes; Text representation; Information retrieval systems";In this paper, we focus on the classification of books using short descriptive texts (cover blurbs) and additional metadata. Building upon BERT, a deep neural language model, we demonstrate how to combine text representations with metadata and knowledge graph embeddings, which encode author information. Compared to the standard BERT approach we achieve considerably better results for the classification task. For a more coarse-grained classification using eight labels we achieve an F1-score of 87.20, while a detailed classification using 343 labels yields an F1-score of 64.70. We make the source code and trained models of our experiments publicly available. © 2020 German Society for Computational Linguistics & Language Technology. All Rights Reserved.;Scopus;2020;;Ostendorff M., Bourgonje P., Berger M., Moreno-Schneider J., Rehm G., Gipp B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098377698&partnerID=40&md5=fe0dd504aa6b69b57e285a77c3dd7e3d;Germany;"text classification; knowledge graph embedding; augmented language models";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;towards knowledge enhanced language model for machine reading comprehension;"BERT; capsule network; knowledge graph embedding; Machine reading comprehension";Machine reading comprehension is a crucial and challenging task in natural language processing (NLP). Recently, knowledge graph (KG) embedding has gained massive attention as it can effectively provide side information for downstream tasks. However, most previous knowledge-based models do not take into account the structural characteristics of the triples in KGs, and only convert them into vector representations for direct accumulation, leading to deficiencies in knowledge extraction and knowledge fusion. In order to alleviate this problem, we propose a novel deep model KCF-NET, which incorporates knowledge graph representations with context as the basis for predicting answers by leveraging capsule network to encode the intrinsic spatial relationship in triples of KG. In KCF-NET, we fine-tune BERT, a highly performance contextual language representation model, to capture complex linguistic phenomena. Besides, a novel fusion structure based on multi-head attention mechanism is designed to balance the weight of knowledge and context. To evaluate the knowledge expression and reading comprehension ability of our model, we conducted extensive experiments on multiple public datasets such as WN11, FB13, SemEval-2010 Task 8 and SQuAD. Experimental results show that KCF-NET achieves state-of-the-art results in both link prediction and MRC tasks with negligible parameter increase compared to BERT-Base, and gets competitive results in triple classification task with significantly reduced model size. © 2013 IEEE.;IEEE;2020;10.1109/access.2020.3044308;Gong P., Liu J., Yang Y., He H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098272414&doi=10.1109%2fACCESS.2020.3044308&partnerID=40&md5=d21eb52d52816118ac8b83407888c247;China;"question answering; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;creativity embedding: a vector to characterise and classify plausible triples in deep learning nlp models;"BERT; Creativity embedding; Creativity evaluation; Creativity metric; Knowledge graph; NLP; Triple";In this paper we define the creativity embedding of a text based on four self-assessment creativity metrics, namely diversity, novelty, serendipity and magnitude, knowledge graphs, and neural networks. We use as basic unit the notion of triple (head, relation, tail). We investigate if additional information about creativity improves natural language processing tasks. In this work, we focus on triple plausibility task, exploiting BERT model and a WordNet11 dataset sample. Contrary to our hypothesis, we do not detect increase in the performance. Copyright © 2020 for this paper by its authors.;Scopus;2020;;Oliveri I., Ardito L., Rizzo G., Morisio M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097864462&partnerID=40&md5=a6d41c3076df8406bafc12883a8154da;Italy;"triple classification; augmented language models";solution proposal;technique;;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;creative storytelling with language models and knowledge graphs;"Knowledge graph; Language model; Natural language generation; Story generation";Automated story generation is a popular and well-recognized task in the field of natural language processing. The emergence of pre-trained language models based on large Transformer architectures shows the great capability of text generation. However, language models are limited when the generation requires explicit clues within the context. In this research, we study how to combine knowledge graphs with language models, and build a creative story generation system named DICE. DICE uses external knowledge graphs to provide context clues and implicit knowledge to generate coherent and creative stories. The evaluation shows that our approach can effectively inject the knowledge from knowledge graphs into the stories automatically generated by the language model. © 2020 CEUR-WS. All rights reserved.;Scopus;2020;;Yang X., Tiddi I.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097546218&partnerID=40&md5=3914a7c1b9edb0fdd9c889dd3a8ed304;Netherlands;"text generation; augmented language models";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;active learning based relation classification for knowledge graph construction from conversation data;"Active learning; Deep learning; Knowledge Graph; Relation classification";Creation of a Knowledge Graph (KG) from text, and its usages in solving several Natural Language Processing (NLP) problems are emerging research areas. Creating KG from text is a challenging problem which requires several NLP modules working together in unison. This task becomes even more challenging when constructing knowledge graph from a conversational data, as user and agent stated facts in conversations are often not grounded and can change with dialogue turns. In this paper, we explore KG construction from conversation data in travel and taxi booking domains. We use a fixed ontology for each of the conversation domain, and extract the relation triples from the conversation. Using active learning technique we build a state-of-the-art BERT based relation classifier which uses minimal data, but still performs accurate classification of the extracted relation triples. We further design heuristics for constructing KG that uses the BERT based relation classifier and Semantic Role Labelling (SRL) for handling negations in extracted relationship triples. Through our experiments we show that using our active learning trained classifier and heuristic based method, KG can be built with good correctness and completeness scores for domain specific conversational datasets. To the best of our knowledge this is the very first attempt at creating a KG from the conversational data that could be efficiently augmented in a dialogue agent to tackle the issue of data sparseness and improve the quality of generated response. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-63820-7_70;Ahmad Z., Ekbal A., Sengupta S., Mitra A., Rammani R., Bhattacharyya P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097300161&doi=10.1007%2f978-3-030-63820-7_70&partnerID=40&md5=c9f91fb7871307866236c0f9b727756f;India;"entity extraction; relation extraction; relation classification";validation research;technique;;1;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;enhancing online knowledge graph population with semantic knowledge;"Data validation; Knowledge Graph; Relation extraction";Knowledge Graphs (KG) are becoming essential to organize, represent and store the world’s knowledge, but they still rely heavily on humanly-curated structured data. Information Extraction (IE) tasks, like disambiguating entities and relations from unstructured text, are key to automate KG population. However, Natural Language Processing (NLP) methods alone can not guarantee the validity of the facts extracted and may introduce erroneous information into the KG. This work presents an end-to-end system that combines Semantic Knowledge and Validation techniques with NLP methods, to provide KG population of novel facts from clustered news events. The contributions of this paper are two-fold: First, we present a novel method for including entity-type knowledge into a Relation Extraction model, improving F1-Score over the baseline with TACRED and TypeRE datasets. Second, we increase the precision by adding data validation on top of the Relation Extraction method. These two contributions are combined in an industrial pipeline for automatic KG population over aggregated news, demonstrating increased data validity when performing online learning from unstructured web data. Finally, the TypeRE and AggregatedNewsRE datasets build to benchmark these results are also published to foster future research in this field. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-62419-4_11;Fernàndez-Cañellas D., Marco Rimmek J., Espadaler J., Garolera B., Barja A., Codina M., Sastre M., Giro-i-Nieto X., Riveiro J.C., Bou-Balust E.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096586450&doi=10.1007%2f978-3-030-62419-4_11&partnerID=40&md5=89e6fb51a6cf9c7f078e5c892263d42d;Spain;"entity extraction; relation extraction";validation research;method;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Journal Article;building a knowledge graph by using cross-lingual transfer method and distributed minie algorithm on apache spark;"Cross-lingual transfer method; Distributed MinIE; Knowledge graph; Natural language processing; Triples extraction";The simplest and effective way to store human knowledge through centuries was using text. Along with the advancement of technology nowadays, the volume of text has grown to be larger and larger. To extract useful information from this amount of text becomes an exceptionally complex task. As an effort to solve that problem, in this paper, we present a pipeline to extract core knowledge from large quantity text using distributed computing. The components of our pipeline are systems that were known to yield good results. The outputs of our proposed system are stored in a knowledge graph. A knowledge graph is a graph for storing knowledge in the form of triples (head, relation, tail). Some of the existing knowledge graphs in the world are Google knowledge graph, YAGO, DBLP, or DBpedia. These knowledge graphs have one thing in common—they are in English. The English language is studied by many researchers in the world and it had become a rich-resource language (with many natural language processing tools and data set). Vietnamese, on the other hand, is a low-resource language. Therefore, we use cross-lingual transfer method to build a Vietnamese knowledge graph. Firstly, we collect data in form of text about Vietnam tourism, which was written mostly in Vietnamese, using Google search and Wikipedia. In the next step, we translate them into English with Google Translate and use English Natural Language Processing tools like Stanford Parser, Co-referencing, ClausIE, MinIE to extract useful triples from this text. Lastly, the triples are translated back to Vietnamese to build a Vietnam tourism knowledge graph. Since we are working with massive text, we develop a distributed algorithm to extract triples from sentences of massive text. This is a distributed version of MinIE, which was originally developed for a single machine model. In Apache Spark framework, we divide massive text into many smaller parts and move them to the worker nodes with distributed MinIE function. Spark distributed MinIE will extract the triples of sentences in the local text of this worker node in parallel. Finally, the result of worker nodes will be sent back to the master node for building the knowledge graph. We conduct experiments with the distributed MinIE on spark cluster to prove the outperformance of our proposed algorithm. © 2020, Springer-Verlag London Ltd., part of Springer Nature.;Scopus;2020;10.1007/s00521-020-05495-1;Do P., Phan T., Le H., Gupta B.B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096524024&doi=10.1007%2fs00521-020-05495-1&partnerID=40&md5=83d0cfd07ec524a4d0e1814edcfea6a1;United Kingdom, India, Vietnam;"entity extraction; relation extraction";validation research;method;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;1
Conference Paper;knowlybert - hybrid query answering over language models and knowledge graphs;"Knowledge graphs; Language models; Query answering";Providing a plethora of entity-centric information, Knowledge Graphs have become a vital building block for a variety of intelligent applications. Indeed, modern knowledge graphs like Wikidata already capture several billions of RDF triples, yet they still lack a good coverage for most relations. On the other hand, recent developments in NLP research show that neural language models can easily be queried for relational knowledge without requiring massive amounts of training data. In this work, we leverage this idea by creating a hybrid query answering system on top of knowledge graphs in combination with the masked language model BERT to complete query results. We thus incorporate valuable structural and semantic information from knowledge graphs with textual knowledge from language models to achieve high precision query results. Standard techniques for dealing with incomplete knowledge graphs are either (1) relation extraction which requires massive amounts of training data or (2) knowledge graph embeddings which have problems to succeed beyond simple baseline datasets. Our hybrid system KnowlyBERT requires only small amounts of training data, while outperforming state-of-the-art techniques by boosting their precision by over 30% in our large Wikidata experiment. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-62419-4_17;Kalo J.-C., Fichtel L., Ehler P., Balke W.-T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096523582&doi=10.1007%2f978-3-030-62419-4_17&partnerID=40&md5=298df314572f6ae44a99122047f6bfa2;Germany;"question answering; augmented language models";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;kore 50dywc: an evaluation data set for entity linking based on dbpedia, yago, wikidata, and crunchbase;"Data Sets; Entity Linking; Knowledge Graph; NLP Interchange Format; Text Annotation";A major domain of research in natural language processing is named entity recognition and disambiguation (NERD). One of the main ways of attempting to achieve this goal is through use of Semantic Web technologies and its structured data formats. Due to the nature of structured data, information can be extracted more easily, therewith allowing for the creation of knowledge graphs. In order to properly evaluate a NERD system, gold standard data sets are required. A plethora of different evaluation data sets exists, mostly relying on either Wikipedia or DBpedia. Therefore, we have extended a widely-used gold standard data set, KORE 50, to not only accommodate NERD tasks for DBpedia, but also for YAGO, Wikidata and Crunchbase. As such, our data set, KORE 50DYWC, allows for a broader spectrum of evaluation. Among others, the knowledge graph agnosticity of NERD systems may be evaluated which, to the best of our knowledge, was not possible until now for this number of knowledge graphs. © European Language Resources Association (ELRA), licensed under CC-BY-NC;Scopus;2020;;Noullet K., Mix R., Färber M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096516371&partnerID=40&md5=677a5dad7c59d18227b3ffb1ff95bc2a;Germany;entity linking;validation research;resource;;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;challenges of knowledge graph evolution from an nlp perspective;"Cultural Heritage; Knowledge Graph Evolution; NLP";Knowledge graphs often express static facts, but concepts and entities change over time. In this position paper, we propose challenges that arise from the perspective of combining NLP and KG evolution in the digital humanities domain based on preliminary experiments. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).;Scopus;2020;;Tietz T., Alam M., Sack H., van Erp M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095966893&partnerID=40&md5=c106c73240fa7ea6a88041fe790f1359;Germany, Netherlands;error detection;opinion paper;guidelines;;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;latent relation language models;"Computational linguistics; Knowledge representation; In contexts; Joint distributions; Knowledge graphs; Language model; Posterior probability; Qualitative analysis; Modeling languages";In this paper, we propose Latent Relation Language Models (LRLMs), a class of language models that parameterizes the joint distribution over the words in a document and the entities that occur therein via knowledge graph relations. This model has a number of attractive properties: it not only improves language modeling performance, but is also able to annotate the posterior probability of entity spans for a given text through relations. Experiments demonstrate empirical improvements over both word-based language models and a previous approach that incorporates knowledge graph information. Qualitative analysis further demonstrates the proposed model’s ability to learn to predict appropriate relations in context. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;Scopus;2020;;Hayashi H., Hu Z., Xiong C., Neubig G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095149010&partnerID=40&md5=0136dc85f139a9219c38f6db0fa02f90;United States;"relation extraction; augmented language models";validation research;tool;;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;knowledge graphs effectiveness in neural machine translation improvement;"knowledge graph representation; natural language processing; neural machine translation";"Maintaining semantic relations between words during the translation process yields more accurate target-language output from Neural Machine Translation (NMT). Although difficult to achieve from training data alone, it is possible to leverage Knowledge Graphs (KGs) to retain source-language semantic relations in the corresponding target-language translation. The core idea is to use KG entity relations as embedding constraints to improve the mapping from source to target. This paper describes two embedding constraints, both of which employ Entity Linking (EL)—assigning a unique identity to entities—to associate words in training sentences with those in the KG: (1) a monolingual embedding constraint that supports an enhanced semantic representation of the source words through access to relations between entities in a KG; and (2) a bilingual embedding constraint that forces entity relations in the source-language to be carried over to the corresponding entities in the target-language translation. The method is evaluated for English-Spanish translation exploiting Freebase as a source of knowledge. Our experimental results demonstrate that exploiting KG information not only decreases the number of unknown words in the translation but also improves translation quality. © 2020 Author(s). This is an open access publication, which can be used, distributed and reproduced in any medium according to the Creative Commons CC-BY 4.0 License.";Scopus;2020;10.7494/csci.2020.21.3.3701;Ahmadnia B., Dorr B.J., Kordjamshidi P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094217000&doi=10.7494%2fcsci.2020.21.3.3701&partnerID=40&md5=c263094a1fc34615f56ad875ee9a86fa;United States;machine translation;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;faq-based question answering via knowledge anchors;"Anchors; Knowledge representation; Query processing; Semantics; Effective solution; Frequently asked questions; Interpretability; Knowledge graphs; Matching models; Multi channel; Query documents; Question Answering; Natural language processing systems";Question answering (QA) aims to understand questions and find appropriate answers. In real-world QA systems, Frequently Asked Question (FAQ) based QA is usually a practical and effective solution, especially for some complicated questions (e.g., How and Why). Recent years have witnessed the great successes of knowledge graphs (KGs) in KBQA systems, while there are still few works focusing on making full use of KGs in FAQ-based QA. In this paper, we propose a novel Knowledge Anchor based Question Answering (KAQA) framework for FAQ-based QA to better understand questions and retrieve more appropriate answers. More specifically, KAQA mainly consists of three modules: knowledge graph construction, query anchoring and query-document matching. We consider entities and triples of KGs in texts as knowledge anchors to precisely capture the core semantics, which brings in higher precision and better interpretability. The multi-channel matching strategy also enables most sentence matching models to be flexibly plugged in our KAQA framework to fit different real-world computation limitations. In experiments, we evaluate our models on both offline and online query-document matching tasks on a real-world FAQ-based QA system in WeChat Search, with detailed analysis, ablation tests and case studies. The significant improvements confirm the effectiveness and robustness of the KAQA framework in real-world FAQ-based QA. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-60450-9_1;Xie R., Lu Y., Lin F., Lin L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093109554&doi=10.1007%2f978-3-030-60450-9_1&partnerID=40&md5=a98121a3a05e1cb66b45614ed84e0d4f;China;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an interactive system for knowledge graph search;"Database systems; Human computer interaction; Knowledge representation; Natural language processing systems; Query processing; Graphical interface; Interactive system; Knowledge graphs; Natural language queries; Natural languages; Query processing engine; Rapid growth; Real-world; Search engines";"Recent years, knowledge graphs (KG) have experienced rapid growth since they contain enormous volume of facts about the real world, and become the source of various knowledge. It is hence highly desirable that the query-processing engine of a KG is capable of processing queries presented in natural language directly, though these natural language queries bring various ambiguities. In this paper, we present, an interactive system for searching information from knowledge graphs with natural language. has the following characteristics: it (1) understands queries issued with natural languages; (2) resolve query ambiguity via human-computer interaction; and (3) provides a graphical interface to interact with users. © 2020, Springer Nature Switzerland AG.";Scopus;2020;10.1007/978-3-030-59419-0_52;Baivab S., Wang X., Jiang W., Ma J., Zhan H., Zhong X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092109956&doi=10.1007%2f978-3-030-59419-0_52&partnerID=40&md5=43f5ea05aa3345a51fe8365ef8c8ef7b;China;semantic search;solution proposal;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;representation learning of knowledge graphs with embedding subspaces;"Embeddings; Encoding (symbols); Natural language processing systems; Semantics; Vectors; Feature vectors; Knowledge graphs; Natural language model; Prediction errors; Semantic properties; Supervised methods; Training data; Unstructured texts; Knowledge representation";Most of the existing knowledge graph embedding models are supervised methods and largely relying on the quality and quantity of obtainable labelled training data. The cost of obtaining high quality triples is high and the data sources are facing a serious problem of data sparsity, which may result in insufficient training of long-tail entities. However, unstructured text encoding entities and relational knowledge can be obtained anywhere in large quantities. Word vectors of entity names estimated from the unlabelled raw text using natural language model encode syntax and semantic properties of entities. Yet since these feature vectors are estimated through minimizing prediction error on unsupervised entity names, they may not be the best for knowledge graphs. We propose a two-phase approach to adapt unsupervised entity name embeddings to a knowledge graph subspace and jointly learn the adaptive matrix and knowledge representation. Experiments on Freebase show that our method can rely less on the labelled data and outperforms the baselines when the labelled data is relatively less. Especially, it is applicable to zero-shot scenario. © 2020 Chunhua Li et al.;Scopus;2020;10.1155/2020/4741963;Li C., Xian X., Ai X., Cui Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092061749&doi=10.1155%2f2020%2f4741963&partnerID=40&md5=7a7df2a1da68d4a421df0133445fd790;China;"knowledge graph embedding; entity classification";validation research;technique;;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph construction of personal relationships;"Entity alignment; Entity recognition; Knowledge graph; Personal relationships; Relation extraction";Knowledge graph has attracted much attention in recent years. It is a high-level natural language processing (NLP) problem, which includes many NLP tasks such as named entity recognition, relation extraction, entity alignment, etc. In this paper, we focus on the entity of persons in the large amount of text data, and then construct the graph of personal relationships. Firstly we investigate how to recognize person names from Chinese text. Secondly, we propose a comprehensive approach including Improved BiGated Recurrent Unit and syntactic analysis to extract the relations between different persons. Then, we align the person entities through entity alignment techniques and some manual proofreading work. Finally, we apply this graph construction process in text records for experimentation. This process performs effectively and efficiently to construct the graph of personal relationships from unstructured Chinese text, and this graph can provide significant relationship insights in texts. © 2020, Springer Nature Switzerland AG.;Scopus;2020;10.1007/978-3-030-57884-8_40;Jin Y., Jin Q., Yang X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091296764&doi=10.1007%2f978-3-030-57884-8_40&partnerID=40&md5=e51d60a77294ca26e3ed675dd07b40bb;China;"entity extraction; relation extraction";solution proposal;method;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;skos tool: a tool for creating knowledge graphs to support semantic text classification;"Artificial intelligence; Knowledge graph; Natural language processing; Semantic classifier; SKOS";"Knowledge graphs are being increasingly adopted in industry in order to add meaning to data and improve the intelligence of data analytics methods. Simple Knowledge Management System (SKOS) is a W3C standard for representation of knowledge graphs in a web-native and machine-understandable format. This paper introduces SKOS Tool; a web-based application developed at the Engineering Informatics Lab at Texas State University. It can be used for creating knowledge graphs and concept schemes based on the SKOS standard. The main feature and functions of SKOS Tool are described in this paper. Beyond creating knowledge graphs, SKOS Tool has additional features that can be used to support semantic document classification based on the Bag of Concepts technique. To demonstrate the utilities of SKOS Tool, a use case related to classifications of manufacturing suppliers with Medical Grade Polymer Tubing capabilities is presented. © 2020, IFIP International Federation for Information Processing.";Scopus;2020;10.1007/978-3-030-57997-5_31;Ameri F., Yoder R., Zandbiglari K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090171505&doi=10.1007%2f978-3-030-57997-5_31&partnerID=40&md5=aa9f9b0ad98ed95b771194f7f5f30b35;United States;"text classification; ontology construction";solution proposal;tool;;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;conquest: a framework for building template-based iqa chatbots for enterprise knowledge graphs;"ChatBot; Interactive Question Answering; Knowledge Graph; Linked Data";The popularization of Enterprise Knowledge Graphs (EKGs) brings an opportunity to use Question Answering Systems to consult these sources using natural language. We present CONQUEST, a framework that automates much of the process of building chatbots for the Template-Based Interactive Question Answering task on EKGs. The framework automatically handles the processes of construction of the Natural Language Processing engine, construction of the question classification mechanism, definition of the system interaction flow, construction of the EKG query mechanism, and finally, the construction of the user interaction interface. CONQUEST uses a machine learning-based mechanism to classify input questions to known templates extracted from EKGs, utilizing the clarification dialog to resolve inconclusive classifications and request mandatory missing parameters. CONQUEST also evolves with question clarification: these cases define question patterns used as new examples for training. © Springer Nature Switzerland AG 2020.;Scopus;2020;10.1007/978-3-030-51310-8_6;Avila C.V.S., Franco W., Maia J.G.R., Vidal V.M.P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087530549&doi=10.1007%2f978-3-030-51310-8_6&partnerID=40&md5=90b1cf371558c57ff7751490c108e38c;Brazil;"question answering; conversational interfaces";solution proposal;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;automatic taxonomy induction and expansion;"HTTP; Taxonomies; Distributional semantics; End to end; Hybrid approach; Induction system; Knowledge graphs; Linguistic patterns; Natural language processing systems";The Knowledge Graph Induction Service (KGIS) is an end-to-end knowledge induction system. One of its main capabilities is to automatically induce taxonomies1 from input documents using a hybrid approach that takes advantage of linguistic patterns, semantic web and neural networks. KGIS allows the user to semi-automatically curate and expand the induced taxonomy through a component called smart spreadsheet by exploiting distributional semantics. In this paper, we describe these taxonomy induction and expansion features of KGIS. A screencast video demonstrating the system is available in https://ibm.box.com/v/emnlp-2019-demo . © 2019 Association for Computational Linguistics.;ACL;2020;;Fauceglia N.R., Gliozzo A., Dash S., Chowdhury M.F.M., Mihindukulasooriya N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087435953&partnerID=40&md5=e6a757718ea22a1913f24ed788ad3a26;United States;"entity extraction; relation extraction; ontology construction";solution proposal;tool;;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;semantic similarity estimation using vector symbolic architectures;"Concept representation; semantic similarity; vector symbolic architectures; word embeddings";For many natural language processing applications, estimating similarity and relatedness between words are key tasks that serve as the basis for classification and generalization. Currently, vector semantic models (VSM) have become a fundamental language modeling tool. VSMs represent words as points in a high-dimensional space and follow the distributional hypothesis of meaning, which assumes that semantic similarity is related to the context. In this paper, we propose a model whose representations are based on the semantic features associated with a concept within the ConceptNet knowledge graph. The proposed model is based on a vector symbolic architecture framework, which defines a set of arithmetic operations to encode the semantic features within a single high-dimensional vector. In addition to word distribution, these vector representations consider several types of information. Moreover, owing to the properties of high-dimensional spaces, they have the additional advantage of being interpretable. We analyze the model's performance on the SimLex-999 dataset, a dataset where commonly used distributional models (e.g., word2vec or GloVe) perform poorly. Our results are similar to those of other hybrid models, and they surpass several state-of-the-art distributional and knowledge-based models. © 2013 IEEE.;IEEE;2020;10.1109/access.2020.3001765;Quiroz-Mercado J.I., Barron-Fernandez R., Ramirez-Salinas M.A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087327864&doi=10.1109%2fACCESS.2020.3001765&partnerID=40&md5=8358776fa31a03fcb0c297e47ff127e0;Mexico;"augmented language models; semantic similarity";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;person-relation extraction using bert based knowledge graph;"Knowledge graph; Named entity recognition; Relation extraction";Artificial intelligence technology has been actively researched in the areas of image processing and natural language processing. Recently, with the release of Google’s language model BERT, the importance of artificial intelligence models has attracted attention in the field of natural language processing. In this paper, we propose a knowledge graph to build a model that can extract people in a document using BERT, and to grasp the relationship between people based on the model. In addition, to verify the applicability of person extraction techniques using BERT based knowledge graphs, we conduct a performance comparison experiment with other person extraction models and apply our proposed method to the case study. © 2020, ICIC International.;Scopus;2020;10.24507/icicelb.11.06.539;Yang S.M., Yoo S.Y., Ahn Y.S., Jeong O.R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084368302&doi=10.24507%2ficicelb.11.06.539&partnerID=40&md5=8a7e5c7967001245abbdb062c2ed5ea0;South Korea;"entity extraction; relation extraction";validation research;technique;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;collaborative policy learning for open knowledge graph reasoning;"Knowledge representation; Linguistics; Open Data; Reinforcement learning; Collaborative agents; Collaborative policy; Fact extraction; Knowledge graphs; On the flies; Reasoning methods; Search spaces; Source codes; Natural language processing systems";"In recent years, there has been a surge of interests in interpretable graph reasoning methods. However, these models often suffer from limited performance when working on sparse and incomplete graphs, due to the lack of evidential paths that can reach target entities. Here we study open knowledge graph reasoning-a task that aims to reason for missing facts over a graph augmented by a background text corpus. A key challenge of the task is to filter out “irrelevant” facts extracted from corpus, in order to maintain an effective search space during path inference. We propose a novel reinforcement learning framework to train two collaborative agents jointly, i.e., a multi-hop graph reasoner and a fact extractor. The fact extraction agent generates fact triples from corpora to enrich the graph on the fly; while the reasoning agent provides feedback to the fact extractor and guides it towards promoting facts that are helpful for the interpretable reasoning. Experiments on two public datasets demonstrate the effectiveness of the proposed approach. Source code and datasets used in this paper can be downloaded at https://github.com/shanzhenren/CPL. © 2019 Association for Computational Linguistics";ACL;2020;;Fu C., Chen T., Qu M., Jin W., Ren X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084325498&partnerID=40&md5=e577b4d5a3073ec43306f199953c4c7d;Canada, China, United States;triple classification;validation research;tool;;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;machine reading comprehension using structural knowledge graph-aware network;"Knowledge management; Knowledge representation; Comprehension tasks; Emerging trends; External knowledge; Knowledge graphs; Reading comprehension; State-of-the-art performance; Structural information; Structural knowledge; Natural language processing systems";Leveraging external knowledge is an emerging trend in machine comprehension task. Previous work usually utilizes knowledge graphs such as ConceptNet as external knowledge, and extracts triples from them to enhance the initial representation of the machine comprehension context. However, such method cannot capture the structural information in the knowledge graph. To this end, we propose a Structural Knowledge Graph-aware Network (SKG) model, constructing sub-graphs for entities in the machine comprehension context. Our method dynamically updates the representation of the knowledge according to the structural information of the constructed sub-graph. Experiments show that SKG achieves state-of-the-art performance on the ReCoRD dataset. © 2019 Association for Computational Linguistics;ACL;2020;;Qiu D., Zhang Y., Feng X., Liao X., Jiang W., Lyu Y., Liu K., Zhao J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084322390&partnerID=40&md5=6f8608bee6e91a2c1f68f09829f92b3b;China;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a non-commutative bilinear model for answering path queries in knowledge graphs;"Computational efficiency; Knowledge representation; Block-circulant matrices; Circulant matrix; Diagonal matrices; Fast computation; Knowledge graphs; Matrix products; Non-commutative; Relation matrix; Natural language processing systems";Bilinear diagonal models for knowledge graph embedding (KGE), such as DistMult and ComplEx, balance expressiveness and computational efficiency by representing relations as diagonal matrices. Although they perform well in predicting atomic relations, composite relations (relation paths) cannot be modeled naturally by the product of relation matrices, as the product of diagonal matrices is commutative and hence invariant with the order of relations. In this paper, we propose a new bilinear KGE model, called BlockHolE, based on block circulant matrices. In BlockHolE, relation matrices can be non-commutative, allowing composite relations to be modeled by matrix product. The model is parameterized in a way that covers a spectrum ranging from diagonal to full relation matrices. A fast computation technique is developed on the basis of the duality of the Fourier transform of circulant matrices. © 2019 Association for Computational Linguistics;ACL;2020;;Hayashi K., Shimbo M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084313620&partnerID=40&md5=bb6763f99dc0dcc882f6eb185a9a50fb;Japan;"knowledge graph embedding; question answering";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;tackling long-tailed relations and uncommon entities in knowledge graph completion;"Knowledge representation; Generative model; Knowledge graphs; Learning paradigms; Meta-learning frameworks; Real-world; Recent researches; Textual description; Natural language processing systems";For large-scale knowledge graphs (KGs), recent research has been focusing on the large proportion of infrequent relations which have been ignored by previous studies. For example few-shot learning paradigm for relations has been investigated. In this work, we further advocate that handling uncommon entities is inevitable when dealing with infrequent relations. Therefore, we propose a meta-learning framework that aims at handling infrequent relations with few-shot learning and uncommon entities by using textual descriptions. We design a novel model to better extract key information from textual descriptions. Besides, we also develop a novel generative model in our framework to enhance the performance by generating extra triplets during the training stage. Experiments are conducted on two datasets from real-world KGs, and the results show that our framework 1 outperforms previous methods when dealing with infrequent relations and their accompanying uncommon entities. © 2019 Association for Computational Linguistics;ACL;2020;;Wang Z., Lai K.P., Li P., Bing L., Lam W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084307036&partnerID=40&md5=15932c5f9d05c9e5672a64d002a86c98;China, Hong Kong, Singapore;"entity extraction; relation extraction; attribute extraction";validation research;tool;;1;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge aware conversation generation with explainable reasoning over augmented graphs;"Flow graphs; Graph algorithms; Knowledge representation; Augmented graph; Knowledge graphs; Reading comprehension; Reasoning algorithms; Response generation; Selection decisions; State of the art; Text information; Natural language processing systems";Two types of knowledge, triples from knowledge graphs and texts from documents, have been studied for knowledge aware open-domain conversation generation, in which graph paths can narrow down vertex candidates for knowledge selection decision, and texts can provide rich information for response generation. Fusion of a knowledge graph and texts might yield mutually reinforcing advantages, but there is less study on that. To address this challenge, we propose a knowledge aware chatting machine with three components, an augmented knowledge graph with both triples and texts, knowledge selector, and knowledge aware response generator. For knowledge selection on the graph, we formulate it as a problem of multi-hop graph reasoning to effectively capture conversation flow, which is more explainable and flexible in comparison with previous work. To fully leverage long text information that differentiates our graph from others, we improve a state of the art reasoning algorithm with machine reading comprehension technology. We demonstrate the effectiveness of our system on two datasets in comparison with state-of-the-art models1. © 2019 Association for Computational Linguistics;ACL;2020;;Liu Z., Niu Z.-Y., Wu H., Wang H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084297175&partnerID=40&md5=7642d4a3a608d25d0744108da05492a3;China;"conversational interfaces; question answering";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;duality of link prediction and entailment graph induction;"Computational linguistics; Knowledge graphs; Link prediction; State of the art; Forecasting";Link prediction and entailment graph induction are often treated as different problems. In this paper, we show that these two problems are actually complementary. We train a link prediction model on a knowledge graph of assertions extracted from raw text. We propose an entailment score that exploits the new facts discovered by the link prediction model, and then form entailment graphs between relations. We further use the learned entailments to predict improved link prediction scores. Our results show that the two tasks can benefit from each other. The new entailment score outperforms prior state-of-the-art results on a standard entialment dataset and the new link prediction scores show improvements over the raw link prediction scores. © 2019 Association for Computational Linguistics;ACL;2020;;Hosseini M.J., Cohen S.B., Johnson M., Steedman M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084090774&partnerID=40&md5=e55d3b1d597f291c3b3278c8d2e0014c;Australia, United Kingdom;link prediction;validation research;tool;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;proactive human-machine conversation with explicit conversation goals;"Speech processing; Baseline results; Baseline systems; Conversation systems; Conversational agents; Dialogue models; Dialogue systems; Knowledge graphs; State of the art; Computational linguistics";Though great progress has been made for human-machine conversation, current dialogue system is still in its infancy: it usually converses passively and utters words more as a matter of response, rather than on its own initiatives. In this paper, we take a radical step towards building a human-like conversational agent: endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic). To facilitate the development of such conversation systems, we create a new dataset named DuConv where one acts as a conversation leader and the other acts as the follower. The leader is provided with a knowledge graph and asked to sequentially change the discussion topics, following the given conversation goal, and meanwhile keep the dialogue as natural and engaging as possible. DuConv enables a very challenging task as the model needs to both understand dialogue and plan over the given knowledge graph. We establish baseline results on this dataset (about 270K utterances and 30k dialogues) using several state-of-the-art models. Experimental results show that dialogue models that plan over the knowledge graph can make full use of related knowledge to generate more diverse multi-turn conversations. The baseline systems along with the dataset are publicly available. © 2019 Association for Computational Linguistics;ACL;2020;;Wu W., Guo Z., Zhou X., Wu H., Zhang X., Lian R., Wang H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084072500&partnerID=40&md5=c8c271ac709cf166e1a5f7a3c2be9908;China;conversational interfaces;validation research;resource;;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a spreading activation framework for tracking conceptual complexity of texts;"Computational linguistics; Semantics; Dbpedia; Knowledge graphs; Long term memory; Reading comprehension; Semantic primings; Spreading activations; State of the art; Unsupervised approaches; Chemical activation";We propose an unsupervised approach for assessing conceptual complexity of texts, based on spreading activation. Using DBpedia knowledge graph as a proxy to long-term memory, mentioned concepts become activated and trigger further activation as the text is sequentially traversed. Drawing inspiration from psycholinguistic theories of reading comprehension, we model memory processes such as semantic priming, sentence wrap-up, and forgetting. We show that our models capture various aspects of conceptual text complexity and significantly outperform current state of the art. © 2019 Association for Computational Linguistics;ACL;2020;;Hulpus I., Štajner S., Stuckenschmidt H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084068774&partnerID=40&md5=f03a787428be66767cfcf9de97df3a56;Germany;text classification;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;embedding imputation with grounded language information;"Computational linguistics; Graph algorithms; Graph structures; Vector spaces; Correlation coefficient; Critical problems; Graphical structures; Knowledge graphs; Language informations; Language processing; Natural languages; State of the art; Embeddings";Due to the ubiquitous use of embeddings as input representations for a wide range of natural language tasks, imputation of embeddings for rare and unseen words is a critical problem in language processing. Embedding imputation involves learning representations for rare or unseen words during the training of an embedding model, often in a post-hoc manner. In this paper, we propose an approach for embedding imputation which uses grounded information in the form of a knowledge graph. This is in contrast to existing approaches which typically make use of vector space properties or subword information. We propose an online method to construct a graph from grounded information and design an algorithm to map from the resulting graphical structure to the space of the pre-trained embeddings. Finally, we evaluate our approach on a range of rare and unseen word tasks across various domains and show that our model can learn better representations. For example, on the Card-660 task our method improves Pearson's and Spearman's correlation coefficients upon the state-of-the-art by 11% and 17.8% respectively using GloVe embeddings. © 2019 Association for Computational Linguistics;ACL;2020;;Yang Z., Zhu C., Sachidananda V., Darve E.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084066541&partnerID=40&md5=f3073d456559e02b92b4e75f708ba968;United States;augmented language models;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;comet: commonsense transformers for automatic knowledge graph construction;"Computational linguistics; Knowledge based systems; Commonsense knowledge; Explicit knowledge; Generative model; Human performance; Implicit knowledge; Knowledge graphs; Knowledge-base construction; Natural languages; Modeling languages";We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods. © 2019 Association for Computational Linguistics;ACL;2020;;Bosselut A., Rashkin H., Sap M., Malaviya C., Celikyilmaz A., Choi Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084040907&partnerID=40&md5=f7e9dc21d41a91b6d7646b53e4952c17;United States;"entity classification; link prediction; augmented language models";validation research;tool;;0;0;0;0;0;0;0;1;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;barack's wife hillary: using knowledge graphs for fact-aware language modeling;"Computational linguistics; Factual knowledge; Human language; Knowledge graphs; Language model; Training time; Modeling languages";Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset,1 a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark (Merity et al., 2017). In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language models' ability to complete sentences requiring factual knowledge, and show that the KGLM outperforms even very large language models in generating facts. © 2019 Association for Computational Linguistics;ACL;2020;;Logan R.L., IV, Liu N.F., Peters M.E., Gardner M., Singh S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084035303&partnerID=40&md5=bae32a9cf40bc8c2a3755d5922ecfdb9;United States;augmented language models;validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;using local knowledge graph construction to scale seq2seq models to multi-document inputs;"Graph structures; Knowledge based systems; Knowledge representation; Query processing; Graph representation; Information synthesis; Local knowledge; Multi-document; Multi-document summarization; Question Answering; Sequence models; Structured knowledge; Natural language processing systems";Query-based open-domain NLP tasks require information synthesis from long and diverse web results. Current approaches extractively select portions of web text as input to Sequence-to-Sequence models using methods such as TF-IDF ranking. We propose constructing a local graph structured knowledge base for each query, which compresses the web search information and reduces redundancy. We show that by linearizing the graph into a structured input sequence, models can encode the graph representations within a standard Sequence-to-Sequence setting. For two generative tasks with very long text input, long-form question answering and multi-document summarization, feeding graph representations as input can achieve better performance than using retrieved text portions. © 2019 Association for Computational Linguistics;ACL;2020;;Fan A., Gardent C., Braud C., Bordes A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082548175&partnerID=40&md5=b73972fec8bc7474af4e72b788c4d693;France;"text summarization; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;opendialkg: explainable conversational reasoning with attention-based walks over knowledge graphs;"Fact knowledge; Human evaluation; Knowledge graphs; Parallel corpora; Reasoning models; Rule-based models; State of the art; Walker models; Computational linguistics";We study a conversational reasoning model that strategically traverses through a large-scale common fact knowledge graph (KG) to introduce engaging and contextually diverse entities and attributes. For this study, we collect a new Open-ended Dialog ? KG parallel corpus called OpenDialKG, where each utterance from 15K human-to-human role-playing dialogs is manually annotated with ground-truth reference to corresponding entities and paths from a large-scale KG with 1M+ facts. We then propose the DialKG Walker model that learns the symbolic transitions of dialog contexts as structured traversals over KG, and predicts natural entities to introduce given previous dialog contexts via a novel domain-agnostic, attention-based graph path decoder. Automatic and human evaluations show that our model can retrieve more natural and human-like responses than the state-of-the-art baselines or rule-based models, in both in-domain and cross-domain tasks. The proposed model also generates a KG walk path for each entity retrieved, providing a natural way to explain conversational reasoning. © 2019 Association for Computational Linguistics;ACL;2020;;Moon S., Shah P., Kumar A., Subba R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082383935&partnerID=40&md5=6d03b54489b80a0eca5f0a51d5300161;;conversational interfaces;validation research;"resource; technique";;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;multi-task identification of entities, relations, and coreference for scientific knowledge graph construction;"Information use; Coreference; Domain specific; Multi-task model; Scientific articles; Scientific information; Scientific knowledge; Scientific literature; Unified framework; Natural language processing systems";We introduce a multi-task setup of identifying and classifying entities, relations, and coreference clusters in scientific articles. We create SCIERC, a dataset that includes annotations for all three tasks and develop a unified framework called Scientific Information Extractor (SCIIE) for with shared span representations. The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature.1 © 2018 Association for Computational Linguistics;ACL;2020;;Luan Y., He L., Ostendorf M., Hajishirzi H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081754181&partnerID=40&md5=709a9ea70a6f4e7a6d4b10acc623c89a;United States;"entity extraction; relation extraction; text analysis";validation research;"tool; resource";;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;neural compositional denotational semantics for question answering;"Gradient methods; Semantics; Syntactics; Trees (mathematics); Composition functions; Composition operators; Denotational semantics; Gradient descent; Knowledge graphs; Question Answering; Semantic operators; Syntactic structure; Natural language processing systems";Answering compositional questions requiring multi-step reasoning is challenging. We introduce an end-to-end differentiable model for interpreting questions about a knowledge graph (KG), which is inspired by formal approaches to semantics. Each span of text is represented by a denotation in a KG and a vector that captures ungrounded aspects of meaning. Learned composition modules recursively combine constituent spans, culminating in a grounding for the complete sentence which answers the question. For example, to interpret “not green”, the model represents “green” as a set of KG entities and “not” as a trainable ungrounded vector-and then uses this vector to parameterize a composition function that performs a complement operation. For each sentence, we build a parse chart subsuming all possible parses, allowing the model to jointly learn both the composition operators and output structure by gradient descent from end-task supervision. The model learns a variety of challenging semantic operators, such as quantifiers, disjunctions and composed relations, and infers latent syntactic structure. It also generalizes well to longer questions than seen in its training data, in contrast to RNN, its tree-based variants, and semantic parsing baselines. © 2018 Association for Computational Linguistics;ACL;2020;;Gupta N., Lewis M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081749991&partnerID=40&md5=6e1825813feae6e068d1eeff5f3b7153;United States;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;label-free distant supervision for relation extraction via knowledge graph embedding;"Embeddings; Extraction; Labeled data; Natural language processing systems; Knowledge graphs; Label free; Prior knowledge; Relation extraction; Type information; Data mining";Distant supervision is an effective method to generate large scale labeled data for relation extraction, which assumes that if a pair of entities appears in some relation of a Knowledge Graph (KG), all sentences containing those entities in a large unlabeled corpus are then labeled with that relation to train a relation classifier. However, when the pair of entities has multiple relationships in the KG, this assumption may produce noisy relation labels. This paper proposes a label-free distant supervision method, which makes no use of the relation labels under this inadequate assumption, but only uses the prior knowledge derived from the KG to supervise the learning of the classifier directly and softly. Specifically, we make use of the type information and the translation law derived from typical KG embedding model to learn embeddings for certain sentence patterns. As the supervision signal is only determined by the two aligned entities, neither hard relation labels nor extra noise-reduction model for the bag of sentences is needed in this way. The experiments show that the approach performs well in current distant supervision dataset. © 2018 Association for Computational Linguistics;ACL;2020;;Wang G., Zhang W., Wang R., Zhou Y., Chen X., Zhang W., Zhu H., Chen H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081738408&partnerID=40&md5=a42733c5b20e34263c5f089f881fbb43;China;"relation extraction; knowledge graph embedding";validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;mapping text to knowledge graph entities using multi-sense lstms;"Knowledge based systems; Long short-term memory; Mapping; Semantics; Text processing; Classification tasks; Compositional modeling; Knowledge graphs; Mapping process; Multi-dimensional entities; Natural language text; State of the art; Textual features; Natural language processing systems";This paper addresses the problem of mapping natural language text to knowledge base entities. The mapping process is approached as a composition of a phrase or a sentence into a point in a multi-dimensional entity space obtained from a knowledge graph. The compositional model is an LSTM equipped with a dynamic disambiguation mechanism on the input word embeddings (a Multi-Sense LSTM), addressing polysemy issues. Further, the knowledge base space is prepared by collecting random walks from a graph enhanced with textual features, which act as a set of semantic bridges between text and knowledge base entities. The ideas of this work are demonstrated on large-scale text-to-entity mapping and entity classification tasks, with state of the art results. © 2018 Association for Computational Linguistics;ACL;2020;;Kartsaklis D., Pilehvar M.T., Collier N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081720002&partnerID=40&md5=76e164a9517a73ff7c470458a711c14c;United Kingdom;"entity linking; text classification; entity classification";validation research;technique;;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;multi-hop knowledge graph reasoning with reward shaping;"Embeddings; Reinforcement learning; Action sequences; Benchmark datasets; Effective approaches; False negatives; Incomplete knowledge; Knowledge graphs; Low qualities; Query answering; Natural language processing systems";"Multi-hop reasoning is an effective approach for query answering (QA) over incomplete knowledge graphs (KGs). The problem can be formulated in a reinforcement learning (RL) setup, where a policy-based agent sequentially extends its inference path until it reaches a target. However, in an incomplete KG environment, the agent receives low-quality rewards corrupted by false negatives in the training data, which harms generalization at test time. Furthermore, since no golden action sequence is used for training, the agent can be misled by spurious search trajectories that incidentally lead to the correct answer. We propose two modeling advances to address both issues: (1) we reduce the impact of false negative supervision by adopting a pretrained one-hop embedding model to estimate the reward of unobserved facts; (2) we counter the sensitivity to spurious paths of on-policy RL by forcing the agent to explore a diverse set of paths using randomly generated edge masks. Our approach significantly improves over existing path-based KGQA models on several benchmark datasets and is comparable or better than embedding-based models. © 2018 Association for Computational Linguistics";ACL;2020;;Lin X.V., Socher R., Xiong C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081715825&partnerID=40&md5=e1a964431bd28a2432bd7b51c780140a;;"question answering; knowledge graph embedding";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;semi-automatic corpus expansion and extraction of uyghur-named entities and relations based on a hybrid method;"Conditional randomfield; Hybrid neural network; Named entity; Relation extraction; Uyghur";Relation extraction is an important task with many applications in natural language processing, such as structured knowledge extraction, knowledge graph construction, and automatic question answering system construction. However, relatively little past work has focused on the construction of the corpus and extraction of Uyghur-named entity relations, resulting in a very limited availability of relation extraction research and a deficiency of annotated relation data. This issue is addressed in the present article by proposing a hybrid Uyghur-named entity relation extraction method that combines a conditional random field model for making suggestions regarding annotation based on extracted relations with a set of rules applied by human annotators to rapidly increase the size of the Uyghur corpus. We integrate our relation extraction method into an existing annotation tool, and, with the help of human correction, we implement Uyghur relation extraction and expand the existing corpus. The effectiveness of our proposed approach is demonstrated based on experimental results by using an existing Uyghur corpus, and our method achieves a maximum weighted average between precision and recall of 61.34%. The method we proposed achieves state-of-the-art results on entity and relation extraction tasks in Uyghur. © 2020 by the authors.;Scopus;2020;10.3390/info11010031;Halike A., Abiderexiti K., Yibulayin T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079035010&doi=10.3390%2finfo11010031&partnerID=40&md5=da2537c978af69c328a8600a11cff1c2;China;"entity extraction; relation extraction";validation research;technique;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;adapting meta knowledge graph information for multi-hop reasoning over few-shot relations;"Knowledge representation; High frequency HF; Knowledge graphs; Meta-knowledge; Meta-parameters; Query answering; Reasoning methods; Reasoning models; State-of-the-art methods; Natural language processing systems";Multi-hop knowledge graph (KG) reasoning is an effective and explainable method for predicting the target entity via reasoning paths in query answering (QA) task. Most previous methods assume that every relation in KGs has enough training triples, regardless of those few-shot relations which cannot provide sufficient triples for training robust reasoning models. In fact, the performance of existing multi-hop reasoning methods drops significantly on few-shot relations. In this paper, we propose a meta-based multi-hop reasoning method (Meta-KGR), which adopts meta-learning to learn effective meta parameters from high-frequency relations that could quickly adapt to few-shot relations. We evaluate Meta-KGR on two public datasets sampled from Freebase and NELL, and the experimental results show that Meta-KGR outperforms the current state-of-the-art methods in few-shot scenarios. Our code and datasets can be obtained from https://github.com/THU-KEG/MetaKGR. © 2019 Association for Computational Linguistics;ACL;2020;;Lv X., Gu Y., Han X., Hou L., Li J., Liu Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078244531&partnerID=40&md5=218cfe38a23eee703309d3a67597207f;China;link prediction;validation research;tool;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;zero-shot word sense disambiguation using sense definition embeddings;"Computational linguistics; Embeddings; Signal encoding; Knowledge graphs; Label space; Large corpora; NAtural language processing; Poor performance; State of the art; Word-sense disambiguation; Wordnet; Natural language processing systems";Word Sense Disambiguation (WSD) is a longstanding but open problem in Natural Language Processing (NLP). WSD corpora are typically small in size, owing to an expensive annotation process. Current supervised WSD methods treat senses as discrete labels and also resort to predicting the Most-Frequent-Sense (MFS) for words unseen during training. This leads to poor performance on rare and unseen senses. To overcome this challenge, we propose Extended WSD Incorporating Sense Embeddings (EWISE), a supervised model to perform WSD by predicting over a continuous sense embedding space as opposed to a discrete label space. This allows EWISE to generalize over both seen and unseen senses, thus achieving generalized zero-shot learning. To obtain target sense embeddings, EWISE utilizes sense definitions. EWISE learns a novel sentence encoder for sense definitions by using WordNet relations and also ConvE, a recently proposed knowledge graph embedding method. We also compare EWISE against other sentence encoders pretrained on large corpora to generate definition embeddings. EWISE achieves new state-of-the-art WSD performance. © 2019 Association for Computational Linguistics;ACL;2020;;Kumar S., Jat S., Saxena K., Talukdar P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075859601&partnerID=40&md5=df7fa442077c5b74e0de03860cb4219b;India, United States;"text analysis; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a state-transition framework to answer complex questions over knowledge base;"Knowledge based systems; Semantics; Complex questions; Knowledge basis; Knowledge graphs; Natural language questions; Primitive operations; Semantic query; State of the art; State transitions; Natural language processing systems";Although natural language question answering over knowledge graphs have been studied in the literature, existing methods have some limitations in answering complex questions. To address that, in this paper, we propose a State Transition-based approach to translate a complex natural language question N to a semantic query graph (SQG) QS, which is used to match the underlying knowledge graph to find the answers to question N. In order to generate QS, we propose four primitive operations (expand, fold, connect and merge) and a learning-based state transition approach. Extensive experiments on several benchmarks (such as QALD, WebQuestions and ComplexQuestions) with two knowledge bases (DBpedia and Freebase) confirm the superiority of our approach compared with state-of-the-arts. © 2018 Association for Computational Linguistics;ACL;2020;;Hu S., Zou L., Zhang X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066476875&partnerID=40&md5=91bc65a67dcc9579224479b7cba5f2cb;China;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;beyond word embeddings: learning entity and concept representations from large scale knowledge bases;"Concept categorization; Entity and concept embeddings; Entity identification; Knowledge graph representations; Probase; Skip-gram";Text representations using neural word embeddings have proven effective in many NLP applications. Recent researches adapt the traditional word embedding models to learn vectors of multiword expressions (concepts/entities). However, these methods are limited to textual knowledge bases (e.g., Wikipedia). In this paper, we propose a novel and simple technique for integrating the knowledge about concepts from two large scale knowledge bases of different structure (Wikipedia and Probase) in order to learn concept representations. We adapt the efficient skip-gram model to seamlessly learn from the knowledge in Wikipedia text and Probase concept graph. We evaluate our concept embedding models on two tasks: (1) analogical reasoning, where we achieve a state-of-the-art performance of 91% on semantic analogies, (2) concept categorization, where we achieve a state-of-the-art performance on two benchmark datasets achieving categorization accuracy of 100% on one and 98% on the other. Additionally, we present a case study to evaluate our model on unsupervised argument type identification for neural semantic parsing. We demonstrate the competitive accuracy of our unsupervised method and its ability to better generalize to out of vocabulary entity mentions compared to the tedious and error prone methods which depend on gazetteers and regular expressions. © 2018, Springer Nature B.V.;Scopus;2019;10.1007/s10791-018-9340-3;Shalaby W., Zadrozny W., Jin H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052060481&doi=10.1007%2fs10791-018-9340-3&partnerID=40&md5=e1915bd676ccbb126a6dd18dd829ad61;United States;"augmented language models; knowledge graph embedding";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;look before you hop: conversational question answering over knowledge graphs using judicious context expansion;"Natural language processing systems; Different domains; Graph exploration; Interrogative sentences; Knowledge graphs; Question Answering; Question answering systems; State of the art; Unsupervised method; Knowledge management";"Fact-centric information needs are rarely one-shot; users typically ask follow-up questions to explore a topic. In such a conversational setting, the user's inputs are often incomplete, with entities or predicates left out, and ungrammatical phrases. This poses a huge challenge to question answering (QA) systems that typically rely on cues in full-fledged interrogative sentences. As a solution, we develop Convex: an unsupervised method that can answer incomplete questions over a knowledge graph (KG) by maintaining conversation context using entities and predicates seen so far and automatically inferring missing or ambiguous pieces for follow-up questions. The core of our method is a graph exploration algorithm that judiciously expands a frontier to find candidate answers for the current question. To evaluate Convex, we release ConvQuestions, a crowdsourced benchmark with 11, 200 distinct conversations from five different domains. We show that Convex: (i) adds conversational support to any stand-alone QA system, and (ii) outperforms state-of-the-art baselines and question completion strategies. © 2019 Association for Computing Machinery.";ACM;2019;10.1145/3357384.3358016;Christmann P., Roy R.S., Abujabal A., Singh J., Weikum G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075482520&doi=10.1145%2f3357384.3358016&partnerID=40&md5=5d66b42af52e47f26f93e8a4450a6180;Germany;"conversational interfaces; question answering";validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;knowledge-aware textual entailment with graph attention network;"Graph attention network; Knowledge base; Textual entailment";Textual entailment is a central problem of language variability, which has been attracting a lot of interest and it poses significant issues in front of systems aimed at natural language understanding. Recently, various frameworks have been proposed for textual entailment recognition, ranging from traditional computational linguistics techniques to deep learning model based methods. However, recent deep neural networks that achieve the state of the art on textual entailment task only consider the context information of the given sentences rather than the real-world background information and knowledge beyond the context. In the paper, we propose a Knowledge-Context Interactive Textual Entailment Network (KCI-TEN) that learns graph level sentence representations by harnessing external knowledge graph with graph attention network. We further propose a text-graph interaction mechanism for neural based entailment matching learning, which endows the redundancy and noise with less importance and put emphasis on the informative representations. Experiments on the SciTail dataset demonstrate that KCI-TEN outperforms the state-of-the-art methods. © 2019 Association for Computing Machinery.;ACM;2019;10.1145/3357384.3358071;Chen D., Li Y., Yang M., Zheng H.-T., Shen Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075468679&doi=10.1145%2f3357384.3358071&partnerID=40&md5=122e9e69faf8c86a7cfce803b0cf3b2e;China, United States;natural language inference;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;embedding learning with triple trustiness on noisy knowledge graph;"Cross entropy; Embedding learning; Knowledge graph; Noise detection; Triple trustiness";Embedding learning on knowledge graphs (KGs) aims to encode all entities and relationships into a continuous vector space, which provides an effective and flexible method to implement downstream knowledge-driven artificial intelligence (AI) and natural language processing (NLP) tasks. Since KG construction usually involves automatic mechanisms with less human supervision, it inevitably brings in plenty of noises to KGs. However, most conventional KG embedding approaches inappropriately assume that all facts in existing KGs are completely correct and ignore noise issues, which brings about potentially serious errors. To address this issue, in this paper we propose a novel approach to learn embeddings with triple trustiness on KGs, which takes possible noises into consideration. Specifically, we calculate the trustiness value of triples according to the rich and relatively reliable information from large amounts of entity type instances and entity descriptions in KGs. In addition, we present a cross-entropy based loss function for model optimization. In experiments, we evaluate our models on KG noise detection, KG completion and classification. Through extensive experiments on three datasets, we demonstrate that our proposed model can learn better embeddings than all baselines on noisy KGs. © 2019 by the authors.;Scopus;2019;10.3390/e21111083;Zhao Y., Feng H., Gallinari P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075465861&doi=10.3390%2fe21111083&partnerID=40&md5=b36481ea4e03b9b6fc51e0dacbd942a5;China, France;knowledge graph embedding;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;edgegat: an approach to add external knowledge for semantic matching;"Knowledge graphs; Natural language inference; Natural language processing";Natural Language Inference (NLI) is one of NLP tasks to deduce, given a premise, whether a relevant hypothesis should be declared true or false. In view of the performance of previous models, the improvement provided by external knowledge is substantial. Inspired by it, we propose a new mechanism for introducing external knowledge, i.e., adding the graph convolutional network (EDGEGAT) we designed to the NLI model. Unlike previous external knowledge methods, EDGEGAT can easily be combined with NLI models and automatically learn to filter and utilize the knowledge graph during training. Using this mechanism we show significant improvement in performance for previous NLI models with Stanford Natural Language Inference (SNLI) dataset. Moreover, we demonstrate that EDGEGAT is effective and more suitable for knowledge graphs than the previous graph convolution network. © 2019 IEEE.;IEEE;2019;10.1109/iccsnt47585.2019.8962429;Song M., Zhao W., Haihong E.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079101339&doi=10.1109%2fICCSNT47585.2019.8962429&partnerID=40&md5=89ce3503ad982dde7ef35b8ada21e20c;China;natural language inference;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a comprehensive framework for ontology based classifier using unstructured data;"Feature Hashing; Knowledge Graphs; Multiclass classification; Ontology; Text categorization; Topic Modeling";The knowledge contained within the natural language data can be used to build expert systems. Classifying unstructured data using ontology and text classification algorithms to extract information is one way of approaching the problem of building intelligent systems. One major problem with text processing is most data generated is unstructured and ambiguous, as, data with a structure helps to identify meaningful patterns and eventually exhibit the latent knowledge. Ambiguity in natural language affects accuracy of categorization. Also, Natural Language Processing techniques when combined with semantic data modeling through ontological knowledge will also solve the problem of domain knowledge representation thereby enabling improved data classification facilities, particularly in large datasets where number of features scale to unmanageable proportions. In this paper, the domain knowledge is presented as a knowledge graph, derived from the semantic data modeling. Further, to achieve better Multi Class classification, Multinomial Naive Bayes algorithm is applied to categorize items in their respective classes. For the experiments, Data about various news groups were used for testing the accuracy of the model. Experimental results have proved that the proposed classifier performs better compared to existing systems. © BEIESP.;Scopus;2019;10.35940/ijeat.a2042.109119;Thangaraj M., Sivakami M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075291008&doi=10.35940%2fijeat.A2042.109119&partnerID=40&md5=063a175982918a56be7bfdfb2793dc1d;India;text classification;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;assessing the lexico-semantic relational knowledge captured by word and concept embeddings;"Embedding evaluation; Knowledge graphs; Lexico-semantic relations";Deep learning currently dominates the benchmarks for various NLP tasks and, at the basis of such systems, words are frequently represented as embeddings - vectors in a low dimensional space - learned from large text corpora and various algorithms have been proposed to learn both word and concept embeddings. One of the claimed benefits of such embeddings is that they capture knowledge about semantic relations. Such embeddings are most often evaluated through tasks such as predicting human-rated similarity and analogy which only test a few, often ill-defined, relations. In this paper, we propose a method for (i) reliably generating word and concept pair datasets for a wide number of relations by using a knowledge graph and (ii) evaluating to what extent pre-trained embeddings capture those relations. We evaluate the approach against a proprietary and a public knowledge graph and analyze the results, showing which lexico-semantic relational knowledge is captured by current embedding learning approaches. © 2019 ACM.;ACM;2019;10.1145/3360901.3364445;Denaux R., Gomez-Perez J.M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077265357&doi=10.1145%2f3360901.3364445&partnerID=40&md5=15a0f51088a9f2a6f9e2afd6ae018b56;Spain;"relation classification; knowledge graph embedding";validation research;method;;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;a survey of knowledge reasoning based on kg;"Inference engines; Learning algorithms; Manufacture; Natural language processing systems; Future improvements; Inference models; Knowledge graphs; Knowledge reasoning; Look-forward; NAtural language processing; Question Answering; Machine learning";Knowledge Reasoning(KR) has become the core issue in the field of Artificial Intelligence(AI) and even Natural Language Processing(NLP). KR based on Knowledge Graph(KG) is based on existing KG's facts. It uses some inference models and algorithms to infer new unknown knowledge and targets at improving the completeness and accuracy of KG. This article presents a brief overview of KR based on KG, expounds the connotation and research scope of it, judges the two main research directions(Knowledge Graph Completion(KGC) and Question Answering over Knowledge Graph (QA-KG)) of current KR and summarizes the four main technical methods. A series of latest results of current research on KR are also listed in this paper. Finally, we look forward to the future improvement of KR. © Published under licence by IOP Publishing Ltd.;Scopus;2019;10.1088/1757-899x/569/5/052058;Lu R., Cai Z., Zhao S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071851447&doi=10.1088%2f1757-899X%2f569%2f5%2f052058&partnerID=40&md5=f5eeb1c6dc1492b77694a31f594e4fa4;China;"entity classification; link prediction; question answering";secondary research;guidelines;;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;difficulties and improvements to graph-based lexical sentiment analysis using lisa;Sentiment Analysis, Affect Analysis, Knowledge Base, Graph Navigation, Sentiment Lexicon, ANEW;Lexical sentiment analysis (LSA) underlines a family of methods combining natural language processing, machine learning, or graph navigation techniques to identify the underlying sentiments or emotions carried in textual data. In this paper, we introduce LISA, an unsupervised word-level knowledge graph-based LexIcal Sentiment Analysis framework. It uses different variants of shortest path graph navigation techniques to compute and propagate affective scores in a lexical-Affective graph (LAG), created by connecting a typical lexical knowledgebase (KB) like WordNet, with a reliable affect KB like WordNet-Affect Hierarchy. LISA was designed in two consecutive iterations, producing two main modules: i) LISA 1.0 for affect navigation, and ii) LISA 2.0 for affect propagation and lookup. LISA 1.0 suffered from the semantic connectivity problem shared by some existing lexicon-based methods, and required polynomial execution time. This led to the development of LISA 2.0, which i) processes affective relationships separately from lexical/semantic connections (solving the semantic connectivity problem of LISA 1.0), and ii) produces a sentiment lexicon which can be searched in logarithmic time (handling LISA 1.0's efficiency problem). Experimental results on the ANEW dataset show that LISA 2.0, while completely unsupervised, is on a par with existing supervised solutions, highlighting its quality and potential. © 2019 IEEE.;IEEE;2019;10.1109/iccc.2019.00008;Fares M., Moufarrej A., Jreij E., Tekli J., Grosky W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072793727&doi=10.1109%2fICCC.2019.00008&partnerID=40&md5=7be1b4aa6806df28bfcdeb1c5073483b;Lebanon, United States;text analysis;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge-enhanced ensemble learning for word embeddings;"Ensemble model; Knowledge graph; Word embedding";Representing words as embeddings in a continuous vector space has been proven to be successful in improving the performance in many natural language processing (NLP) tasks. Beyond the traditional methods that learn the embeddings from large text corpora, ensemble methods have been proposed to leverage the merits from pre-trained word embeddings as well as external semantic sources. In this paper, we propose a knowledge-enhanced ensemble method to combine both knowledge graphs and pre-trained word embedding models. Specifically, we interpret relations in knowledge graphs as linear translation from one word to another. We also propose a novel weighting scheme to further distinguish edges in the knowledge graph with same type of relation. Extensive experiments demonstrate that our proposed method is up to 20% times better than state-of-the-art in word analogy task and up to 16% times better than state-of-the-art in word similarity task. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.;ACM;2019;10.1145/3308558.3313425;Fang L., Luo Y., Feng K., Zhao K., Hu A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066898567&doi=10.1145%2f3308558.3313425&partnerID=40&md5=6c9f65c8d066edfe67223970d2835676;China, Singapore;augmented language models;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0
Conference Paper;scalable knowledge graph construction over text using deep learning based predicate mapping;"Deep Learning; Knowledge Graph; Predicate Mapping; Scalability; Sentence Simplification";Automatic extraction of information from text and its transformation into a structured format is an important goal in both Semantic Web Research and computational linguistics. Knowledge Graphs (KG) serve as an intuitive way to provide structure to unstructured text. A fact in a KG is expressed in the form of a triple which captures entities and their interrelationships (predicates). Multiple triples extracted from text can be semantically identical but they may have a vocabulary gap which could lead to an explosion in the number of redundant triples. Hence, to get rid of this vocabulary gap, there is a need to map triples to a homogeneous namespace. In this work, we present an end-to-end KG construction system, which identifies and extracts entities and relationships from text and maps them to the homogenous DBpedia namespace. For Predicate Mapping, we propose a Deep Learning architecture to model semantic similarity. This mapping step is computation heavy, owing to the large number of triples in DBpedia. We identify and prune unnecessary comparisons to make this step scalable. Our experiments show that the proposed approach is able to construct a richer KG at a significantly lower computation cost with respect to previous work. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.;Scopus;2019;10.1145/3308560.3317708;Mehta A., Singhal A., Karlapalem K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066883504&doi=10.1145%2f3308560.3317708&partnerID=40&md5=a9f7161e47f9f88cb0bf4f6c7fbbf75e;India;"entity extraction; relation extraction; entity linking; relation linking";validation research;method;;1;1;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;interactive natural language question answering over knowledge graphs;"Interactive query; Knowledge graph; Natural language question and answering; Question understanding";As many real-world data are constructed into knowledge graphs, providing effective and convenient query techniques for end users is an urgent and important task. Although structured query languages, such as SPARQL, offer a powerful expression ability to query RDF datasets, they are difficult to use. Keywords are simple but have a very limited expression ability. Natural language question (NLQ) is promising for querying knowledge graphs. A huge challenge is how to understand the question clearly so as to translate the unstructured question into a structured query. In this paper, we present a data + oracle approach to answer NLQs over knowledge graphs. We let users verify the ambiguities during the query understanding. To reduce the interaction cost, we formalize an interaction problem and design an efficient strategy to solve the problem. We also propose a query prefetching technique by exploiting the latency in the interactions with users. Moreover, we devise a hybrid approach that incorporates NLP-based, data-driven, and interaction techniques together to complete the question understanding. Extensive experiments over real datasets demonstrate that our proposed approach is effective as it outperforms state-of-the-art methods significantly. © 2018 Elsevier Inc.;ScienceDirect;2019;10.1016/j.ins.2018.12.032;Zheng W., Cheng H., Yu J.X., Zou L., Zhao K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059296689&doi=10.1016%2fj.ins.2018.12.032&partnerID=40&md5=c0f1122b7a2ef491a4a36e2de6634c9d;China, Hong Kong;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;semantic similarity computation in knowledge graphs: comparisons and improvements;"Knowledge graph; Semantic similarity; Synonym";Computing semantic similarity between concepts is a fundamental task in natural language processing and has a large variety of applications. In this paper, first of all, we will review and analyze existing semantic similarity computation methods in knowledge graphs. Through the analysis of these methods, we find that existing works mainly focus on the context features of concepts which indicate the position or the frequency of the concepts in the knowledge graphs, such as the depth of terms, information content of the terms, or the distance between terms, while a fundamental part to describe the meaning of the concept, the synsets of concepts, are neglected for a long term. Thus, in this paper, we propose a new method to compute the similarity of concepts based on their extended synsets. Moreover, we propose a general hybrid framework, which can combine our new similarity measure based on extended synsets with any of existing context feature based semantic similarities to evaluate the concepts more accurately. We conducted experiments on five well-known datasets for semantic similarity evaluation, and the experimental results show that our general framework can improve most of existing methods significantly. © 2019 IEEE.;Scopus;2019;10.1109/icdew.2019.000-5;Yang C., Zhu Y., Zhong M., Li R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069231114&doi=10.1109%2fICDEW.2019.000-5&partnerID=40&md5=9c72f6589f2083035fe8398c243a18fc;China;semantic similarity;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;relation classification in knowledge graph based on natural language text;"bidirectinal GRU; distant supervisin; knowledge graph; relation classification";Relation classification is an important semantic processing task in natural language processing, and it is also an important task to construct knowledge graph based on natural language text. At present, the cutting-edge method in the field of natural language processing is to obtain some advanced features based on deep learning. One problem is that important features of a sentence can appear anywhere in the sentence. Another problem is that building a domain-specific knowledge map often lacks annotated data. In order to solve these problems, this paper proposes to obtain labeled corpus by distant supervision, and use bidirectional GRU to get relationship between entities. Because the corpus is Chinese so use the word vector as input. At the same time, the attention mechanism is applied to reduce the weight of the noise instance. Finally, the classification model is tested on open dataset and get a good result. © 2018 IEEE.;IEEE;2019;10.1109/icsess.2018.8663945;Song Y., Rao R.N., Shi J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063649445&doi=10.1109%2fICSESS.2018.8663945&partnerID=40&md5=f9c3bdb4ce94a8ff6122266299726025;China;relation classification;validation research;technique;;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a knowledge graph based approach for automatic speech and essay summarization;"Knowledge Graphs; Named Entity Recognition; NLP; Speech Analysis";Every day, big amounts of unstructured data is generated. This data is of the form of essays, research papers, speeches, patents, scholastic articles, book chapters etc. In today's world, it is very important to extract key patterns from huge text passages or verbal speeches. This paper proposes a novel method for summarizing multilingual vocal as well as written paragraphs and speeches, using semantic Knowledge Graphs. Using the proposed model, big text extracts or speeches can be summarized for better understanding and analysis. The method uses speech recognition as well as Named Entity Recognition to identify entities from spoken content to create optimized Knowledge Graphs in the English Language. © 2019 IEEE.;Scopus;2019;10.1109/i2ct45611.2019.9033908;Khadilkar K., Kulkarni S., Venkatraman S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083072791&doi=10.1109%2fI2CT45611.2019.9033908&partnerID=40&md5=52dd58fcd8695857771e14b3307126c1;Australia, India;"entity extraction; relation extraction";solution proposal;method;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a methodology for extracting knowledge about controlled vocabularies from textual data using fca-based ontology engineering;"Controlled vocabulary; Formal Concept Analysis; Natural Language Processing; Ontology learning; Semantic knowledge extraction";We introduce an end-to-end methodology (from text processing to querying a knowledge graph) for the sake of knowledge extraction from text corpora with a focus on a list of vocabularies of interest. We propose a pipeline that incorporates Natural Language Processing (NLP), Formal Concept Analysis (FCA), and Ontology Engineering techniques to build an ontology from textual data. We then extract the knowledge about controlled vocabularies by querying that knowledge graph, i.e., the engineered ontology. We demonstrate the significance of the proposed methodology by using it for knowledge extraction from a text corpus that consists of 800 news articles and reports about companies and products in the IT and pharmaceutical domain, where the focus is on a given list of 250 controlled vocabularies. © 2018 IEEE.;IEEE;2019;10.1109/bibm.2018.8621239;Jabbari S., Stoffel K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062533489&doi=10.1109%2fBIBM.2018.8621239&partnerID=40&md5=51d5ab6af8286e2415b936bae2f93c5e;Switzerland;"ontology construction; semantic search";solution proposal;method;;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1
Conference Paper;leveraging knowledge graph for open-domain question answering;"Automated Question Answering; Diffbot Knowledge Graph; Information Retrieval; Natural Language Processing";Rich and comprehensive knowledge graphs (KG) of the Web, such as, Google KG, NELL, and Diffbot KG, are becoming increasingly prevalent and powerful as the underlying AI technology is rapidly progressing. In this work, we leverage this ongoing advancement for the task of answering questions posed from any domain and any type (factoid and non-factoid). We present a framework for knowledge graph based question answering systems, KGQA, and experiment with an instance of this framework that employs Diffbot KG. The unique features offered by KGs, such as, rapid query response time, connections between related graph objects, and structured information, are used to design a QA system that is effective and efficient. © 2018 IEEE.;IEEE;2019;10.1109/wi.2018.00-63;Ortiz Costa J., Kulkarni A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061928044&doi=10.1109%2fWI.2018.00-63&partnerID=40&md5=a5c9365ae0c71db1a0eff53f09a2afa8;United States;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a survey of relation extraction of knowledge graphs;"Knowledge graph; Machine learning; Relation extraction";With the widespread use of big data, knowledge graph has become a new hotspot. It is used in intelligent question answering, recommendation system, map navigation and so on. Constructing a knowledge graph includes ontology construction, annotated data, relation extraction, and ontology inspection. Relation extraction is to solve the problem of entity semantic linking, which is of great significance to many natural language processing applications. Research related to relation extraction has gained momentum in recent years, necessitating a comprehensive survey to offer a bird’s-eye view of the current state of relation extraction. In this paper, we discuss the development process of relation extraction, and classify the relation extraction algorithms in recent years. Furthermore, we discuss deep learning, reinforcement learning, active learning and transfer learning. By analyzing the basic principles of supervised learning, unsupervised learning, semi-supervised learning and distant supervision, we elucidate the characteristics of different relation extraction algorithms, and give the potential research directions in the future. © Springer Nature Switzerland AG 2019.;Scopus;2019;10.1007/978-3-030-33982-1_5;Li A., Wang X., Wang W., Zhang A., Li B.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090282440&doi=10.1007%2f978-3-030-33982-1_5&partnerID=40&md5=deeaf3415e8f4a278d70c2c69435314c;China;relation extraction;secondary research;guidelines;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;simple question answering with subgraph ranking and joint-scoring;"Graphic methods; Knowledge based systems; Knowledge base; Knowledge graphs; Loss functions; Question Answering; Ranking methods; Research communities; State of the art; Unified framework; Computational linguistics";Knowledge graph based simple question answering (KBSQA) is a major area of research within question answering. Although only dealing with simple questions, i.e., questions that can be answered through a single knowledge base (KB) fact, this task is neither simple nor close to being solved. Targeting on the two main steps, subgraph selection and fact selection, the research community has developed sophisticated approaches. However, the importance of subgraph ranking and leveraging the subject-relation dependency of a KB fact have not been sufficiently explored. Motivated by this, we present a unified framework to describe and analyze existing approaches. Using this framework as a starting point, we focus on two aspects: improving subgraph selection through a novel ranking method and leveraging the subject-relation dependency by proposing a joint scoring CNN model with a novel loss function that enforces the well-order of scores. Our methods achieve a new state of the art (85.44% in accuracy) on the SimpleQuestions dataset. © 2019 Association for Computational Linguistics;ACL;2019;;Zhao W., Chung T., Goyal A., Metallinou A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085585112&partnerID=40&md5=ca516900d7646ea683baa65ab240ddb9;United States;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;generating knowledge graph paths from textual definitions using sequence-to-sequence models;"Computational linguistics; Mapping; Knowledge graphs; Mapping systems; Model outputs; Proof of concept; Sequence models; State-of-the-art system; Structured prediction; Unrestricted texts; Graph theory";We present a novel method for mapping unrestricted text to knowledge graph entities by framing the task as a sequence-to-sequence problem. Specifically, given the encoded state of an input text, our decoder directly predicts paths in the knowledge graph, starting from the root and ending at the target node following hypernym-hyponym relationships. In this way, and in contrast to other text-to-entity mapping systems, our model outputs hierarchically structured predictions that are fully interpretable in the context of the underlying ontology, in an end-to-end manner. We present a proof-of-concept experiment with encouraging results, comparable to those of state-of-the-art systems. © 2019 Association for Computational Linguistics;ACL;2019;;Prokhorov V., Pilehvar M.T., Collier N.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085580987&partnerID=40&md5=75fa179b9d98094c591880397d81fb45;United Kingdom;"entity linking; link prediction";validation research;technique;;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;long-tail relation extraction via knowledge graph embeddings and graph convolution networks;"Computational linguistics; Convolution; Embeddings; Extraction; Knowledge management; Large dataset; Semantics; Attention mechanisms; Benchmark datasets; Class distributions; Coarse to fine; Imbalanced data; Knowledge graphs; Real world setting; Relation extraction; Data mining";We propose a distance supervised relation extraction approach for long-tailed, imbalanced data which is prevalent in real-world settings. Here, the challenge is to learn accurate”few-shot” models for classes existing at the tail of the class distribution, for which little data is available. Inspired by the rich semantic correlations between classes at the long tail and those at the head, we take advantage of the knowledge from data-rich classes at the head of the distribution to boost the performance of the data-poor classes at the tail. First, we propose to leverage implicit relational knowledge among class labels from knowledge graph embeddings and learn explicit relational knowledge using graph convolution networks. Second, we integrate that relational knowledge into relation extraction model by coarse-to-fine knowledge-aware attention mechanism. We demonstrate our results for a large-scale benchmark dataset which show that our approach significantly outperforms other baselines, especially for long-tail relations. © 2019 Association for Computational Linguistics;ACL;2019;;Zhang N., Deng S., Sun Z., Wang G., Chen X., Zhang W., Chen H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085555333&partnerID=40&md5=c86d6bb110af1f2b70bac3b2301cc74f;China;"relation extraction; knowledge graph embedding";validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;node embeddings for graph merging: case of knowledge graph construction;"Embeddings; Errors; Graph algorithms; Graphic methods; Merging; Natural language processing systems; Error reduction; Graph-based; Knowledge graphs; Matching methods; Process errors; String similarity; Text corpora; Two-graphs; Graph theory";Combining two graphs requires merging the nodes which are counterparts of each other. In this process errors occur, resulting in incorrect merging or incorrect failure to merge. We find a high prevalence of such errors when using AskNET, an algorithm for building Knowledge Graphs from text corpora. AskNET node matching method uses string similarity, which we propose to replace with vector embedding similarity. We explore graph-based and wordbased embedding models and show an overall error reduction of from 56% to 23.6%, with a reduction of over a half in both types of incorrect node matching. © 2019 EMNLP-IJCNLP 2019 - Graph-Based Methods for Natural Language Processing - Proceedings of the 13th Workshop. All rights reserved.;ACL;2019;;Szubert I., Steedman M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085036865&partnerID=40&md5=28bd67adc5310fa8700c9bfc54d763b0;United Kingdom;"entity alignment; knowledge graph embedding";validation research;technique;;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;relation prediction for unseen-entities using entity-word graphs;"Forecasting; Graph structures; Graphic methods; Knowledge graphs; Word graphs; Natural language processing systems";Knowledge graphs (KGs) are generally used for various NLP tasks. However, as KGs still miss some information, it is necessary to develop Knowledge Graph Completion (KGC) methods. Most KGC researches do not focus on the Out-of-KGs entities (Unseen-entities), we need a method that can predict the relation for the entity pairs containing Unseen-entities to automatically add new entities to the KGs. In this study, we focus on relation prediction and propose a method to learn entity representations via a graph structure that uses Seenentities, Unseen-entities and words as nodes created from the descriptions of all entities. In the experiments, our method shows a significant improvement in the relation prediction for the entity pairs containing Unseen-entities. © 2019 EMNLP-IJCNLP 2019 - Graph-Based Methods for Natural Language Processing - Proceedings of the 13th Workshop. All rights reserved.;ACL;2019;;Tagawa Y., Taniguchi M., Miura Y., Taniguchi T., Ohkuma T., Yamamoto T., Nemoto K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085025805&partnerID=40&md5=5335d10699cca3d052813bbbbd3ed7e4;Japan;"knowledge graph embedding; relation classification";validation research;technique;;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;integrating semantic knowledge to tackle zero-shot text classification;"Character recognition; Computational linguistics; Information retrieval systems; Semantics; Text processing; Class hierarchies; Classification tasks; Data augmentation; General knowledge; Overall accuracies; Semantic knowledge; Text classification; Training data; Classification (of information)";Insufficient or even unavailable training data of emerging classes is a big challenge of many classification tasks, including text classification. Recognising text documents of classes that have never been seen in the learning stage, so-called zero-shot text classification, is therefore difficult and only limited previous works tackled this problem. In this paper, we propose a two-phase framework together with data augmentation and feature augmentation to solve this problem. Four kinds of semantic knowledge (word embeddings, class descriptions, class hierarchy, and a general knowledge graph) are incorporated into the proposed framework to deal with instances of unseen classes effectively. Experimental results show that each and the combination of the two phases achieve the best overall accuracy compared with baselines and recent approaches in classifying real-world texts under the zero-shot scenario. © 2019 Association for Computational Linguistics;ACL;2019;;Zhang J., Lertvittayakumjorn P., Guo Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084312963&partnerID=40&md5=31fda81739e5648fc3effe72b16c09f9;United Kingdom;text classification;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;qaldgen: towards microbenchmarking of question answering systems over knowledge graphs;"Benchmarking; Clustering algorithms; HTTP; Natural language processing systems; Open source software; GNU general public license; Important features; Knowledge graphs; Micro-benchmarking; Natural language questions; Question Answering; Question answering systems; State of the art; Semantic Web";Over the last years, a number of Knowledge Graph (KG) based Question Answering (QA) systems have been developed. Consequently, the series of Question Answering Over Linked Data (QALD1–QALD9) challenges and other datasets have been proposed to evaluate these systems. However, the QA datasets contain a fixed number of natural language questions and do not allow users to select micro benchmarking samples of the questions tailored towards specific use-cases. We propose QaldGen, a framework for microbenchmarking of QA systems over KGs which is able to select customised question samples from existing QA datasets. The framework is flexible enough to select question samples of varying sizes and according to the user-defined criteria on the most important features to be considered for QA benchmarking. This is achieved using different clustering algorithms. We compare state-of-the-art QA systems over knowledge graphs by using different QA benchmarking samples. The observed results show that specialised micro-benchmarking is important to pinpoint the limitations of the various QA systems and its components. Resource Type: Evaluation benchmarks or Methods Repository: https://github.com/dice-group/qald-generator License: GNU General Public License v3.0 © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-30796-7_18;Singh K., Saleem M., Nadgeri A., Conrads F., Pan J.Z., Ngomo A.-C.N., Lehmann J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081092804&doi=10.1007%2f978-3-030-30796-7_18&partnerID=40&md5=bdf48e5071cdd83a30a784c944b85152;Germany, United Kingdom, India;question answering;validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;old is gold: linguistic driven approach for entity and relation linking of short text;"Computational linguistics; Gold; Back-ground knowledge; Empirical studies; Fundamental principles; Knowledge graphs; Knowledge sources; Linguistic approach; Named entity recognition; State of the art; Knowledge management";Short texts challenge NLP tasks such as named entity recognition, disambiguation, linking and relation inference because they do not provide sufficient context or are partially malformed (e.g. wrt. capitalization, long tail entities, implicit relations). In this work, we present the Falcon approach which effectively maps entities and relations within a short text to its mentions of a background knowledge graph. Falcon overcomes the challenges of short text using a light-weight linguistic approach relying on a background knowledge graph. Falcon performs joint entity and relation linking of a short text by leveraging several fundamental principles of English morphology (e.g. compounding, headword identification) and utilizes an extended knowledge graph created by merging entities and relations from various knowledge sources. It uses the context of entities for finding relations and does not require training data. Our empirical study using several standard benchmarks and datasets show that Falcon significantly outperforms state-of-the-art entity and relation linking for short text query inventories. © 2019 Association for Computational Linguistics;ACL;2019;;Sakor A., Mulang I.O., Singh K., Shekarpour S., Vidal M.-E., Lehmann J., Auer S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081090168&partnerID=40&md5=d93ebebd95c7e03c292d4b885c224512;Germany, United States;"entity linking; relation linking";validation research;tool;;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;text generation from knowledge graphs with graph transformers;"Computational linguistics; Decoding; Knowledge management; Knowledge representation; Signal encoding; Ubiquitous computing; Document structure; Human evaluation; Information extraction systems; Knowledge graphs; Long-distance dependencies; Relational structures; Scientific texts; Trainable system; Graph structures";Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods. © 2019 Association for Computational Linguistics;ACL;2019;;Koncel-Kedziorski R., Bekal D., Luan Y., Lapata M., Hajishirzi H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079655513&partnerID=40&md5=ca349cd558be9df6d472894bc5d0745f;United Kingdom, United States;"augmented language models; data-to-text generation";validation research;tool;scholarly domain;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;uhop: an unrestricted-hop relation extraction framework for knowledge-based question answering;"Computational linguistics; Extraction; Knowledge based systems; Competitive performance; Knowledge based; Knowledge graphs; Number of hops; Performance gaps; Question Answering; Relation extraction; State of the art; Data mining";In relation extraction for knowledge-based question answering, searching from one entity to another entity via a single relation is called “one hop”. In related work, an exhaustive search from all one-hop relations, two-hop relations, and so on to the max-hop relations in the knowledge graph is necessary but expensive. Therefore, the number of hops is generally restricted to two or three. In this paper, we propose UHop, an unrestricted-hop framework which relaxes this restriction by use of a transition-based search framework to replace the relation-chain-based search one. We conduct experiments on conventional 1- and 2-hop questions as well as lengthy questions, including datasets such as WebQSP, PathQuestion, and Grid World. Results show that the proposed framework enables the ability to halt, works well with state-of-the-art models, achieves competitive performance without exhaustive searches, and opens the performance gap for long relation paths. © 2019 Association for Computational Linguistics;ACL;2019;;Chen Z.-Y., Chang C.-H., Chen Y.-P., Nayak J., Ku L.-W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078931467&partnerID=40&md5=848b379bc05192f761eae9408b6baf8d;India, United States;"question answering; relation extraction";validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a deep neural network model for joint entity and relation extraction;"Automatic knowledge graph construction; deep neural networks; entity and relation extraction; natural language processing; pointer networks; relational triplet extraction; sequence-to-sequence learning";Joint extraction of entities and their relations from the text is an essential issue in automatic knowledge graph construction, which is also known as the joint extraction of relational triplets. The relational triplets in sentence are complicated, multiple and different relational triplets may have overlaps, which is commonly seen in reality. However, multiple pairs of triplets cannot be efficiently extracted in most of the previous works. To mitigate this problem, we propose a deep neural network model based on the sequence-to-sequence learning, namely, the hybrid dual pointer networks (HDP), which extracts multiple pairs of triplets from the given sentence by generating the hybrid dual pointer sequence. In experiments, we tested our model using the New York Times (NYT) public dataset. The experimental results demonstrated that our model outperformed the state-of-the-art work, and achieved a 17.1% improvement on the F1 values. © 2013 IEEE.;IEEE;2019;10.1109/access.2019.2949086;Pang Y., Liu J., Liu L., Yu Z., Zhang K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077241235&doi=10.1109%2fACCESS.2019.2949086&partnerID=40&md5=f44050826fcd5d272602eb42755f91af;China;"entity extraction; relation extraction";validation research;technique;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;querying knowledge graphs with natural languages;"Expert systems; Graphic methods; Natural language processing systems; Pattern matching; Semantics; Graph pattern matching; Knowledge graphs; Natural language queries; Natural languages; Query algorithms; Query evaluation; Subgraph isomorphism; Top-k-matches; Query processing";"With the unprecedented proliferation of knowledge graphs, how to process query evaluation over them becomes increasingly important. On knowledge graphs, queries are typically evaluated with graph pattern matching, i.e., given a pattern query Q and a knowledge graph G, it is to find the set M(Q, G) of matches of Q in G, where matching is defined with subgraph isomorphism. However querying big knowledge graphs brings us challenges: (1) queries are often issued with natural languages, hence can not be evaluated directly; (2) query evaluation is very costly and match results are often difficult to inspect. In light of these, this paper studies the problem of querying knowledge graphs with natural languages. (1) We extend pattern queries by designating a node uo as “query focus”, and revise the matching semantic based on the extension. (2) We develop techniques to understand natural language queries, and generate pattern queries with “query focus”. (3) We develop efficient techniques to identify top-k matches of “query focus”. (4) We experimentally verify that our techniques for query understanding perform well, and our query algorithm is able to find diversified top-k matches efficiently. © 2019, Springer Nature Switzerland AG.";Scopus;2019;10.1007/978-3-030-27618-8_3;Wang X., Yang L., Zhu Y., Zhan H., Jin Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077129551&doi=10.1007%2f978-3-030-27618-8_3&partnerID=40&md5=cd4fd8ce028f66e5f94e3a0eed394057;China;question answering;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;difficulty-controllable multi-hop question generation from knowledge graphs;"Knowledge graph; Natural language processing; Neural network; Question generation; Transformer";Knowledge graphs have become ubiquitous data sources and their utility has been amplified by the research on ability to answer carefully crafted questions over knowledge graphs. We investigate the problem of question generation (QG) over knowledge graphs wherein, the level of difficulty of the question can be controlled. We present an end-to-end neural network-based method for automatic generation of complex multi-hop questions over knowledge graphs. Taking a subgraph and an answer as input, our transformer-based model generates a natural language question. Our model incorporates difficulty estimation based on named entity popularity, and makes use of this estimation to generate difficulty-controllable questions. We evaluate our model on two recent multi-hop QA datasets. Our evaluation shows that our model is able to generate high-quality, fluent and relevant questions. We have released our curated QG dataset and code at https://github.com/liyuanfang/mhqg. © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-30793-6_22;Kumar V., Hua Y., Ramakrishnan G., Qi G., Gao L., Li Y.-F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075720005&doi=10.1007%2f978-3-030-30793-6_22&partnerID=40&md5=9ef13d2dfba894395c43d0e9965d082b;Australia, China, India;"question generation; question answering";validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;improving named entity recognition with commonsense knowledge pre-training;"Commonsense; ConceptNet; Deep neural networks; Word embeddings";Commonsense can be vital in some applications like Natural Language Understanding, where it is often required to resolve ambiguity arising from implicit knowledge and under-specification. In spite of the remarkable success of neural network approaches on a variety of Natural Language Processing tasks, many of them struggle to react effectively in cases that require commonsense knowledge. In the present research paper, we take advantage of the availability of the open multilingual knowledge graph ConceptNet, by using it as an additional external resource in a Named Entity Recognition system (NER). Our proposed architecture involves BiLSTM layers combined with a CRF layer that was augmented with some features such as pre-trained word embedding layers and dropout layers. Moreover, apart from using word representations, we used also character-based representation to capture the morphological and the orthographic information. Our experiments and evaluations showed an improvement in the overall performance with +2.86 in the F1-measure. To the best of our knowledge, there is no study relating the integration of a commonsense knowledge base in NER. © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-30639-7_2;Dekhili G., Le N.T., Sadat F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072853690&doi=10.1007%2f978-3-030-30639-7_2&partnerID=40&md5=c11be8283c4bb247e076e2b193ba4c04;Canada;entity extraction;validation research;technique;;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;okgraph: unsupervised structured data extraction from plain text;"Knowledge graphs; Machine understanding; Unsupervised learning; Word embeddings";In this report we introduce OKgraph, a software library for (open) Knowledge Graph extraction from free text. Named after a two-year project where we studied and developed unsupervised algorithms addressing tasks related to taxonomy learning, the library contains NLP tools powered by these results. Copyright © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).;Scopus;2019;;Atzori M., Balloccu S., Bellanti A., Mameli E., Usai S.R.;http://ceur-ws.org/Vol-2441/paper19.pdf;Italy;"entity classification; entity extraction; relation extraction";validation research;tool;;1;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;integration of knowledge graph embedding into topic modeling with hierarchical dirichlet process;"Computational linguistics; Embeddings; Information retrieval systems; Knowledge management; Bayesian nonparametric modeling; Document Classification; Hierarchical Dirichlet process; Hierarchical dirichlet process (HDP); Integration of knowledge; Large document corpora; Low-dimensional representation; Variational inference methods; Classification (of information)";Leveraging domain knowledge is an effective strategy for enhancing the quality of inferred low-dimensional representations of documents by topic models. In this paper, we develop topic modeling with knowledge graph embedding (TMKGE), a Bayesian nonparametric model to employ knowledge graph (KG) embedding in the context of topic modeling, for extracting more coherent topics. Specifically, we build a hierarchical Dirichlet process (HDP) based model to flexibly borrow information from KG to improve the interpretability of topics. An efficient online variational inference method based on a stick-breaking construction of HDP is developed for TMKGE, making TMKGE suitable for large document corpora and KGs. Experiments on three public datasets illustrate the superior performance of TMKGE in terms of topic coherence and document classification accuracy, compared to state-of-the-art topic modeling methods. © 2019 Association for Computational Linguistics;ACL;2019;;Li D., Dadaneh S.Z., Zhang J., Li P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071153019&partnerID=40&md5=ee9ffcf1663cd95d39e3c0878e18d238;United States;"augmented language models; text analysis; knowledge graph embedding";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;leveraging domain context for question answering over knowledge graph;"Big data; Natural language processing systems; Semantics; Complex questions; Domain knowledge; Information interaction; Knowledge graphs; New approaches; Question Answering; Real data sets; Semantic parsing; Knowledge management";This paper focuses on the problem of question answering over knowledge graph (KG-QA). With the increasing availability of different knowledge graphs in a variety of domains, KG-QA becomes a prevalent information interaction approach. Current KG-QA methods usually resort to semantic parsing, retrieval or neural matching based models. However, current methods generally ignore the rich domain context, i.e., category and surrounding descriptions within the knowledge graphs. Experiments shows that they can not well tackle the complex questions and information needs. In this work, we propose a new KG-QA approach, leveraging the domain context. The new method designs a neural cross-attention QA framework. We incorporate the new approach with question and answer domain contexts. Specifically, for questions, we enrich them with users' access log, and for the answers, we equip them with meta-paths within the target knowledge graph. Experimental study on real datasets verifies its improvement. The new approach is especially beneficial for domain knowledge graphs. © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-26072-9_27;Tong P., Yao J., He L., Xu L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070012145&doi=10.1007%2f978-3-030-26072-9_27&partnerID=40&md5=83103122ed6026651a53102d473bc7d3;China;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;leveraging lexical semantic information for learning concept-based multiple embedding representations for knowledge graph completion;"Concept information; Knowledge graph completion; Representation learning";Knowledge graphs (KGs) are important resources for a variety of natural language processing tasks but suffer from incompleteness. To address this challenge, a number of knowledge graph completion (KGC) methods have been developed using low-dimensional graph embeddings. Most existing methods focus on the structured information of triples in encyclopaedia KG and maximize the likelihood of them. However, they neglect semantic information contained in lexical KG. To overcome this drawback, we propose a novel KGC method (named as TransC), that integrates the structured information in encyclopaedia KG and the entity concepts in lexical KG, which describe the categories of entities. Since all entities appearing in the head (or tail) position with the same relation have some common concepts, we introduce a novel semantic similarity to measure the distinction of entity semantics with the concept information. And then TransC utilizes concept-based semantic similarity of the related entities and relations to capture prior distributions of entities and relations. With the concept-based prior distributions, TransC generates multiple embedding representations of each entity in different contexts and estimates the posterior probability of entity and relation prediction. Experimental results demonstrate the efficiency of the proposed method on two benchmark datasets. © 2019, Springer Nature Switzerland AG.;Scopus;2019;10.1007/978-3-030-26072-9_28;Wang Y., Liu Y., Zhang H., Xie H.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069979622&doi=10.1007%2f978-3-030-26072-9_28&partnerID=40&md5=cd6cd31782a1a4a013236ca86cb45dfe;China;"entity classification; relation classification; triple classification; knowledge graph embedding";validation research;technique;;0;0;0;0;0;0;0;1;1;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;hierarchical ontology graph for solving semantic issues in decision support systems;"Decision support systems; Knowledge graph; Neural-symbolic integration; NLP; Ontology graph; Semantic composition";In the context of the development of AI algorithms in natural language processing, tremendous progress has been made in knowledge abstraction and semantic reasoning. However, for answering the questions with complex logic, AI system is still in an early stage. Hierarchical ontology graph is proposed to establish analysis threads for the complex question in order to facilitate AI system to further support in business decision making. The study of selecting the appropriate corpora is intended to improve the data asset management of enterprises. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.;Scopus;2019;10.5220/0007769904830487;Guo H., Liu K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067517322&doi=10.5220%2f0007769904830487&partnerID=40&md5=a64e2a8ca25263f2765e6651ad2fcab4;United Kingdom;semantic search;solution proposal;guidelines;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;automated event extraction model for linked portuguese documents;"Data mining; Learning systems; Natural language processing systems; Event extraction; Knowledge graphs; Named entities; Ontological structures; Question Answering; Sparql queries; Extraction";In recent times, Machine Learning is booming and researchers are applying it to the most conceivable cases such as the area of linked documents. This article presents a process of automatic event extraction from Portuguese linked document whose accuracy (95.00%) was calculated by manual verification. With the help of an ontological structure, extracted events are mapped as a knowledge graph that represents the named entities and the events associated with each document. Such graphs are accessible through SPARQL queries. This way, the information existing in the linked documents can be easily accessed by resorting to a question-answering approach. Copyright © 2019 for the individual papers by the paper’s authors. Copying permitted for private and academic purposes. This volume is published and copyrighted by its editors.;Scopus;2019;;Kashyap R., Teresa G., Paulo Q., Beires Nogueira V.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066468101&partnerID=40&md5=500890662a4847a6b58ea9ca396e6d6d;Portugal;entity extraction;validation research;method;;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1
Journal Article;embedding logic rules into recurrent neural networks;"logic rules; named entity recognition; RNN; sentiment classification";Incorporating prior knowledge into recurrent neural network (RNN) is of great importance for many natural language processing tasks. However, most of the prior knowledge is in the form of structured knowledge and is difficult to be exploited in the existing RNN framework. By extracting the logic rules from the structured knowledge and embedding the extracted logic rule into the RNN, this paper proposes an effective framework to incorporate the prior information in the RNN models. First, we demonstrate that commonly used prior knowledge could be decomposed into a set of logic rules, including the knowledge graph, social graph, and syntactic dependence. Second, we present a technique to embed a set of logic rules into the RNN by the way of feedback masks. Finally, we apply the proposed approach to the sentiment classification and named entity recognition task. The extensive experimental results verify the effectiveness of the embedding approach. The encouraging results suggest that the proposed approach has the potential for applications in other NLP tasks. © 2019 IEEE.;IEEE;2019;10.1109/access.2019.2892140;Chen B., Hao Z., Cai X., Cai R., Wen W., Zhu J., Xie G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061738019&doi=10.1109%2fACCESS.2019.2892140&partnerID=40&md5=406e85a9e3261688e498aef73d7594e7;China;augmented language models;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;graph embedding based query construction over knowledge graphs;"Knowledge graph; Knowledge graph embedding; Natural language question answering; Query construction";Graph-structured queries provide an efficient way to retrieve the desired data from large-scale knowledge graphs. However, it is difficult for non-expert users to write such queries, and users prefer expressing their query intention through natural language questions. Therefore, automatically constructing graph-structured queries of given natural language questions has received wide attention in recent years. Most existing methods rely on natural language processing techniques to perform the query construction process, which is complicated and time-consuming. In this paper, we focus on the query construction process and propose a novel framework which stands on recent advances in knowledge graph embedding techniques. Our framework first encodes the underlying knowledge graph into a low-dimensional embedding space by leveraging the generalized local knowledge graphs. Then, given a natural language question, our framework computes the structure of the target query and determines the vertices/edges which form the target query based on the learned embedding vectors. Finally, the target graph-structured query is constructed according to the query structure and determined vertices/edges. Extensive experiments were conducted on the benchmark dataset. The results demonstrate that our framework outperforms several state-of-the-art baseline models regarding effectiveness and efficiency. ©2018 IEEE;IEEE;2018;10.1109/icbk.2018.00009;Wang R., Wang M., Liu J., Yao S., Zheng Q.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061368151&doi=10.1109%2fICBK.2018.00009&partnerID=40&md5=49caf2aa9e0874c02c32174f9252d0ae;China;"question answering; knowledge graph embedding";validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;multiview clustering via unified and view-specific embeddings learning;"Incomplete multiview data; knowledge graph embedding; multiview learning; subspace learning";"Multiview clustering, which aims at using multiple distinct feature sets to boost clustering performance, has a wide range of applications. A subspace-based approach, a type of widely used methods, learns unified embedding from multiple sources of information and gives a relatively good performance. However, these methods usually ignore data similarity rankings; for example, example A may be more similar to B than C, and such similarity triplets may be more effective in revealing the data cluster structure. Motivated by recent embedding methods for modeling knowledge graph in natural-language processing, this paper proposes to mimic different views as different relations in a knowledge graph for unified and view-specific embedding learning. Moreover, in real applications, it happens so often that some views suffer from missing information, leading to incomplete multiview data. Under such a scenario, the performance of conventional multiview clustering degenerates notably, whereas the method we propose here can be naturally extended for incomplete multiview clustering, which enables full use of examples with incomplete feature sets for model promotion. Finally, we demonstrate through extensive experiments that our method performs better than the state-of-the-art clustering methods. © 2012 IEEE.";IEEE;2018;10.1109/tnnls.2017.2786743;Yin Q., Wu S., Wang L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043366384&doi=10.1109%2fTNNLS.2017.2786743&partnerID=40&md5=fa92ff5c6dbae29b0f71c2746298fef9;China;knowledge graph embedding;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;sentence comprehension and semantic syntheses by cognitive machine learning;"AI; Algorithms; Cognitive computing; Cognitive systems; Computational intelligence; Computational linguistics; Machine knowledge learning; Natural language processing; Semantic computing";Recent development in machine learning and computational linguistics has enabled cognitive machines to understand the semantics of human expressions. A system for sentence syntactic analysis and semantic synthesis is developed based on denotational mathematics. Machine sentence learning and comprehension are reduced to the building of a composed concept that maps the semantics of the subject onto the counterpart of object(s) represented by formal concepts and phrases. A set of semantic operations such as concept composition, modification, generalization, specification, extension and reduction is formally specified based on concept algebra and semantic algebra for machine learning. An Algorithm for Unsupervised Sentence Learning (AUSL) is designed and implemented, which expresses a learnt sentence as a knowledge graph related to the semantic hierarchy of the machine's knowledge base. Experimental results demonstrate the autonomous learning algorithm and case studies on machine learning towards applications in cognitive robots and knowledge learning systems. © 2018 IEEE.;IEEE;2018;10.1109/icci-cc.2018.8482024;Valipour M., Wang Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056452607&doi=10.1109%2fICCI-CC.2018.8482024&partnerID=40&md5=27da2970d1bc95a2a2b80b882e9140ef;Canada;semantic parsing;solution proposal;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;using multiple web resources and inference rules to classify chinese word semantic relation;"Chinese word semantic relation; Inference rules; Lexical relation; Morpho syntactics; Ontology; Semantic relation classification";Purpose: The purpose of this paper is to classify Chinese word semantic relations, which are synonyms, antonyms, hyponyms and meronymys. Design/methodology/approach: Basically, four simple methods are applied, ontology-based, dictionary-based, pattern-based and morpho-syntactic method. The authors make good use of search engine to build lexical and semantic resources for dictionary-based and pattern-based methods. To improve classification performance with more external resources, they also classify the given word pairs in Chinese and in English at the same time by using machine translation. Findings: Experimental results show that the approach achieved an average F1 score of 50.87 per cent, an average accuracy of 70.36 per cent and an average recall of 40.05 per cent over all classification tasks. Synonym and antonym classification achieved high accuracy, i.e. above 90 per cent. Moreover, dictionary-based and pattern-based approaches work effectively on final data set. Originality/value: For many natural language processing (NLP) tasks, the step of distinguishing word semantic relation can help to improve system performance, such as information extraction and knowledge graph generation. Currently, common methods for this task rely on large corpora for training or dictionaries and thesauri for inference, where limitation lies in freely data access and keeping built lexical resources up-date. This paper builds a primary system for classifying Chinese word semantic relations by seeking new ways to obtain the external resources efficiently. © 2018, Emerald Publishing Limited.;Scopus;2018;10.1108/idd-03-2018-0010;Ma S., Zhang Y., Zhang C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051177141&doi=10.1108%2fIDD-03-2018-0010&partnerID=40&md5=26f5fc665c2e4d820442ba81a146c6ee;China;relation classification;solution proposal;method;;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;enriching word embeddings with domain knowledge for readability assessment;"Computational linguistics; Domain Knowledge; Knowledge graph; Semantics; Domain knowledge; Embeddings; Knowledge graphs; Learn+; Loss functions; Semantic relations; Word level; Embeddings";In this paper, we present a method which learns the word embedding for readability assessment. For the existing word embedding models, they typically focus on the syntactic or semantic relations of words, while ignoring the reading difficulty, thus they may not be suitable for readability assessment. Hence, we provide the knowledge-enriched word embedding (KEWE), which encodes the knowledge on reading difficulty into the representation of words. Specifically, we extract the knowledge on word-level difficulty from three perspectives to construct a knowledge graph, and develop two word embedding models to incorporate the difficulty context derived from the knowledge graph to define the loss functions. Experiments are designed to apply KEWE for readability assessment on both English and Chinese datasets, and the results demonstrate both effectiveness and potential of KEWE. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.;ACL;2018;;Jiang Z., Gu Q., Yin Y., Chen D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119407962&partnerID=40&md5=5e5d5bf1d59a8e84a572d8b7dd592b78;China;text classification;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;cooperative denoising for distantly supervised relation extraction;"Computational linguistics; Distillation; Extraction; Knowledge management; Bi-directional; De-noising; Knowledge graphs; Labelings; Mutual learning; Performance; Relation extraction; State-of-the-art methods; Text corpora; Unstructured texts; Knowledge graph";Distantly supervised relation extraction greatly reduces human efforts in extracting relational facts from unstructured texts. However, it suffers from noisy labeling problem, which can degrade its performance. Meanwhile, the useful information expressed in knowledge graph is still underutilized in the state-of-the-art methods for distantly supervised relation extraction. In the light of these challenges, we propose CORD, a novel COopeRative Denoising framework, which consists two base networks leveraging text corpus and knowledge graph respectively, and a cooperative module involving their mutual learning by the adaptive bi-directional knowledge distillation and dynamic ensemble with noisy-varying instances. Experimental results on a real-world dataset demonstrate that the proposed method reduces the noisy labels and achieves substantial improvement over the state-of-the-art methods. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.;ACL;2018;;Lei K., Chen D., Li Y., Du N., Yang M., Fan W., Shen Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119405619&partnerID=40&md5=2d338ee255c369b1941010d748a8e7ab;China;relation extraction;validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;automatic assessment of conceptual text complexity using knowledge graphs;"Computational linguistics; Graphic methods; Text processing; Automatic assessment; Binary classification; Classification tasks; Discriminative power; Graph-based; High quality; Knowledge graphs; Large knowledge basis; Learner corpora; Simple++; Knowledge graph";Complexity of texts is usually assessed only at the lexical and syntactic levels. Although it is known that conceptual complexity plays a significant role in text understanding, no attempts have been made at assessing it automatically. We propose to automatically estimate the conceptual complexity of texts by exploiting a number of graph-based measures on a large knowledge base. By using a high-quality language learners corpus for English, we show that graph-based measures of individual text concepts, as well as the way they relate to each other in the knowledge graph, have a high discriminative power when distinguishing between two versions of the same text. Furthermore, when used as features in a binary classification task aiming to choose the simpler of two versions of the same text, our measures achieve high performance even in a default setup. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.;ACL;2018;;Štajner S., Hulpuş I.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113796054&partnerID=40&md5=41dfe972929ede701199ee6b7358cd91;Germany;text classification;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;a neural question answering model based on semi-structured tables;"Computational linguistics; End-to-end systems; Knowledge graphs; Model-based OPC; Multiple-choice questions; Question Answering; Question answering systems; Semi-structured; State of the art; Structured knowledge; Text corpora; Knowledge graph";Most question answering (QA) systems are based on raw text and structured knowledge graph. However, raw text corpora are hard for QA system to understand, and structured knowledge graph needs intensive manual work, while it is relatively easy to obtain semi-structured tables from many sources directly, or build them automatically. In this paper, we build an end-to-end system to answer multiple choice questions with semi-structured tables as its knowledge. Our system answers queries by two steps. First, it finds the most similar tables. Then the system measures the relevance between each question and candidate table cells, and choose the most related cell as the source of answer. The system is evaluated with TabMCQ dataset, and gets a huge improvement compared to the state of the art. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.;ACL;2018;;Wang H., Zhang X., Ma S., Sun X., Wang H., Wang M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108798869&partnerID=40&md5=749ef04ce6beca0769a96fbd7fac66fd;China;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;elden: improved entity linking using densified knowledge graphs;"Arts computing; Embeddings; Benchmark datasets; Co-occurrence statistics; Degree of connectivity; Entity similarities; Knowledge graphs; State of the art; Text corpora; Computational linguistics";Entity Linking (EL) systems aim to automatically map mentions of an entity in text to the corresponding entity in a Knowledge Graph (KG). Degree of connectivity of an entity in the KG directly affects an EL system's ability to correctly link mentions in text to the entity in KG. This causes many EL systems to perform well for entities well connected to other entities in KG, bringing into focus the role of KG density in EL. In this paper, we propose Entity Linking using Densified Knowledge Graphs (ELDEN). ELDEN is an EL system which first densifies the KG with co-occurrence statistics from a large text corpus, and then uses the densified KG to train entity embeddings. Entity similarity measured using these trained entity embeddings result in improved EL. ELDEN outperforms stateof-the-Art EL system on benchmark datasets. Due to such densification, ELDEN performs well for sparsely connected entities in the KG too. ELDEN's approach is simple, yet effective. We have made ELDEN's code and data publicly available. © 2018 The Association for Computational Linguistics.;ACL;2018;;Radhakrishnan P., Talukdar P., Varma V.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083504420&partnerID=40&md5=dbb1b33c24df23e2de72e92771f5e6cf;India;entity linking;validation research;tool;;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;retrofitting distributional embeddings to knowledge graphs with functional relations;"Computational linguistics; Embeddings; Encoding (symbols); Graphic methods; Natural language processing systems; Retrofitting; Semantics; 'current; Data relationships; Embeddings; Extract informations; Functional relation; Knowledge graphs; Learn+; Penalty function; Structured data; Unstructured data; Knowledge graph";Knowledge graphs are a versatile framework to encode richly structured data relationships, but it can be challenging to combine these graphs with unstructured data. Methods for retrofitting pre-trained entity representations to the structure of a knowledge graph typically assume that entities are embedded in a connected space and that relations imply similarity. However, useful knowledge graphs often contain diverse entities and relations (with potentially disjoint underlying corpora) which do not accord with these assumptions. To overcome these limitations, we present Functional Retrofitting, a framework that generalizes current retrofitting methods by explicitly modeling pairwise relations. Our framework can directly incorporate a variety of pairwise penalty functions previously developed for knowledge graph completion. Further, it allows users to encode, learn, and extract information about relation semantics. We present both linear and neural instantiations of the framework. Functional Retrofitting significantly outperforms existing retrofitting methods on complex knowledge graphs and loses no accuracy on simpler graphs (in which relations do imply similarity). Finally, we demonstrate the utility of the framework by predicting new drug–disease treatment pairs in a large, complex health knowledge graph. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.;ACL;2018;;Lengerich B.J., Maas A.L., Potts C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083094891&partnerID=40&md5=1b543e2a44f15bc08c2a72105b4779ea;United States;knowledge graph embedding;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;learning beyond datasets: knowledge graph augmented neural networks for natural language processing;"Computational linguistics; Deep learning; Knowledge based systems; Labeled data; Learning algorithms; Natural language processing systems; Text processing; Attention mechanisms; Enhance learning; Knowledge graphs; Labeled training data; NAtural language processing; Natural languages; Prior information; Text classification; Learning systems";Machine Learning has been the quintessential solution for many AI problems, but learning models are heavily dependent on specific training data. Some learning models can be incorporated with prior knowledge using a Bayesian setup, but these learning models do not have the ability to access any organized world knowledge on demand. In this work, we propose to enhance learning models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural Language Processing (NLP) tasks. Our aim is to develop a deep learning model that can extract relevant prior support facts from knowledge graphs depending on the task using attention mechanism. We introduce a convolutionbased model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. We show that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task. Using this method we show significant improvement in performance for text classification with 20Newsgroups (News20) & DBPedia datasets, and natural language inference with Stanford Natural Language Inference (SNLI) dataset. We also demonstrate that a deep learning model can be trained with substantially less amount of labeled training data, when it has access to organized world knowledge in the form of a knowledge base. © 2018 The Association for Computational Linguistics.;ACL;2018;;Annervaz K.M., Chowdhury S.B.R., Dukkipati A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075751697&partnerID=40&md5=53881b9376f21b7c2dd77a987ac41ebb;India;augmented language models;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;accurate text-enhanced knowledge graph representation learning;"Classification (of information); Computational linguistics; Knowledge representation; Semantics; Text processing; Attention mechanisms; Classification tasks; Knowledge graphs; Learning methods; Learning techniques; State-of-the-art performance; Textual information; Textual representation; Learning systems";Previous representation learning techniques for knowledge graph representation usually represent the same entity or relation in different triples with the same representation, without considering the ambiguity of relations and entities. To appropriately handle the semantic variety of entities/relations in distinct triples, we propose an accurate text-enhanced knowledge graph representation learning method, which can represent a relation/entity with different representations in different triples by exploiting additional textual information. Specifically, our method enhances representations by exploiting the entity descriptions and triplespecific relation mention. And a mutual attention mechanism between relation mention and entity description is proposed to learn more accurate textual representations for further improving knowledge graph representation. Experimental results show that our method achieves the state-of-The-Art performance on both link prediction and triple classification tasks, and significantly outperforms previous text-enhanced knowledge representation models. © 2018 The Association for Computational Linguistics.;ACL;2018;;An B., Chen B., Han X., Sun L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065643962&partnerID=40&md5=cf0de02b4f0b09bf79a22ebb07737b95;China;knowledge graph embedding;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;generating fine-grained open vocabulary entity type descriptions;"Dynamic contexts; Dynamic memory; Entity-types; Fine grained; Knowledge graphs; Textual description; Computational linguistics";While large-scale knowledge graphs provide vast amounts of structured facts about entities, a short textual description can often be useful to succinctly characterize an entity and its type. Unfortunately, many knowledge graph entities lack such textual descriptions. In this paper, we introduce a dynamic memory-based network that generates a short open vocabulary description of an entity by jointly leveraging induced fact embeddings as well as the dynamic context of the generated sequence of words. We demonstrate the ability of our architecture to discern relevant information for more accurate generation of type description by pitting the system against several strong baselines. © 2018 Association for Computational Linguistics;ACL;2018;10.18653/v1/p18-1081;Bhowmik R., De Melo G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063099681&doi=10.18653%2fv1%2fp18-1081&partnerID=40&md5=15fca4c5111b0b729e1f41e051c865a6;United States;"data-to-text generation; augmented language models";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;entity-duet neural ranking: understanding the role of knowledge graph semantics in neural information retrieval;"Computational linguistics; Information retrieval; Distributed representation; End to end; Generalization ability; Knowledge graphs; Ranking model; Search system; Two-component; Semantics";This paper presents the Entity-Duet Neural Ranking Model (EDRM), which introduces knowledge graphs to neural search systems. EDRM represents queries and documents by their words and entity annotations. The semantics from knowledge graphs are integrated in the distributed representations of their entities, while the ranking is conducted by interaction-based neural ranking networks. The two components are learned end-to-end, making EDRM a natural combination of entity-oriented search and neural information retrieval. Our experiments on a commercial search log demonstrate the effectiveness of EDRM. Our analyses reveal that knowledge graph semantics significantly improve the generalization ability of neural ranking models. © 2018 Association for Computational Linguistics;ACL;2018;10.18653/v1/p18-1223;Liu Z., Xiong C., Sun M., Liu Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061193161&doi=10.18653%2fv1%2fp18-1223&partnerID=40&md5=7fd9ea97f0d33a051b0d7f2ed46380cc;China, United States;semantic search;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;complex sequential question answering: towards learning to converse over linked question answer pairs with a knowledge graph;"Artificial intelligence; Natural language processing systems; Knowledge graphs; Natural language questions; Question Answering; Question-answer pairs; Real world setting; Real-world scenario; Semi-automatics; State of the art; Query processing";While conversing with chatbots, humans typically tend to ask many questions, a significant portion of which can be answered by referring to large-scale knowledge graphs (KG). While Question Answering (QA) and dialog systems have been studied independently, there is a need to study them closely to evaluate such real-world scenarios faced by bots involving both these tasks. Towards this end, we introduce the task of Complex Sequential QA which combines the two tasks of (i) answering factual questions through complex inferencing over a realistic-sized KG of millions of entities, and (ii) learning to converse through a series of coherently linked QA pairs. Through a labor intensive semi-automatic process, involving in-house and crowdsourced workers, we created a dataset containing around 200K dialogs with a total of 1.6M turns. Further, unlike existing large scale QA datasets which contain simple questions that can be answered from a single tuple, the questions in our dialogs require a larger subgraph of the KG. Specifically, our dataset has questions which require logical, quantitative, and comparative reasoning as well as their combinations. This calls for models which can: (i) parse complex natural language questions, (ii) use conversation context to resolve coreferences and ellipsis in utterances, (iii) ask for clarifications for ambiguous queries, and finally (iv) retrieve relevant subgraphs of the KG to answer such questions. However, our experiments with a combination of state of the art dialog and QA models show that they clearly do not achieve the above objectives and are inadequate for dealing with such complex real world settings. We believe that this new dataset coupled with the limitations of existing models as reported in this paper should encourage further research in Complex Sequential QA. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;Scopus;2018;;Saha A., Pahuja V., Khapra M.M., Sankaranarayanan K., Chandar S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060473640&partnerID=40&md5=ef0c0573598eb4d1f0183fe2858540d6;Canada, India, United States;"question answering; conversational interfaces";validation research;"technique; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;variational reasoning for question answering with knowledge graph;"Artificial intelligence; Benchmarking; Learning algorithms; Natural language processing systems; Benchmark datasets; Knowledge graphs; Learning architectures; Logic reasoning; Question Answering; Question-answer pairs; State-of-the-art performance; Translation models; Deep learning";Knowledge graph (KG) is known to be helpful for the task of question answering (QA), since it provides well-structured relational information between entities, and allows one to further infer indirect facts. However, it is challenging to build QA systems which can learn to reason over knowledge graphs based on question-answer pairs alone. First, when people ask questions, their expressions are noisy (for example, typos in texts, or variations in pronunciations), which is non-trivial for the QA system to match those mentioned entities to the knowledge graph. Second, many questions require multi-hop logic reasoning over the knowledge graph to retrieve the answers. To address these challenges, we propose a novel and unified deep learning architecture, and an end-to-end variational learning algorithm which can handle noise in questions, and learn multi-hop reasoning simultaneously. Our method achieves state-of-the-art performance on a recent benchmark dataset in the literature. We also derive a series of new benchmark datasets, including questions for multi-hop reasoning, questions paraphrased by neural translation model, and questions in human voice. Our method yields very promising results on all these challenging datasets. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;Scopus;2018;;Zhang Y., Dai H., Kozareva Z., Smola A.J., Song L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060464851&partnerID=40&md5=e20549798b3f7ebbb7a6ede335984a21;Georgia, United States;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;knowledge-enriched two-layered attention network for sentiment analysis;"Computational linguistics; Sentiment analysis; Support vector regression; Benchmark datasets; External knowledge; Knowledge graphs; Model-based OPC; Multi-layer perceptron networks; Network-based; State-of-the-art system; Word net; Network layers";We propose a novel two-layered attention network based on Bidirectional Long Short-Term Memory for sentiment analysis. The novel two-layered attention network takes advantage of the external knowledge bases to improve the sentiment prediction. It uses the Knowledge Graph Embedding generated using the Word- Net. We build our model by combining the two-layered attention network with the supervised model based on Support Vector Regression using a Multilayer Perceptron network for sentiment analysis. We evaluate our model on the benchmark dataset of SemEval 2017 Task 5. Experimental results show that the proposed model surpasses the top system of SemEval 2017 Task 5. The model performs significantly better by improving the state-of-the-art system at SemEval 2017 Task 5 by 1.7 and 3.7 points for sub-tracks 1 and 2 respectively. © 2018 Association for Computational Linguistics.;ACL;2018;;Kumar A., Kawahara D., Kurohashi S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059660544&partnerID=40&md5=4ec5e2b4078d1f79d129334ef87dfc49;India, Japan;"augmented language models; text analysis";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;farewell freebase: migrating the simplequestions dataset to dbpedia;"Computational linguistics; Mapping; Natural language processing systems; Benchmark datasets; Dbpedia; Knowledge graphs; Lookups; Natural language questions; Non-trivial; Question Answering; Question answering systems; Real-world; Simple++; Knowledge graph";Question answering over knowledge graphs is an important problem of interest both commercially and academically. There is substantial interest in the class of natural language questions that can be answered via the lookup of a single fact, driven by the availability of the popular SIMPLEQUESTIONS dataset. The problem with this dataset, however, is that answer triples are provided from Freebase, which has been defunct for several years. As a result, it is difficult to build “real-world” question answering systems that are operationally deployable. Furthermore, a defunct knowledge graph means that much of the infrastructure for querying, browsing, and manipulating triples no longer exists. To address this problem, we present SIMPLEDBPEDIAQA, a new benchmark dataset for simple question answering over knowledge graphs that was created by mapping SIMPLEQUESTIONS entities and predicates from Freebase to DBpedia. Although this mapping is conceptually straightforward, there are a number of nuances that make the task non-trivial, owing to the different conceptual organizations of the two knowledge graphs. To lay the foundation for future research using this dataset, we leverage recent work to provide simple yet strong baselines with and without neural networks. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.;ACL;2018;;Azmy M., Shi P., Lin J., Ilyas I.F.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059516001&partnerID=40&md5=a0320632393ad98021bf13988601f5ff;Canada;"question answering; entity alignment";validation research;resource;;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;open-world knowledge graph completion;"Neural networks; Closed world assumption; Convolutional neural network; Embeddings; Filling in; Knowledge graphs; Large datasets; Link prediction; Web searches; Natural language processing systems";Knowledge Graphs (KGs) have been applied to many tasks including Web search, link prediction, recommendation, natural language processing, and entity linking. However, most KGs are far from complete and are growing at a rapid pace. To address these problems, Knowledge Graph Completion (KGC) has been proposed to improve KGs by filling in its missing connections. Unlike existing methods which hold a closed-world assumption, i.e., where KGs are fixed and new entities cannot be easily added, in the present work we relax this assumption and propose a new open-world KGC task. As a first attempt to solve this task we introduce an open-world KGC model called ConMask. This model learns embeddings of the entity's name and parts of its text-description to connect unseen entities to the KG. To mitigate the presence of noisy text descriptions, ConMask uses a relationship-dependent content masking to extract relevant snippets and then trains a fully convolutional neural network to fuse the extracted snippets with entities in the KG. Experiments on large data sets, both old and new, show that ConMask performs well in the open-world KGC task and even outperforms existing KGC models on the standard closed-world KGC task. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;Scopus;2018;;Shi B., Weninger T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056498188&partnerID=40&md5=63fcef4c8de3a789f08f50abbb4eca9e;United States;"knowledge graph embedding; entity classification; link prediction";validation research;tool;;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment;"Artificial intelligence; Large dataset; Semantics; Co-training; Cross-lingual; Knowledge graphs; Latent semantics; Semi-supervised; Structured knowledge; Wikipedia; Embeddings";Multilingual knowledge graph (KG) embeddings provide latent semantic representations of entities and structured knowledge with cross-lingual inferences, which benefit various knowledge-driven cross-lingual NLP tasks. However, precisely learning such cross-lingual inferences is usually hindered by the low coverage of entity alignment in many KGs. Since many multilingual KGs also provide literal descriptions of entities, in this paper, we introduce an embedding-based approach which leverages a weakly aligned multilingual KG for semi-supervised cross-lingual learning using entity descriptions. Our approach performs co-training of two embedding models, i.e. a multilingual KG embedding model and a multilingual literal description embedding model. The models are trained on a large Wikipedia-based trilingual dataset where most entity alignment is unknown to training. Experimental results show that the performance of the proposed approach on the entity alignment task improves at each iteration of co-training, and eventually reaches a stage at which it significantly surpasses previous approaches. We also show that our approach has promising abilities for zero-shot entity alignment, and cross-lingual KG completion. © 2018 International Joint Conferences on Artificial Intelligence. All right reserved.;Scopus;2018;10.24963/ijcai.2018/556;Chen M., Tian Y., Chang K.-W., Skiena S., Zaniolo C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055705769&doi=10.24963%2fijcai.2018%2f556&partnerID=40&md5=6842c775fa6e625c8cc0d86867b2dd74;United States;"entity alignment; knowledge graph embedding";validation research;technique;;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;commonsense knowledge aware conversation generation with graph attention;"Artificial intelligence; Encoding (symbols); Knowledge based systems; Natural language processing systems; Semantics; Attention mechanisms; Commonsense knowledge; Knowledge base; Knowledge graphs; Language understanding; NAtural language processing; Semantic information; State of the art; Graphic methods";Commonsense knowledge is vital to many natural language processing tasks. In this paper, we present a novel open-domain conversation generation model to demonstrate how large-scale commonsense knowledge can facilitate language understanding and generation. Given a user post, the model retrieves relevant knowledge graphs from a knowledge base and then encodes the graphs with a static graph attention mechanism, which augments the semantic information of the post and thus supports better understanding of the post. Then, during word generation, the model attentively reads the retrieved knowledge graphs and the knowledge triples within each graph to facilitate better generation through a dynamic graph attention mechanism. This is the first attempt that uses large-scale commonsense knowledge in conversation generation. Furthermore, unlike existing models that use knowledge triples (entities) separately and independently, our model treats each knowledge graph as a whole, which encodes more structured, connected semantic information in the graphs. Experiments show that the proposed model can generate more appropriate and informative responses than state-of-the-art baselines. © 2018 International Joint Conferences on Artificial Intelligence.All right reserved.;Scopus;2018;10.24963/ijcai.2018/643;Zhou H., Young T., Huang M., Zhao H., Xu J., Zhu X.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055701005&doi=10.24963%2fijcai.2018%2f643&partnerID=40&md5=30fb7d91d04da226c2891179047f5e29;China;"text generation; conversational interfaces";validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;joint entity and relation linking using earl;"Entity Linking; Question Answering; Relation Linking";In order to answer natural language questions over knowledge graphs, most processing pipelines involve entity and relation linking. Traditionally, entity linking and relation linking have been performed either as dependent sequential tasks or independent parallel tasks. In this demo paper, we present EARL, which performs entity linking and relation linking as a joint single task. The system determines the best semantic connection between all keywords of the question by referring to the knowledge graph. This is achieved by exploiting the connection density between entity candidates and relation candidates. EARL uses Bloom filters for faster retrieval of connection density and uses an extended label vocabulary for higher recall to improve the overall accuracy. © 2018 CEUR-WS. All rights reserved.;Scopus;2018;;Banerjee D., Dubey M., Chaudhuri D., Lehmann J.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055354595&partnerID=40&md5=41e9eb05d3899dd42ebb7be107c9fff4;Germany;"entity linking; relation linking; question answering";validation research;tool;;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;the whyis knowledge graph framework in action;"Computer software reusability; Learning algorithms; Learning systems; Pipelines; Semantics; Complex applications; Deductive reasoning; Health informatics; Knowledge curation; Multiple data sources; Predictive models; Research and development; Semantic-analytics; Natural language processing systems";We will demonstrate a reusable framework for developing knowledge graphs that supports general, open-ended development of knowledge curation, interaction, and inference. Knowledge graphs need to be easily maintainable and usable in sometimes complex application settings. Often, scaling knowledge graph updates can require developing a knowledge curation pipeline that either replaces the graph wholesale whenever updates are made, or requires detailed tracking of knowledge provenance across multiple data sources. Fig. 1 shows how Whyis provides a semantic analysis ecosystem: an environment that supports research and development of semantic analytics for which we previously had to build custom applications [3,4]. Users interact through a suite of knowledge graph views driven by the node type and view requested in the URL. Knowledge curation methods include Semantic ETL, external linked data mapping,and Natural Language Processing (NLP). Autonomous inference agents expand the available knowledge using traditional deductive reasoning as well as inductive methods that can include predictive models, statistical reasoners, and machine learning. Whyis is used in a number of areas today, including nanopolymers, spectrum policy, and health informatics. We demonstrate Whyis by creating and deploying an example Biological Knowledge Graph (BioKG), using data from DrugBank and Uniprot1, and briefly discuss benefits of using our approach over a conventional knowledge graph pipeline. © 2018 CEUR-WS. All rights reserved.;Scopus;2018;;McCusker J.P., Rashid S.M., Agu N., Bennett K.P., McGuinness D.L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055314766&partnerID=40&md5=78a6009ee8ea00dc13b4330c896629e2;United States;semantic search;solution proposal;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;research progress of knowledge graph based on knowledge base embedding;"Deep learning; Knowledge embedding; Knowledge graph; Knowledge representation";The knowledge Graph (KGs) is a valuable tool and useful resource to describe the entities and their relationships in various natural language processing tasks. Especially, the insufficient semantic of entities and relationship in text limited the efficiency and accuracy of knowledge representation. With the increasing of knowledge base resources, many scholars began to study the knowledge graph’s construction technology based on knowledge base embedding. The basic idea is that the knowledge graph will be treated as a recursive process. Through utilizing the knowledge base’s resources and the semantic representation of text characteristic, we can extend the new features that improve learning performance and knowledge graph completeness. In this paper, we give a general overview of knowledge graph’s construction research based on knowledge embedding, including knowledge representation, knowledge embedding and so on. Then we summarize the challenge for the knowledge graph and the future development trend. © Springer Nature Singapore Pte Ltd. 2018.;Scopus;2018;10.1007/978-981-13-2206-8_16;Caifang T., Yuan R., Hualei Y., Jiamin C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053994602&doi=10.1007%2f978-981-13-2206-8_16&partnerID=40&md5=1c589bd6a56e3e0d4e907314836d064f;China;knowledge graph embedding;secondary research;guidelines;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;towards building a knowledge graph with open data - a roadmap;"Knowledge graph; Open data";With the increasing interest in knowledge graph over the years, several approaches have been proposed for building knowledge graphs. Most of the recent approaches involve using semi-structured sources such as Wikipedia or information crawled from the web using a combination of extraction methods and Natural Language Processing (NLP) techniques. In most cases, these approaches tend to make a compromise between accuracy and completeness. In our ongoing work, we examine a technique for building a knowledge graph over the increasing volume of open data published on the web. The rationale for this is two-fold. First, we intend to provide a foundation for making existing open datasets searchable through keywords similar to how information is sought on the web. The second reason is to generate logically consistent facts from usually inaccurate and inconsistent open datasets. Our approach to knowledge graph development will compute the confidence score of every relationship elicited from underpinning open data in the knowledge graph. Our method will also provide a scheme for extending coverage of a knowledge graph by predicting new relationships that are not in the knowledge graph. In our opinion, our work has major implications for truly opening up access to the hitherto untapped value in open datasets not directly accessible on the World Wide Web today. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.;Scopus;2018;10.1007/978-3-319-98827-6_13;Musa Aliyu F., Ojo A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052830661&doi=10.1007%2f978-3-319-98827-6_13&partnerID=40&md5=9f314ffdeeab53f27006d8c39358af5c;Ireland, Niger, Nigeria;"entity extraction; relation extraction";solution proposal;method;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;relation linking for wikidata using bag of distribution representation;"Knowledge graph; NLP; Relation linking";Knowledge graphs (KGs) are essential repositories of structured and semi-structured knowledge which benefit various NLP applications. To utilize the knowledge in KGs to help machines to better understand plain texts, one needs to bridge the gap between knowledge and texts. In this paper, a Relation Linking System for Wikidata (RLSW) is proposed to link the relations in KGs to plain texts. The proposed system uses the knowledge in Wikidata as seeds and clusters relation mentions in text with a novel phrase similarity algorithm. To enhance the system’s ability of handling unseen expressions and make use of the location information of words to reduce false positive rate, a bag of distribution pattern modeling method is proposed. Experimental results show that the proposed approach improves traditional methods, including word based pattern and syntax feature enriched system such as OLLIE. © 2018, Springer International Publishing AG.;Scopus;2018;10.1007/978-3-319-73618-1_55;Yang X., Ren S., Li Y., Shen K., Li Z., Wang G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041237683&doi=10.1007%2f978-3-319-73618-1_55&partnerID=40&md5=ae21a3a73a0a85eab250dd087fa09bc7;China;relation linking;validation research;method;;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;capturing knowledge in semantically-typed relational patterns to enhance relation linking;"Knowledge Capture; Knowledge Graphs; Question Answering Systems; Relation Linking";Transforming natural language questions into formal queries is an integral task in Question Answering (QA) systems. QA systems built on knowledge graphs like DBpedia, require a step after natural language processing for linking words, specifically including named entities and relations, to their corresponding entities in a knowledge graph. To achieve this task, several approaches rely on background knowledge bases containing semantically-typed relations, e.g., PATTY, for an extra disambiguation step. Two major factors may affect the performance of relation linking approaches whenever background knowledge bases are accessed: A) limited availability of such semantic knowledge sources, and b) lack of a systematic approach on how to maximize the benefits of the collected knowledge. We tackle this problem and devise SIBKB, a semantic-based index able to capture knowledge encoded on background knowledge bases like PATTY. SIBKB represents a background knowledge base as a bi-partite and a dynamic index over the relation patterns included in the knowledge base. Moreover, we develop a relation linking component able to exploit SIBKB features. The benefits of SIBKB are empirically studied on existing QA benchmarks and observed results suggest that SIBKB is able to enhance the accuracy of relation linking by up to three times. © 2017 Copyright held by the owner/author(s).;ACM;2017;10.1145/3148011.3148031;Singh K., Mulang I.O., Lytra I., Jaradeh M.Y., Sakor A., Vidal M.-E., Lange C., Auer S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040631730&doi=10.1145%2f3148011.3148031&partnerID=40&md5=02b470de9f8d8ee03358cef89641997f;Germany;relation linking;validation research;technique;;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;cross-modal knowledge transfer: improving the word embedding of apple by looking at oranges;"Knowledge Transfer; Multi-Modality; Word Similarity";"Capturing knowledge via learned latent vector representations of words, images and knowledge graph (KG) entities has shown state of-the-art performance in computer vision, computational linguistics and KG tasks. Recent results demonstrate that the learning of such representations across modalities can be beneficial, since each modality captures complementary information. However, those approaches are limited to concepts with cross-modal alignments in the training data which are only available for just a few concepts. Especially for visual objects exist far fewer embeddings than for words or KG entities. We investigate whether a word embedding (e.g., for ""apple"") can still capture information from other modalities even if there is no matching concept within the other modalities (i.e., no images or KG entities of apples but of oranges as pictured in the title analogy). The empirical results of our knowledge transfer approach demonstrate that word embeddings do benefit from extrapolating information across modalities even for concepts that are not represented in the other modalities. Interestingly, this applies most to concrete concepts (e.g., dragonfly) while abstract concepts (e.g., animal) benefit most if aligned concepts are available in the other modalities. © 2017 Copyright held by the owner/author(s).";ACM;2017;10.1145/3148011.3148026;Both F., Thoma S., Rettinger A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040602084&doi=10.1145%2f3148011.3148026&partnerID=40&md5=824cabcd87f1f2c599a636242b7ee82f;Germany;augmented language models;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;triple prediction from texts by using distributed representations of words;"Distributed representations of words; Knowledge extraction; Knowledge graph completion";"Knowledge graphs have been shown to be useful to many tasks in artificial intelligence. Triples of knowledge graphs are traditionally structured by human editors or extracted from semi-structured information; however, editing is expensive, and semi-structured information is not common. On the other hand, most such information is stored as text. Hence, it is necessary to develop a method that can extract knowledge from texts and then construct or populate a knowledge graph; this has been attempted in various ways. Currently, there are two approaches to constructing a knowledge graph. One is open information extraction (Open IE), and the other is knowledge graph embedding; however, neither is without problems. Stanford Open IE, the current best such system, requires labeled sentences as training data, and knowledge graph embedding systems require numerous triples. Recently, distributed representations of words have become a hot topic in the field of natural language processing, since this approach does not require labeled data for training. These require only plain text, but Mikolov showed that it can perform well with the word analogy task, answering questions such as, “a is to b as c is to ?.” This can be considered as a knowledge extraction task from a text for finding the missing entity of a triple. However, the accuracy is not sufficiently high when applied in a straightforward manner to relations in knowledge graphs, since the method uses only one triple as a positive example. In this paper, we analyze why distributed representations perform such tasks well; we also propose a new method for extracting knowledge from texts that requires much less annotated data. Experiments show that the proposed method achieves considerable improvement compared with the baseline; in particular, the improvement in HITS@10 was more than doubled for some relations. Copyright © 2017 The Institute of Electronics, Information and Communication Engineers.";Scopus;2017;10.1587/transinf.2017edp7112;Ebisu T., Ichise R.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038370232&doi=10.1587%2ftransinf.2017EDP7112&partnerID=40&md5=abde520637a26b4a98203e0abf597760;Japan;"entity extraction; relation extraction";validation research;technique;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge qestions from knowledge graphs;"Information retrieval; Natural language processing systems; Document collection; Historical data; Knowledge graphs; Logistic regression classifier; Multiple choice questions; Natural language questions; Structured queries; Template based methods; Query processing";We address the problem of automatically generating quiz-style knowledge questions from a knowledge graph such as DBpedia. Qestions of this kind have ample applications, for instance, to educate users about or to evaluate their knowledge in a specific domain. To solve the problem, we propose a novel end-to-end approach. The approach first selects a named entity from the knowledge graph as an answer. It then generates a structured triple-pattern query, which yields the answer as its sole result. If a multiple-choice question is desired, the approach selects alternative answer options as distractors. Finally, our approach uses a template-based method to verbalize the structured query and yield a natural language question. A key challenge is estimating how dificult the generated question is to human users. To do this, we make use of historical data from the Jeopardy! quiz show and a semantically annotated Web-scale document collection, engineer suitable features, and train a logistic regression classifier to predict question diffliculty. Experiments demonstrate the viability of our overall approach. © 2017 Copyright held by the owner/author(s).;Scopus;2017;10.1145/3121050.3121073;Seyler D., Yahya M., Berberich K.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033238128&doi=10.1145%2f3121050.3121073&partnerID=40&md5=aa1629dd0304b8502db08c1f7b38984d;Germany, United Kingdom, United States;"question generation; question answering";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;the arabic knowledge graph: opportunities and challenges;"Arabic Knowledge Graph; Challenges; Linked Data; Opportunities; Semantic Web";Semantic Web has brought forth the idea of computing with knowledge, hence, attributing the ability of thinking to machines. Knowledge Graphs represent a major advancement in the construction of the Web of Data where machines are context-aware when answering users' queries. The English Knowledge Graph was a milestone realized by Google in 2012. Even though it is a useful source of information for English users and applications, it does not offer much for the Arabic users and applications. In this paper, we investigated the different challenges and opportunities prone to the life-cycle of the construction of the Arabic Knowledge Graph (AKG) while following some best practices and techniques. Additionally, this work suggests some potential solutions to these challenges. The proprietary factor of data creates a major problem in the way of harvesting this latter. Moreover, when the Arabic data is openly available, it is generally in an unstructured form which requires further processing. The complexity of the Arabic language itself creates a further problem for any automatic or semi-automatic extraction processes. Therefore, the usage of NLP techniques is a feasible solution. Some preliminary results are presented later in this paper. The AKG has very promising outcomes for the Semantic Web in general and the Arabic community in particular. The goal of the Arabic Knowledge Graph is mainly the integration of the different isolated datasets available on the Web. Later, it can be used in both the academic (by providing a large dataset for many different research fields and enhance discovery) and commercial sectors (by improving search engines, providing metadata, interlinking businesses). © 2017 IEEE.;IEEE;2017;10.1109/icsc.2017.22;Ktob A., Li Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018265429&doi=10.1109%2fICSC.2017.22&partnerID=40&md5=b8b2e9a682a79659a37287eafb138c56;China;"entity extraction; relation extraction; ontology construction";solution proposal;"method; guidelines";;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;sparsity and noise: where knowledge graph embeddings fall short;"Errors; Natural language processing systems; Benchmark datasets; Embedding technique; Empirical experiments; Knowledge graphs; Low-dimensional representation; Relationships between entities; Embeddings";Knowledge graph (KG) embedding techniques use structured relationships between entities to learn low-dimensional representations of entities and relations. One prominent goal of these approaches is to improve the quality of knowledge graphs by removing errors and adding missing facts. Surprisingly, most embedding techniques have been evaluated on benchmark datasets consisting of dense and reliable subsets of human-curated KGs, which tend to be fairly complete and have few errors. In this paper, we consider the problem of applying embedding techniques to KGs extracted from text, which are often incomplete and contain errors. We compare the sparsity and unreliability of different KGs and perform empirical experiments demonstrating how embedding approaches degrade as sparsity and unreliability increase. © 2017 Association for Computational Linguistics.;ACL;2017;10.18653/v1/d17-1184;Pujara J., Augustine E., Getoor L.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055864552&doi=10.18653%2fv1%2fd17-1184&partnerID=40&md5=8e874f5aa0770ba757d26eabcb18ed5a;United States;knowledge graph embedding;validation research;guidelines;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;towards lexical chains for knowledge-graph-based word embeddings;"Chains; Deep learning; Graphic methods; Linguistics; Data sparseness; Embeddings; Knowledge graphs; Lexical Chain; Linguistic values; Natural language text; Wikipedia; Word vectors; Natural language processing systems";Word vectors with varying dimensionalities and produced by different algorithms have been extensively used in NLP. The corpora that the algorithms are trained on can contain either natural language text (e.g. Wikipedia or newswire articles) or artificially-generated pseudo corpora due to natural data sparseness. We exploit Lexical Chain based templates over Knowledge Graph for generating pseudo-corpora with controlled linguistic value. These corpora are then used for learning word embeddings. A number of experiments have been conducted over the following test sets: WordSim353 Similarity, WordSim353 Relatedness and SimLex-999. Lhe results show that, on the one hand, the incorporation of many-relation lexical chains improves results, but on the other hand, unrestricted-length chains remain difficult to handle with respect to their huge quantity. © 2018 Association for Computational Linguistics (ACL). All rights reserved.;ACL;2017;10.26615/978-954-452-049-6-087;Simov K., Boytcheva S., Osenova P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045766451&doi=10.26615%2f978-954-452-049-6-087&partnerID=40&md5=b184f7213d9a24aeb09144fb1a85109e;Bulgaria;"augmented language models; text generation";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings;"Linguistics; Semantics; Speech processing; Dialogue systems; Human dialogues; Human evaluation; Human like; Knowledge graphs; Neural modeling; Rule-based models; Structured knowledge; Computational linguistics";We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models. © 2017 Association for Computational Linguistics.;ACL;2017;10.18653/v1/p17-1162;He H., Balakrishnan A., Eric M., Liang P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040931116&doi=10.18653%2fv1%2fP17-1162&partnerID=40&md5=c6484eddfd9dbadea164ad122779386a;United States;"conversational interfaces; knowledge graph embedding";validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;learning multi-faceted knowledge graph embeddings for natural language processing;"Artificial intelligence; Embeddings; Learning algorithms; Knowledge graphs; NAtural language processing; Related works; Relational properties; Wide spectrum; Natural language processing systems";Knowledge graphs have challenged the existing embedding-based approaches for representing their multifacetedness. To address some of the issues, we have investigated some novel approaches that (i) capture the multilingual transitions on different language-specific versions of knowledge, and (ii) encode the commonly existing monolingual knowledge with important relational properties and hierarchies. In addition, we propose the use of our approaches in a wide spectrum of NLP tasks that have not been well explored by related works.;Scopus;2017;10.24963/ijcai.2017/744;Chen M., Zaniolo C.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031917956&doi=10.24963%2fijcai.2017%2f744&partnerID=40&md5=cd70b8e5cef2d02a4147a63a3b55d373;United States;knowledge graph embedding;solution proposal;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;generating natural language question-answer pairs from a knowledge graph using a rnn based question generation model;"Computational linguistics; Knowledge representation; Automatically generated; Downstream applications; Factoid questions; Natural language questions; Question-answer pairs; Sequence modeling; State of the art; Template based methods; Natural language processing systems";In recent years, knowledge graphs such as Freebase that capture facts about entities and relationships between them have been used actively for answering factoid questions. In this paper, we explore the problem of automatically generating question answer pairs from a given knowledge graph. The generated question answer (QA) pairs can be used in several downstream applications. For example, they could be used for training better QA systems. To generate such QA pairs, we first extract a set of keywords from entities and relationships expressed in a triple stored in the knowledge graph. From each such set, we use a subset of keywords to generate a natural language question that has a unique answer. We treat this subset of keywords as a sequence and propose a sequence to sequence model using RNN to generate a natural language question from it. Our RNN based model generates QA pairs with an accuracy of 33.61 percent and performs 110.47 percent (relative) better than a state-of-the-art template based method for generating natural language question from keywords. We also do an extrinsic evaluation by using the generated QA pairs to train a QA system and observe that the F1-score of the QA system improves by 5.5 percent (relative) when using automatically generated QA pairs in addition to manually generated QA pairs available for training. © 2017 Association for Computational Linguistics.;ACL;2017;10.18653/v1/e17-1036;Indurthi S., Raghu D., Khapra M.M., Joshi S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021669255&doi=10.18653%2fv1%2fe17-1036&partnerID=40&md5=a0c5d4c9b14990e04e1684a304c25941;India;"question answering; question generation";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;srdf: a novel lexical knowledge graph for whole sentence knowledge extraction;"Lexical knowledge graph; Natural language processing; Open information extraction; Question answering; Semantic web";In this paper, we present a novel lexical knowledge graph called SRDF and describe an extraction system that automatically generates a SRDF graph from the Korean natural language sentence. In the semantic web, knowledge is expressed in the RDF triple form but natural language sentences consist of multiple relationships between the predicates and arguments. For this reason, we design a SRDF graph structure that combines open information extraction method with reification for the whole sentence knowledge extraction. In addition, to add semantics to a SRDF graph, we establish a link between the lexical argument and entity in ontological knowledge base using the Entity Linking system. The proposed knowledge graph is adaptable for many existing semantic web applications. We present the results of an experimental evaluation and demonstrate the use of SRDF graph in developing a Korean SPARQL template generation module in the OKBQA platform. © Springer International Publishing AG 2017.;Scopus;2017;10.1007/978-3-319-59888-8_27;Nam S., Choi G., Choi K.-S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021190357&doi=10.1007%2f978-3-319-59888-8_27&partnerID=40&md5=b162408a3c1e1bb9776d38379aa78248;South Korea;"entity extraction; relation extraction; entity linking";solution proposal;"resource; tool";;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;frame-based ontology population with pikes;"FrameBase; natural language processing; Ontology population; semantic role labeling; Semantic Web";We present an approach for ontology population from natural language English texts that extracts RDF triples according to FrameBase, a Semantic Web ontology derived from FrameNet. Processing is decoupled in two independently-tunable phases. First, text is processed by several NLP tasks, including Semantic Role Labeling (SRL), whose results are integrated in an RDF graph of mentions, i.e., snippets of text denoting some entity/fact. Then, the mention graph is processed with SPARQL-like rules using a specifically created mapping resource from NomBank/PropBank/FrameNet annotations to FrameBase concepts, producing a knowledge graph whose content is linked to DBpedia and organized around semantic frames, i.e., prototypical descriptions of events and situations. A single RDF/OWL representation is used where each triple is related to the mentions/tools it comes from. We implemented the approach in PIKES, an open source tool that combines two complementary SRL systems and provides a working online demo. We evaluated PIKES on a manually annotated gold standard, assessing precision/recall in (i) populating FrameBase ontology, and (ii) extracting semantic frames modeled after standard predicate models, for comparison with state-of-the-art tools for the Semantic Web. We also evaluated (iii) sampled precision and execution times on a large corpus of 110 K Wikipedia-like pages. © 2016 IEEE.;IEEE;2016;10.1109/tkde.2016.2602206;Corcoglioniti F., Rospocher M., Aprosio A.P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996478366&doi=10.1109%2fTKDE.2016.2602206&partnerID=40&md5=7c4327818df442d9c25eb0795b3e669d;Italy;"entity extraction; relation extraction; ontology construction";validation research;tool;;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;learning better word embedding by asymmetric low-rank projection of knowledge graph;"knowledge graph; natural language processing; neural network; word embedding";"Word embedding, which refers to low-dimensional dense vector representations of natural words, has demon-strated its power in many natural language processing tasks. However, it may suffer from the inaccurate and incomplete information contained in the free text corpus as training data. To tackle this challenge, there have been quite a few studies that leverage knowledge graphs as an additional information source to improve the quality of word embedding. Although these studies have achieved certain success, they have neglected some important facts about knowledge graphs: 1) many relationships in knowledge graphs are many-to-one, one-to-many or even many-to-many, rather than simply one-to-one; 2) most head entities and tail entities in knowledge graphs come from very different semantic spaces. To address these issues, in this paper, we propose a new algorithm named ProjectNet. ProjectNet models the relationships between head and tail entities after transforming them with different low-rank projection matrices. The low-rank projection can allow non one-to-one relationships between entities, while different projection matrices for head and tail entities allow them to originate in different semantic spaces. The experimental results demonstrate that ProjectNet yields more accurate word embedding than previous studies, and thus leads to clear improvements in various natural language processing tasks. © 2016, Springer Science+Business Media New York.";Scopus;2016;10.1007/s11390-016-1651-5;Tian F., Gao B., Chen E.-H., Liu T.-Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969920163&doi=10.1007%2fs11390-016-1651-5&partnerID=40&md5=0ca88e505f792fd1149ac1e3712af344;China;"knowledge graph embedding; text analysis; natural language inference";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a 2-phase frame-based knowledge extraction framework;"Frame detection; Knowledge extraction; Natural language processing; Rdf knowledge graph; Sparql rules";"We present an approach for extracting knowledge from natural language English texts where processing is decoupled in two phases. The first phase comprises several standard NLP tasks whose results are integrated in a single RDF graph of mentions. The second phase processes the mention graph with SPARQL-like mapping rules to produce a knowledge graph organized around semantic frames (i.e., prototypical descriptions of events and situations). The decoupling allows: (i) choosing different tools for the NLP tasks without affecting the remaining computation; (ii) combining the outputs of different NLP tasks in non-trivial ways, leveraging their integrated and coherent representation in a mention graph; and (iii) relating each piece of extracted knowledge to the mention(s) it comes from, leveraging the single RDF representation. We evaluate precision and recall of our approach on a gold standard, showing its competitiveness w.r.t. the state of the art. We also evaluate execution times and (sampled) accuracy on a corpus of 110K Wikipedia pages, showing the applicability of the approach on large corpora. © 2016 ACM.";ACM;2016;10.1145/2851613.2851845;Corcoglioniti F., Rospocher M., Aprosio A.P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975887050&doi=10.1145%2f2851613.2851845&partnerID=40&md5=74d8dfb749aaf69ee62ee10c021762eb;Italy;"entity extraction; relation extraction; entity linking";validation research;tool;;1;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;relation schema induction using tensor factorization with side information;"Automation; Factorization; Tensors; Automatic identification; Knowledge graphs; Medical research; Real-world datasets; Side information; State of the art; Tensor factorization; Natural language processing systems";Given a set of documents from a specific domain (e.g., medical research journals), how do we automatically build a Knowledge Graph (KG) for that domain? Automatic identification of relations and their schemas, i.e., type signature of arguments of relations (e.g., undergo(Patient, Surgery)), is an important first step towards this goal. We refer to this problem as Relation Schema Induction (RSI). In this paper, we propose Schema Induction using Coupled Tensor Factorization (SICTF), a novel tensor factorization method for relation schema induction. SICTF factorizes Open Information Extraction (OpenIE) triples extracted from a domain corpus along with additional side information in a principled way to induce relation schemas. To the best of our knowledge, this is the first application of tensor factorization for the RSI problem. Through extensive experiments on multiple real-world datasets, we find that SICTF is not only more accurate than state-of-the-art baselines, but also significantly faster (about 14x faster). © 2016 Association for Computational Linguistics;ACL;2016;10.18653/v1/d16-1040;Nimishakavi M., Saini U.S., Talukdar P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072831168&doi=10.18653%2fv1%2fd16-1040&partnerID=40&md5=278dcee15ccc743912d48979442e98e4;India;ontology construction;validation research;method;;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;constraint-based question answering with knowledge graph;"Computational linguistics; Benchmark data; Constraint-based; Knowledge base; Knowledge based; Knowledge graphs; Multi-constraints; Question Answering; State-of-the-art methods; Knowledge based systems";WebQuestions and SimpleQuestions are two benchmark data-sets commonly used in recent knowledge-based question answering (KBQA) work. Most questions in them are 'simple' questions which can be answered based on a single relation in the knowledge base. Such data-sets lack the capability of evaluating KBQA systems on complicated questions. Motivated by this issue, we release a new data-set, namely ComplexQuestions1 aiming to measure the quality of KBQA systems on 'multi-constraint' questions which require multiple knowledge base relations to get the answer. Beside, we propose a novel systematic KBQA approach to solve multi-constraint questions. Compared to state-of-the-art methods, our approach not only obtains comparable results on the two existing benchmark data-sets, but also achieves significant improvements on the ComplexQuestions. © 1963-2018 ACL.;ACL;2016;;Bao J., Duan N., Yan Z., Zhou M., Zhao T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034261067&partnerID=40&md5=869fde72520a8d3d7450bf206dfd5fd2;China;question answering;validation research;"technique; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;the role of the wordnet relations in the knowledge-basedword sense disambiguation task;"Knowledge based systems; Natural language processing systems; Semantics; Knowledge based; Knowledge graphs; Semantic relations; Test sets; Word Sense Disambiguation; Wordnet; Ontology";In this paper we present an analysis of different semantic relations extracted from WordNet, Extended WordNet and Sem-Cor, with respect to their role in the task of knowledge-based word sense disambiguation. The experiments use the same algorithm and the same test sets, but different variants of the knowledge graph. The results show that different sets of relations have different impact on the results: positive or negative. The beneficial ones are discussed with respect to the combination of relations and with respect to the test set. The inclusion of inference has only a modest impact on accuracy, while the addition of syntactic relations produces stable improvement over the baselines.;Scopus;2016;;Simov K., Popov A., Osenova P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962860263&partnerID=40&md5=3ab548c97fe84345aa1605171213d5dc;Bulgaria;text analysis;validation research;guidelines;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;how to build templates for rdf question/answering - an uncertain graph similarity join approach;"Computational linguistics; Benchmark datasets; Effectiveness and efficiencies; Knowledge graphs; Natural language questions; Natural languages; Pruning techniques; Template generation; Unstructured natural language; Natural language processing systems";"A challenging task in the natural language question answering (Q/A for short) over RDF knowledge graph is how to bridge the gap between unstructured natural language questions (NLQ) and graph-structured RDF data (G). One of the effective tools is the ""template"", which is often used in many existing RDF Q/A systems. However, few of them study how to generate templates automatically. To the best of our knowledge, we are the first to propose a join approach for template generation. Given a workload D of SPARQL queries and a set N of natural language questions, the goal is to find some pairs 〈q, n〉, for q ∈ D∧ n ∈ N, where SPARQL query q is the best match for natural language question n. These pairs provide promising hints for automatic template generation. Due to the ambiguity of the natural languages, we model the problem above as an uncertain graph join task. We propose several structural and probability pruning techniques to speed up joining. Extensive experiments over real RDF Q/A benchmark datasets confirm both the effectiveness and efficiency of our approach. Copyright © 2015 ACM.";Scopus;2015;10.1145/2723372.2747648;Zheng W., Zou L., Lian X., Yu J.X., Song S., Zhao D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957575023&doi=10.1145%2f2723372.2747648&partnerID=40&md5=d6b0b8cd083030b7def968255e60b954;China, Hong Kong, United States;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;semantics-based graph approach to complex question-answering;"Computational linguistics; Natural language processing systems; Semantics; Architectural approach; Complex questions; Coreference; Cross validation; Knowledge graphs; Named entities; Proof of concept; Question Answering; Semantic roles; Syntactic dependencies; Knowledge graph";This paper suggests an architectural approach of representing knowledge graph for complex question-answering. There are four kinds of entity relations added to our knowledge graph: syntactic dependencies, semantic role labels, named entities, and coreference links, which can be effectively applied to answer complex questions. As a proof of concept, we demonstrate how our knowledge graph can be used to solve complex questions such as arithmetics. Our experiment shows a promising result on solving arithmetic questions, achieving the 3-folds cross-validation score of 71.75%. © NAACL-HLT 2015 - 2015 Student Research Workshop (SRW) at the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings. All rights reserved.;ACL;2015;;Jurczyk T., Choi J.D.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093129374&partnerID=40&md5=2400b8f1db2850418960e6b8dee57d5f;United States;question answering;solution proposal;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;sematch: semantic entity search from knowledge graph;"Entity search; Knowledge graph; Query expansion; Semantic search; Semantic similarity";As an increasing amount of the knowledge graph is published as Linked Open Data, semantic entity search is required to develop new applications. However, the use of structured query languages such as SPARQL is challenging for non-skilled users who need to master the query language as well as acquiring knowledge of the underlying ontology of Linked Data knowledge bases. In this article, we propose the Sematch framework for entity search in the knowledge graph that combines natural language query processing, entity linking, entity type linking and semantic similarity based query expansion. The system has been validated in a dataset and a prototype has been developed that translates natural language queries into SPARQL.;Scopus;2015;;Zhu G., Iglesias C.A.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964417432&partnerID=40&md5=272af308b0b35a7d840f7fd7aa67a194;Spain;semantic search;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1
Conference Paper;an entity-centric approach for overcoming knowledge graph sparsity;"Automatic construction; Best effort; Centric expansion; Knowledge graphs; Real-world; Recent researches; Unstructured texts; Natural language processing systems";Automatic construction of knowledge graphs (KGs) from unstructured text has received considerable attention in recent research, resulting in the construction of several KGs with millions of entities (nodes) and facts (edges) among them. Unfortunately, such KGs tend to be severely sparse in terms of number of facts known for a given entity, i.e., have low knowledge density. For example, the NELL KG consists of only 1.34 facts per entity. Unfortunately, such low knowledge density makes it challenging to use such KGs in real-world applications. In contrast to best-effort extraction paradigms followed in the construction of such KGs, in this paper we argue in favor of ENTIty Centric Expansion (ENTICE), an entity-centric KG population framework, to alleviate the low knowledge density problem in existing KGs. By using ENTICE, we are able to increase NELL's knowledge density by a factor of 7.7 at 75.5% accuracy. Additionally, we are also able to extend the ontology discovering new relations and entities. © 2015 Association for Computational Linguistics.;ACL;2015;10.18653/v1/d15-1061;Hegde M., Talukdar P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959894844&doi=10.18653%2fv1%2fd15-1061&partnerID=40&md5=293b887d578030d6f73fb6d89bcf3814;India;"entity extraction; relation extraction; entity classification";validation research;tool;;1;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;sanaphor: ontology-based coreference resolution;"Arts computing; Knowledge representation; Natural language processing systems; Ontology; Co-reference resolutions; Inverted indices; Knowledge graphs; Semantic annotations; Semantic relatedness; Semantic-Web techniques; Splitting and merging; State-of-the-art techniques; Semantic Web";"We tackle the problem of resolving coreferences in textual content by leveraging Semantic Web techniques. Specifically, we focus on noun phrases that coreference identifiable entities that appear in the text; the challenge in this context is to improve the coreference resolution by leveraging potential semantic annotations that can be added to the identified mentions. Our system, SANAPHOR, first applies state-of-the-art techniques to extract entities, noun phrases, and candidate coreferences. Then, we propose an approach to type noun phrases using an inverted index built on top of a Knowledge Graph (e.g., DBpedia). Finally, we use the semantic relatedness of the introduced types to improve the stateof- the-art techniques by splitting and merging coreference clusters. We evaluate SANAPHOR on CoNLL datasets, and show how our techniques consistently improve the state of the art in coreference resolution. © Springer International Publishing Switzerland 2015.";Scopus;2015;10.1007/978-3-319-25007-6_27;Prokofyev R., Tonon A., Luggen M., Vouilloz L., Difallah D.E., Cudré-Mauroux P.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952333039&doi=10.1007%2f978-3-319-25007-6_27&partnerID=40&md5=9dd9e49e2c2b9a33b1f09c507b62260c;Switzerland;text analysis;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1
Conference Paper;entity translation with collective inference in knowledge graph;"Collective learning; Knowledge base; Machine translation";"Nowadays knowledge base (KB) has been viewed as one of the important infrastructures for many web search applications and NLP tasks. However, in practice the availability of KB data varies from language to language, which greatly limits potential usage of knowledge base. In this paper, we propose a novel method to construct or enrich a knowledge base by entity translation with help of another KB but compiled in a different language. In our work, we concentrate on two key tasks: 1) collecting translation candidates with as good coverage as possible from various sources such as web or lexicon; 2) building an effective disambiguation algorithm based on collective inference approach over knowledge graph to find correct translation for entities in the source knowledge base. We conduct experiments on movie domain of our inhouse knowledge base from English to Chinese, and the results show the proposed method can achieve very high translation precision compared with classical translation methods, and significantly increase the volume of Chinese knowledge base in this domain. © Springer International Publishing Switzerland 2015.";Scopus;2015;10.1007/978-3-319-25207-0_5;Li Q., Liu S., Lin R., Li M., Zhou M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951275676&doi=10.1007%2f978-3-319-25207-0_5&partnerID=40&md5=5981a3d872977177e02b88848fe0a77c;China;"entity alignment; machine translation";validation research;method;entertainment media;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;matrix factorization with knowledge graph propagation for unsupervised spoken language understanding;"Computational linguistics; Factorization; Matrix algebra; Ontology; Semantics; Speech processing; Corpus annotations; Domain specificity; Matrix factorizations; Pre-defined semantics; Propagation modeling; Semantic structures; Spoken dialogue system; Spoken language understanding; Natural language processing systems";Spoken dialogue systems (SDS) typically require a predefined semantic ontology to train a spoken language understanding (SLU) module. In addition to the annotation cost, a key challenge for designing such an ontology is to define a coherent slot set while considering their complex relations. This paper introduces a novel matrix factorization (MF) approach to learn latent feature vectors for utterances and semantic elements without the need of corpus annotations. Specifically, our model learns the semantic slots for a domain-specific SDS in an unsupervised fashion, and carries out semantic parsing using latent MF techniques. To further consider the global semantic structure, such as inter-word and inter-slot relations, we augment the latent MF-based model with a knowledge graph propagation model based on a slot-based semantic graph and a word-based lexical graph. Our experiments show that the proposed MF approaches produce better SLU models that are able to predict semantic slots and word patterns taking into account their relations and domain-specificity in a joint manner. © 2015 Association for Computational Linguistics.;ACL;2015;10.3115/v1/p15-1047;Chen Y.-N., Wang W.Y., Gershman A., Rudnicky A.I.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943809524&doi=10.3115%2fv1%2fp15-1047&partnerID=40&md5=ced451fd4d69f3a5fae48f44dd33ac73;United States;semantic parsing;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;learning to explain entity relationships in knowledge graphs;"Computational linguistics; Baseline models; Entity-relationship; Human-readable; Knowledge graphs; Learning to rank; State of the art; Natural language processing systems";We study the problem of explaining relationships between pairs of knowledge graph entities with human-readable descriptions. Our method extracts and enriches sentences that refer to an entity pair from a corpus and ranks the sentences according to how well they describe the relationship between the entities. We model this task as a learning to rank problem for sentences and employ a rich set of features. When evaluated on a large set of manually annotated sentences, we find that our method significantly improves over state-of-The-Art baseline models. © 2015 Association for Computational Linguistics.;ACL;2015;10.3115/v1/p15-1055;Voskarides N., Meij E., Tsagkias M., De Rijke M., Weerkamp W.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943740328&doi=10.3115%2fv1%2fp15-1055&partnerID=40&md5=8c07724f26c915d18f4f8a42a4218f51;United Kingdom, Netherlands;semantic search;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;rc-net: a general framework for incorporating knowledge into word representations;"Deep learning; Distributed word representations; Knowledge graph";Representing words into vectors in continuous space can form up a potentially powerful basis to generate high-quality textual features for many text mining and natural language processing tasks. Some recent efforts, such as the skip-gram model, have attempted to learn word representations that can capture both syntactic and semantic information among text corpus. However, they still lack the capability of encoding the properties of words and the complex relationships among words very well, since text itself often contains incomplete and ambiguous information. Fortunately, knowledge graphs provide a golden mine for enhancing the quality of learned word representations. In particular, a knowledge graph, usually composed by entities (words, phrases, etc.), relations between entities, and some corresponding meta information, can supply invaluable relational knowledge that encodes the relationship between entities as well as categorical knowledge that encodes the attributes or properties of entities. Hence, in this paper, we introduce a novel framework called RC-NET to leverage both the relational and categorical knowledge to produce word representations of higher quality. Specifically, we build the relational knowledge and the categorical knowledge into two separate reg-ularization functions, and combine both of them with the original objective function of the skip-gram model. By solving this combined optimization problem using back propagation neural networks, we can obtain word representations enhanced by the knowledge graph. Experiments on popular text mining and natural language processing tasks, including analogical reasoning, word similarity, and topic prediction, have all demonstrated that our model can significantly improve the quality of word representations. Copyright 2014 ACM.;ACM;2014;10.1145/2661829.2662038;Xu C., Bai Y., Bian J., Gao B., Wang G., Liu X., Liu T.-Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937567033&doi=10.1145%2f2661829.2662038&partnerID=40&md5=b6fdb47bf7af72dfb02f96491b291832;China;"natural language inference; text classification";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;ontology-based translation of natural language queries to sparql;"Data storage equipment; Digital storage; Knowledge representation; Natural language processing systems; Query processing; Architectural approach; Back-ground knowledge; Effective approaches; Knowledge graphs; Natural language queries; Natural languages; Ontology-based; Query efficiency; Big data";We present an implemented approach to transform natur al language sentences into SPARQL. using background knowledge from ontologies and lexicons. Therefore, eli gible technologies and data storage possibilities are ana lyzed and evaluated. The contributions of this paper are twofold. Firstly, we describe the motivation and current needs for a natural language access to industry data. We describe several scenarios where the proposed solution is required. Resulting in an architectural approach based on automatic SPARQL query construction for efTective natural language queries. Secondly. we analyze the perf ormance of RDBMS, RDF and Triple Stores for the knowledge representation. The proposed approach will be evaluated on the basis of a query catalog by means of query efficiency, accuracy. and data storage perform ance. The results show, that natural language access to industry data using ontologies and lexicons, is a simp le but effective approach to improve the diagnosis proc ess and the data search for a broad range of users. Furt hermore. virtual RDF graphs do support the DB-driven knowledge graph representation process. but do not perf orm efficient under industry conditions in terms of perf orinance and scalability. Copyright © 2014, Association for the Advancement of Artificial Intelligence.;Scopus;2014;;Sander M., Waltinger U., Roshchin M., Runkler T.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987648006&partnerID=40&md5=b1132f2375f92b2c6dd085930ba8309a;Germany;machine translation;evaluation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;the wisdom of minority: unsupervised slot filling validation based on multi-dimensional truth-finding;"Computational linguistics; Information sources; Knowledge graphs; Linguistic analysis; Multi dimensional; Multi-source system; Multiple source; Multiple systems; Supervised methods; Linguistics";Information Extraction using multiple information sources and systems is beneficial due to multisource/ system consolidation and challenging due to the resulting inconsistency and redundancy. We integrate IE and truth-finding research and present a novel unsupervised multi-dimensional truth finding framework which incorporates signals from multiple sources, multiple systems and multiple pieces of evidence by knowledge graph construction through multi-layer deep linguistic analysis. Experiments on the case study of Slot Filling Validation demonstrate that our approach can find truths accurately (9.4% higher F-score than supervised methods) and efficiently (finding 90% truths with only one half the cost of a baseline without credibility estimation).;ACL;2014;;Yu D., Huang H., Cassidy T., Ji H., Wang C., Zhi S., Han J., Voss C., Magdon-Ismail M.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959925878&partnerID=40&md5=90f28cb8be63c97f482b727a68d32de7;United States;text analysis;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge graph and text jointly embedding;"Linguistics; Natural language processing systems; Vector spaces; Analogical reasoning; Embedding method; Embedding process; Knowledge graphs; Large scale experiments; Text corpora; Wikipedia; Embeddings";We examine the embedding approach to reason new relational facts from a largescale knowledge graph and a text corpus. We propose a novel method of jointly embedding entities and words into the same continuous vector space. The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus. Entity names and Wikipedia anchors are utilized to align the embeddings of entities and words in the same space. Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts, compared to separately embedding knowledge graphs and text. Particularly, jointly embedding enables the prediction of facts containing entities out of the knowledge graph, which cannot be handled by previous embedding methods. At the same time, concerning the quality of the word embeddings, experiments on the analogical reasoning task show that jointly embedding is comparable to or slightly better than word2vec (Skip-Gram). © 2014 Association for Computational Linguistics.;ACL;2014;10.3115/v1/d14-1167;Wang Z., Zhang J., Feng J., Chen Z.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926065966&doi=10.3115%2fv1%2fd14-1167&partnerID=40&md5=eb21d9b18f85533cd6ff04cbef47a079;China, United States;"entity classification; link prediction";validation research;technique;;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;tailor knowledge graph for query understanding: linking intent topics by propagation;"Graphic methods; Natural language processing systems; Global knowledge; Knowledge graphs; Local contexts; Query logs; Query representations; Unsupervised algorithms; Information retrieval";Knowledge graphs are recently used for enriching query representations in an entity-aware way for the rich facts organized around entities in it. However, few of the methods pay attention to non-entity words and clicked websites in queries, which also help conveying user intent. In this paper, we tackle the problem of intent understanding with innovatively representing entity words, refiners and clicked urls as intent topics in a unified knowledge graph based framework, in a way to exploit and expand knowledge graph which we call 'tailor'. We collaboratively exploit global knowledge in knowledge graphs and local contexts in query log to initialize intent representation, then propagate the enriched features in a graph consisting of intent topics using an unsupervised algorithm. The experiments prove intent topics with knowledge graph enriched features significantly enhance intent understanding. © 2014 Association for Computational Linguistics.;ACL;2014;10.3115/v1/d14-1114;Zhao S., Zhang Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925987420&doi=10.3115%2fv1%2fd14-1114&partnerID=40&md5=ca0b878ae63563f4b2c9f55f55cea827;China;semantic search;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;building sentiment lexicons for all major languages;"Sentiment analysis; Component language; Cultural difference; Knowledge graphs; Language pairs; Linguistic resources; Scarce resources; Sentiment lexicons; Wikipedia articles; Computational linguistics";Sentiment analysis in a multilingual world remains a challenging problem, because developing language-specific sentiment lexicons is an extremely resourceintensive process. Such lexicons remain a scarce resource for most languages. In this paper, we address this lexicon gap by building high-quality sentiment lexicons for 136 major languages. We integrate a variety of linguistic resources to produce an immense knowledge graph. By appropriately propagating from seed words, we construct sentiment lexicons for each component language of our graph. Our lexicons have a polarity agreement of 95.7% with published lexicons, while achieving an overall coverage of 45.2%. We demonstrate the performance of our lexicons in an extrinsic analysis of 2,000 distinct historical figures' Wikipedia articles on 30 languages. Despite cultural difference and the intended neutrality of Wikipedia articles, our lexicons show an average sentiment correlation of 0.28 across all language pairs. © 2014 Association for Computational Linguistics.;ACL;2014;10.3115/v1/p14-2063;Chen Y., Skiena S.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906927782&doi=10.3115%2fv1%2fp14-2063&partnerID=40&md5=21feca95c076bbfb9e61213e4383cbf7;United States;text analysis;validation research;resource;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;gem-based entity-knowledge maintenance;"Emerging entities; Knowledge acceleration; Knowledge maintenance; Long-tail entities; Novelty; Relatedness";Knowledge bases about entities have become a vital asset for Web search, recommendations, and analytics. Examples are Freebase being the core of the Google Knowledge Graph and the use of Wikipedia for distant supervision in numerous IR and NLP tasks. However, maintaining the knowledge about not so prominent entities in the long tail is often a bottleneck as human contributors face the tedious task of continuously identifying and reading relevant sources. To overcome this limitation and accelerate the maintenance of knowledge bases, we propose an approach that automatically extracts, from the Web, key contents for given input entities. Our method, called GEM, generates salient contents about a given entity, using minimal assumptions about the underlying sources, while meeting the constraint that the user is willing to read only a certain amount of information. Salient content pieces have variable length and are computed using a budget-constrained optimization problem which decides upon which sub-pieces of an input text should be selected for the final result. GEM can be applied to a variety of knowledge-gathering settings including news streams and speech input from videos. Our experimental studies show the viability of the approach, and demonstrate improvements over various baselines, in terms of precision and recall. Copyright 2013 ACM.;ACM;2013;10.1145/2505515.2505715;Taneva B., Weikum G.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889592632&doi=10.1145%2f2505515.2505715&partnerID=40&md5=3c39903eabd16c6071f97c98070a1426;Germany;semantic search;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;cross-lingual link discovery between chinese and english wiki knowledge bases;"Computational linguistics; Anchor strengths; Chinese documents; Critical issues; Hybrid approach; Knowledge basis; Knowledge graphs; Link Discovery; Topic relevance; Data mining";Wikipedia is an online multilingual encyclopedia that contains a very large number of articles covering most written languages. However, one critical issue for Wikipedia is that the pages in different languages are rarely linked except for the cross-lingual link between pages about the same subject. This could pose serious difficulties to humans and machines who try to seek information from different lingual sources. In order to address above issue, we propose a hybrid approach that exploits anchor strength, topic relevance and entity knowledge graph to automatically discovery cross-lingual links. In addition, we develop CELD, a system for automatically linking key terms in Chinese documents with English Concepts. As demonstrated in the experiment evaluation, the proposed model outperforms several baselines on the NTCIR data set, which has been designed especially for the cross-lingual link discovery evaluation. © 2013 Qingliang Miao, Huayu Lu, Shu Zhang, and Yao Meng.;ACL;2013;;Miao Q., Lu H., Zhang S., Meng Y.;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922783862&partnerID=40&md5=f6f8378f947a26f10f4ad4f6f598c9ba;China;entity alignment;validation research;method;;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;cokebert: contextual knowledge selection and embedding towards enhanced pre-trained language models;Pre-trained language model, Knowledge graph, Entity typing, Relation classification;Several recent efforts have been devoted to enhancing pre-trained language models (PLMs) by utilizing extra heterogeneous knowledge in knowledge graphs (KGs), and achieved consistent improvements on various knowledge-driven NLP tasks. However, most of these knowledge-enhanced PLMs embed static sub-graphs of KGs (“knowledge context”), regardless of that the knowledge required by PLMs may change dynamically according to specific text (“textual context”). In this paper, we propose a novel framework named Coke to dynamically select contextual knowledge and embed knowledge context according to textual context for PLMs, which can avoid the effect of redundant and ambiguous knowledge in KGs that cannot match the input text. Our experimental results show that Coke outperforms various baselines on typical knowledge-driven NLP tasks, indicating the effectiveness of utilizing dynamic knowledge context for language understanding. Besides the performance improvements, the dynamically selected knowledge in Coke can describe the semantics of text-related knowledge in a more interpretable form than the conventional PLMs. Our implementation and datasets are publicly available.;ScienceDirect;2021;10.1016/j.aiopen.2021.06.004;Yusheng Su and Xu Han and Zhengyan Zhang and Yankai Lin and Peng Li and Zhiyuan Liu and Jie Zhou and Maosong Sun;https://www.sciencedirect.com/science/article/pii/S2666651021000188;China;augmented language models;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;a knowledge graph based speech interface for question answering systems;Spoken question answering, Knowledge graphs, Automatic speech recognition, Spoken language understanding, Spoken interface, Linked data;Speech interfaces to conversational systems have been a focus in academia and industry for over a decade due to its applicability as a natural interface. Speech recognition and speech synthesis constitute the important input and output modules respectively for such spoken interface systems. In this paper, the speech recognition interface for question answering applications is reviewed, and existing limitations are discussed. The existing spoken question answering (QA) systems use an automatic speech recogniser by adapting acoustic and language models for the speech interface and off-the-shelf language processing systems for question interpretation. In the process, the impact of recognition errors and language processing inaccuracies is neglected. It is illustrated in the paper how a semantically rich knowledge graph can be used to solve automatic speech recognition and language processing specific problems. A simple concatenation of a speech recogniser and a natural language processing system is a shallow method for a speech interface. An effort beyond merely concatenating these two units is required to develop a successful spoken question answering system. It is illustrated in this paper how a knowledge graph based structured data can be used to build a unified system combining speech recognition and language understanding. This facilitates the use of a semantically rich data model for speech interface.;ScienceDirect;2017;10.1016/j.specom.2017.05.001;Ashwini {Jaya Kumar} and Christoph Schmidt and Joachim Köhler;https://www.sciencedirect.com/science/article/pii/S0167639316301443;Germany;question answering;solution proposal;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;a review: knowledge reasoning over knowledge graph;Knowledge graph, Reasoning, Rule-based reasoning, Distributed representation-based reasoning, Neural network-based reasoning;Mining valuable hidden knowledge from large-scale data relies on the support of reasoning technology. Knowledge graphs, as a new type of knowledge representation, have gained much attention in natural language processing. Knowledge graphs can effectively organize and represent knowledge so that it can be efficiently utilized in advanced applications. Recently, reasoning over knowledge graphs has become a hot research topic, since it can obtain new knowledge and conclusions from existing data. Herein we review the basic concept and definitions of knowledge reasoning and the methods for reasoning over knowledge graphs. Specifically, we dissect the reasoning methods into three categories: rule-based reasoning, distributed representation-based reasoning and neural network-based reasoning. We also review the related applications of knowledge graph reasoning, such as knowledge graph completion, question answering, and recommender systems. Finally, we discuss the remaining challenges and research opportunities for knowledge graph reasoning.;ScienceDirect;2020;10.1016/j.eswa.2019.112948;Xiaojun Chen and Shengbin Jia and Yang Xiang;https://www.sciencedirect.com/science/article/pii/S0957417419306669;China;"knowledge graph embedding; question answering; link prediction; entity classification";secondary research;guidelines;;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;knowledge-driven joint posterior revision of named entity classification and linking;;In this work we address the problem of extracting quality entity knowledge from natural language text, an important task for the automatic construction of knowledge graphs from unstructured content. More in details, we investigate the benefit of performing a joint posterior revision, driven by ontological background knowledge, of the annotations resulting from natural language processing (NLP) entity analyses such as named entity recognition and classification (NERC) and entity linking (EL). The revision is performed via a probabilistic model, called jpark, that given the candidate annotations independently identified by NERC and EL tools on the same textual entity mention, reconsiders the best annotation choice performed by the tools in light of the coherence of the candidate annotations with the ontological knowledge. The model can be explicitly instructed to handle the information that an entity can potentially be NIL (i.e., lacking a corresponding referent in the target linking knowledge base), exploiting it for predicting the best NERC and EL annotation combination. We present a comprehensive evaluation of jpark along various dimensions, comparing its performances with and without exploiting NIL information, as well as the usage of three different background knowledge resources (YAGO, DBpedia, and Wikidata) to build the model. The evaluation, conducted using different tools (the popular Stanford NER and DBpedia Spotlight, as well as the more recent Flair NER and End-to-End Neural EL) with three reference datasets (AIDA, MEANTIME, and TAC-KBP), empirically confirms the capability of the model to improve the quality of the annotations of the given tools, and thus their performances on the tasks they are designed for.;ScienceDirect;2020;10.1016/j.websem.2020.100617;Marco Rospocher and Francesco Corcoglioniti;https://www.sciencedirect.com/science/article/pii/S1570826820300500;Italy;"error detection; entity linking; entity classification";validation research;technique;;0;0;0;1;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Journal Article;knowledge based deep inception model for web page classification;"Web page classification; transfer learning; knowledge graph embedding; pre-trained model";Web Page Classification is decisive for information retrieval and management task and plays an imperative role for natural language processing (NLP) problems in web engineering. Traditional machine learning algorithms excerpt covet features from web pages whereas deep leaning algorithms crave features as the network goes deeper. Pre-trained models such as BERT attains remarkable achievement for text classification and continue to show state-of-the-art results. Knowledge Graphs can provide rich structured factual information for better language modelling and representation. In this study, we proposed an ensemble Knowledge Based Deep Inception (KBDI) approach for web page classification by learning bidirectional contextual representation using pre-trained BERT incorporating Knowledge Graph embeddings and fine-tune the target task by applying Deep Inception network utilizing parallel multi-scale semantics. Proposed ensemble evaluates the efficacy of fusing domain specific knowledge embeddings with the pre-trained BERT model. Experimental interpretation exhibit that the proposed BERT fused KBDI model outperforms benchmark baselines and achieve better performance in contrast to other conventional approaches evaluated on web page classification datasets.;WoS;2021;10.13052/jwe1540-9589.2075;Gupta A,Bhatia R;http://dx.doi.org/10.13052/jwe1540-9589.2075;India;"text classification; knowledge graph embedding";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge extraction and applications utilizing context data in knowledge graphs;;Context is widely considered for NLP and knowledge discovery since it highly influences the exact meaning of natural language. The scientific challenge is not only to extract such context data, but also to store this data for further NLP approaches. Here, we propose a multiple step knowledge graph-based approach to utilize context data for NLP and knowledge expression and extraction. We introduce the graph-theoretic foundation for a general context concept within semantic networks and show a proof-of-concept-based on biomedical literature and text mining. We discuss the impact of this novel approach on text analysis, various forms of text recognition and knowledge extraction and retrieval.;WoS;2019;10.15439/2019f3;Doerpinghaus J,Stefan A;http://dx.doi.org/10.15439/2019F3;Germany;semantic search;solution proposal;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;framework for question-answering in sanskrit through automated construction of knowledge graphs;;Sanskrit (samskrta) enjoys one of the largest and most varied literature in the whole world. Extracting the knowledge from it, however, is a challenging task due to multiple reasons including complexity of the language and paucity of standard natural language processing tools. In this paper, we target the problem of building knowledge graphs for particular types of relationships from samskrta texts. We build a natural language question-answering system in samskrta that uses the knowledge graph to answer factoid questions. We design a framework for the overall system and implement two separate instances of the system on human relationships from mahabharata and ramayana, and one instance on synonymous relationships from bhavaprakasa nighantu, a technical text from ayurveda. We show that about 50% of the factoid questions can be answered correctly by the system. More importantly, we analyse the shortcomings of the system in detail for each step, and discuss the possible ways forward.;ACL;2019;;Terdalkar H,Bhattacharya A;https://aclanthology.org/W19-7508.pdf;India;question answering;solution proposal;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;jointly embedding entities and text with distant supervision;;Learning representations for knowledge base entities and concepts is becoming increasingly important for NLP applications. However, recent entity embedding methods have relied on structured resources that are expensive to create for new domains and corpora. We present a distantly-supervised method for jointly learning embeddings of entities and text from an unnanotated corpus, using only a list of mappings between entities and surface forms. We learn embeddings from open-domain and biomedical corpora, and compare against prior methods that rely on human-annotated text or large knowledge graph structure. Our embeddings capture entity similarity and relatedness better than prior work, both in existing biomedical datasets and a new Wikipedia-based dataset that we release to the community. Results on analogy completion and entity sense disambiguation indicate that entities and words capture complementary information that can be effectively combined for downstream use.;ACL;2018;;Newman-Griffis D,Lai AM,Fosler-Lussier E;https://aclanthology.org/W18-3026.pdf;United States;knowledge graph embedding;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;conceptnet 55: an open multilingual graph of general knowledge;;Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this with state-of-the-art results on intrinsic evaluations of word relatedness that translate into improvements on applications of word vectors, including solving SAT-style analogies.;WoS;2017;;Speer R,Chin J,Havasi C;https://arxiv.org/pdf/1612.03975.pdf;United States;semantic search;validation research;resource;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;an overview of relevant literature on different approaches to word sense disambiguation;"Word Sense Disambiguation;Natural Language Processing;Lesk Algorithms;Embedding Techniques;Neural Network;Bi-LSTM;Knowledge Graph";WSD (Word Sense Disambiguation) is a common issue in Natural Language Processing (NLP) and Machine Learning technology. In NLP, word sense disambiguation is described as the capacity to detect which meaning of a word is activated by its use in a specific context. WSD is a solution to the uncertainty that occurs when words have different meanings in different contexts. Contextual word meaning plays an important role in various applications such as sentiment analysis, search engine, information extraction, machine translation etc. It is a challenge for these systems to detect and overcome the uncertainty that emerges from the lexical ambiguity. Many studies have been conducted over the decades to propose various approaches to the WSD problem. In this manuscript, a comparative study of three approaches namely LESK algorithm, embedding techniques, and Neural Network techniques based on the text collected from children's story books is performed. We explored an approach that combines Bi-LSTM neural network with Knowledge Graph to predict contextual word meaning. Our study shows that the combined approach accuracy is 80.34approaches;IEEE;2021;10.1109/icecct52121.2021.9616677;"P. C. P; S. Mandal";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616677;India;text analysis;secondary research;guidelines;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;conversational recommender system based on gru-attention neural network;"Knowledge graph;Conversational recommender system Deep learning;Neural network";In recent years, the conversational recommender system (CRS) based on natural language processing technology has gained widespread attention, aiming to learn and model user preferences through interactive dialogue. Although existing research has improved the accuracy of the dialogue recommendation system to a certain extent, there are still some shortcomings that make it easy to generate more general and popular responses. This paper proposes a deep learning framework with GRU and attention mechanism on the basis of knowledge graph, namely KGGA. Through the serialized modeling of conversation content and effectively capture the user’s interest to make correct recommendations. Experiments conducted on widely baselines show that the proposed framework is superior to the state-of-the-art methods.;IEEE;2021;10.1109/icdsca53499.2021.9650212;"X. Wang; J. Wang; J. Liu";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650212;China;conversational interfaces;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;joint entity and relation extraction method based on knowledge representation attention;"relation extraction;knowledge representation;joint extraction;knowledge graph";Relation extraction is a fundamental task in natural language processing and is a key step in information extraction tasks and construction of large-scale knowledge graphs, etc. Knowledge graph ontology information is useful for guiding triplet construction, but existing methods do not make full use of relevant information such as relation. Therefore, this paper proposes a joint extraction method of subject-aware entity relation combined with knowledge relation representation. The relation information of knowledge graph is extracted using TransE. Firstly, the subject entity information is extracted based on the text representation, the subject entity information and the relation representation are computed with attention to enhance the connection between the subject and the relation, and the subject information combined with the relation information is used as input to extract the triplets corresponding to the current subject. Compared with the baseline model, the method achieves an increase in F1 value on the Baidu DuIE test set. The experimental results show some improvement in the accuracy and recall of the triplets, and the attention based on relation representation enhances the dependencies between entity pairs and relations. The effectiveness of relation representation modeling is verified.;IEEE;2021;10.1109/iscipt53667.2021.00160;"D. Gu; Y. Wang; B. Song";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644527;China;"entity extraction; relation extraction";validation research;technique;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;representation learning of remote sensing knowledge graph for zero-shot remote sensing image scene classification;"Deep alignment network (DAN);remote sensing knowledge graph (RSKG);remote sensing image scene classification;zero-shot learning (ZSL)";Although deep learning has revolutionized remote sensing image scene classification, current deep learning-based approaches highly depend on the massive supervision of the predetermined scene categories and have disappointingly poor performance on new categories which go beyond the predetermined scene categories. In reality, the classification task often has to be extended along with the emergence of new applications that inevitably involve new categories of remote sensing image scenes, so how to make the deep learning model own the inference ability to recognize the remote sensing image scenes from unseen categories becomes incredibly important. By fully exploiting the remote sensing domain characteristic, this paper proposes a novel remote sensing knowledge graph-guided deep alignment network to address zero-shot remote sensing image scene classification. To improve the semantic representation ability of remote sensing-oriented scene categories, this paper, for the first time, tries to generate the semantic representations of remote sensing scene categories by representation learning of remote sensing knowledge graph (SR-RSKG). In addition, this paper proposes a novel deep alignment network with a series of constraints (DAN) to conduct robust cross-modal alignment between visual features and semantic representations. Extensive experiments on one merged remote sensing image scene dataset, which is the integration of multiple publicly open remote sensing image scene datasets, show that the presented SR-RSKG obviously outperforms the existing semantic representation methods (e.g., the natural language processing models and manually annotated attribute vectors), and our proposed DAN shows better performance compared with the state-of- the-art methods under different kinds of semantic representations.;IEEE;2021;10.1109/igarss47720.2021.9553667;"Y. Li; D. Kong; Y. Zhang; R. Chen; J. Chen";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553667;China;augmented language models;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;contextualized knowledge-aware attentive neural network: enhancing answer selection with knowledge;knowledge graph, Answer selection, attention mechanism, graph convolutional network;Answer selection, which is involved in many natural language processing applications, such as dialog systems and question answering (QA), is an important yet challenging task in practice, since conventional methods typically suffer from the issues of ignoring diverse real-world background knowledge. In this article, we extensively investigate approaches to enhancing the answer selection model with external knowledge from knowledge graph (KG). First, we present a context-knowledge interaction learning framework, Knowledge-aware Neural Network, which learns the QA sentence representations by considering a tight interaction with the external knowledge from KG and the textual information. Then, we develop two kinds of knowledge-aware attention mechanism to summarize both the context-based and knowledge-based interactions between questions and answers. To handle the diversity and complexity of KG information, we further propose a Contextualized Knowledge-aware Attentive Neural Network, which improves the knowledge representation learning with structure information via a customized Graph Convolutional Network and comprehensively learns context-based and knowledge-based sentence representation via the multi-view knowledge-aware attention mechanism. We evaluate our method on four widely used benchmark QA datasets, including WikiQA, TREC QA, InsuranceQA, and Yahoo QA. Results verify the benefits of incorporating external knowledge from KG and show the robust superiority and extensive applicability of our method.;ACM;2021;10.1145/3457533;Deng, Yang and Xie, Yuexiang and Li, Yaliang and Yang, Min and Lam, Wai and Shen, Ying;https://doi.org/10.1145/3457533;China, United States;question answering;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;hierarchical concept-driven language model;Language modeling, hierarchical language modeling, representation learning, interpretation, recurrent conceptualization-enhanced gamma belief network, concept semantic information, text generation;"For guiding natural language generation, many semantic-driven methods have been proposed. While clearly improving the performance of the end-to-end training task, these existing semantic-driven methods still have clear limitations: for example, (i) they only utilize shallow semantic signals (e.g., from topic models) with only a single stochastic hidden layer in their data generation process, which suffer easily from noise (especially adapted for short-text etc.) and lack of interpretation; (ii) they ignore the sentence order and document context, as they treat each document as a bag of sentences, and fail to capture the long-distance dependencies and global semantic meaning of a document. To overcome these problems, we propose a novel semantic-driven language modeling framework, which is a method to learn a Hierarchical Language Model and a Recurrent Conceptualization-enhanced Gamma Belief Network, simultaneously. For scalable inference, we develop the auto-encoding Variational Recurrent Inference, allowing efficient end-to-end training and simultaneously capturing global semantics from a text corpus. Especially, this article introduces concept information derived from high-quality lexical knowledge graph Probase, which leverages strong interpretability and anti-nose capability for the proposed model. Moreover, the proposed model captures not only intra-sentence word dependencies, but also temporal transitions between sentences and inter-sentence concept dependence. Experiments conducted on several NLP tasks validate the superiority of the proposed approach, which could effectively infer meaningful hierarchical concept structure of document and hierarchical multi-scale structures of sequences, even compared with latest state-of-the-art Transformer-based models.";ACM;2021;10.1145/3451167;Wang, Yashen and Zhang, Huanhuan and Liu, Zhirun and Zhou, Qiang;https://doi.org/10.1145/3451167;China;"augmented language models; text generation";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;mg-bert: multi-graph augmented bert for masked language modeling;;Pre-trained models like Bidirectional Encoder Representations from Transformers (BERT), have recently made a big leap forward in Natural Language Processing (NLP) tasks. However, there are still some shortcomings in the Masked Language Modeling (MLM) task performed by these models. In this paper, we first introduce a multi-graph including different types of relations between words. Then, we propose Multi-Graph augmented BERT (MG-BERT) model that is based on BERT. MG-BERT embeds tokens while taking advantage of a static multi-graph containing global word co-occurrences in the text corpus beside global real-world facts about words in knowledge graphs. The proposed model also employs a dynamic sentence graph to capture local context effectively. Experimental results demonstrate that our model can considerably enhance the performance in the MLM task.;ACL;2021;10.18653/v1/2021.textgraphs-1.12;"BehnamGhader, Parishad and
 Zakerinia, Hossein and
 Soleymani Baghshah, Mahdieh";https://aclanthology.org/2021.textgraphs-1.12;Iran;augmented language models;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;kepler: a unified model for knowledge embedding and pre-trained language representation;;Abstract Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M1 , a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.;ACL;2021;10.1162/tacl_a_00360;"Wang, Xiaozhi and
 Gao, Tianyu and
 Zhu, Zhaocheng and
 Zhang, Zhengyan and
 Liu, Zhiyuan and
 Li, Juanzi and
 Tang, Jian";https://aclanthology.org/2021.tacl-1.11;Canada, China, United States;"knowledge graph embedding; augmented language models";validation research;"technique; resource";;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowgraph@iitk at semeval-2021 task 11: building knowledge graph for nlp research;;Research in Natural Language Processing is making rapid advances, resulting in the publication of a large number of research papers. Finding relevant research papers and their contribution to the domain is a challenging problem. In this paper, we address this challenge via the SemEval 2021 Task 11: NLPContributionGraph, by developing a system for a research paper contributions-focused knowledge graph over Natural Language Processing literature. The task is divided into three sub-tasks: extracting contribution sentences that show important contributions in the research article, extracting phrases from the contribution sentences, and predicting the information units in the research article together with triplet formation from the phrases. The proposed system is agnostic to the subject domain and can be applied for building a knowledge graph for any area. We found that transformer-based language models can significantly improve existing techniques and utilized the SciBERT-based model. Our first sub-task uses Bidirectional LSTM (BiLSTM) stacked on top of SciBERT model layers, while the second sub-task uses Conditional Random Field (CRF) on top of SciBERT with BiLSTM. The third sub-task uses a combined SciBERT based neural approach with heuristics for information unit prediction and triplet formation from the phrases. Our system achieved F1 score of 0.38, 0.63 and 0.76 in end-to-end pipeline testing, phrase extraction testing and triplet extraction testing respectively.;ACL;2021;10.18653/v1/2021.semeval-1.57;"Shailabh, Shashank and
 Chaurasia, Sajal and
 Modi, Ashutosh";https://aclanthology.org/2021.semeval-1.57;India;"entity extraction; relation extraction; triple classification";validation research;method;scholarly domain;1;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;ynu-hpcc at semeval-2021 task 11: using a bert model to extract contributions from nlp scholarly articles;;"This paper describes the system we built as the YNU-HPCC team in the SemEval-2021 Task 11: NLPContributionGraph. This task involves first identifying sentences in the given natural language processing (NLP) scholarly articles that reflect research contributions through binary classification; then identifying the core scientific terms and their relation phrases from these contribution sentences by sequence labeling; and finally, these scientific terms and relation phrases are categorized, identified, and organized into subject-predicate-object triples to form a knowledge graph with the help of multiclass classification and multi-label classification. We developed a system for this task using a pre-trained language representation model called BERT that stands for Bidirectional Encoder Representations from Transformers, and achieved good results. The average F1-score for Evaluation Phase 2, Part 1 was 0.4562 and ranked 7th, and the average F1-score for Evaluation Phase 2, Part 2 was 0.6541, and also ranked 7th.";ACL;2021;10.18653/v1/2021.semeval-1.58;"Ma, Xinge and
 Wang, Jin and
 Zhang, Xuejie";https://aclanthology.org/2021.semeval-1.58;China;"entity extraction; relation extraction; triple classification";validation research;method;scholarly domain;1;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;learning numeracy: a simple yet effective number embedding approach using knowledge graph;;Numeracy plays a key role in natural language understanding. However, existing NLP approaches, not only traditional word2vec approach or contextualized transformer-based language models, fail to learn numeracy. As the result, the performance of these models is limited when they are applied to number-intensive applications in clinical and financial domains. In this work, we propose a simple number embedding approach based on knowledge graph. We construct a knowledge graph consisting of number entities and magnitude relations. Knowledge graph embedding method is then applied to obtain number vectors. Our approach is easy to implement, and experiment results on various numeracy-related NLP tasks demonstrate the effectiveness and efficiency of our method.;ACL;2021;10.18653/v1/2021.findings-emnlp.221;"Duan, Hanyu and
 Yang, Yi and
 Tam, Kar Yan";https://aclanthology.org/2021.findings-emnlp.221;Hong Kong;knowledge graph embedding;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;lexicon-based graph convolutional network for chinese word segmentation;;Precise information of word boundary can alleviate the problem of lexical ambiguity to improve the performance of natural language processing (NLP) tasks. Thus, Chinese word segmentation (CWS) is a fundamental task in NLP. Due to the development of pre-trained language models (PLM), pre-trained knowledge can help neural methods solve the main problems of the CWS in significant measure. Existing methods have already achieved high performance on several benchmarks (e.g., Bakeoff-2005). However, recent outstanding studies are limited by the small-scale annotated corpus. To further improve the performance of CWS methods based on fine-tuning the PLMs, we propose a novel neural framework, LBGCN, which incorporates a lexicon-based graph convolutional network into the Transformer encoder. Experimental results on five benchmarks and four cross-domain datasets show the lexicon-based graph convolutional network successfully captures the information of candidate words and helps to improve performance on the benchmarks (Bakeoff-2005 and CTB6) and the cross-domain datasets (SIGHAN-2010). Further experiments and analyses demonstrate that our proposed framework effectively models the lexicon to enhance the ability of basic neural frameworks and strengthens the robustness in the cross-domain scenario.;ACL;2021;10.18653/v1/2021.findings-emnlp.248;"Huang, Kaiyu and
 Yu, Hao and
 Liu, Junpeng and
 Liu, Wei and
 Cao, Jingxiang and
 Huang, Degen";https://aclanthology.org/2021.findings-emnlp.248;China;augmented language models;validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;parameter-efficient domain knowledge integration from multiple sources for biomedical pre-trained language models;;Domain-specific pre-trained language models (PLMs) have achieved great success over various downstream tasks in different domains. However, existing domain-specific PLMs mostly rely on self-supervised learning over large amounts of domain text, without explicitly integrating domain-specific knowledge, which can be essential in many domains. Moreover, in knowledge-sensitive areas such as the biomedical domain, knowledge is stored in multiple sources and formats, and existing biomedical PLMs either neglect them or utilize them in a limited manner. In this work, we introduce an architecture to integrate domain knowledge from diverse sources into PLMs in a parameter-efficient way. More specifically, we propose to encode domain knowledge via \textit{adapters}, which are small bottleneck feed-forward networks inserted between intermediate transformer layers in PLMs. These knowledge adapters are pre-trained for individual domain knowledge sources and integrated via an attention-based knowledge controller to enrich PLMs. Taking the biomedical domain as a case study, we explore three knowledge-specific adapters for PLMs based on the UMLS Metathesaurus graph, the Wikipedia articles for diseases, and the semantic grouping information for biomedical concepts. Extensive experiments on different biomedical NLP tasks and datasets demonstrate the benefits of the proposed architecture and the knowledge-specific adapters across multiple PLMs.;ACL;2021;10.18653/v1/2021.findings-emnlp.325;"Lu, Qiuhao and
 Dou, Dejing and
 Nguyen, Thien Huu";https://aclanthology.org/2021.findings-emnlp.325;China, United States;augmented language models;validation research;technique;health;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;end-to-end construction of nlp knowledge graph;;;ACL;2021;10.18653/v1/2021.findings-acl.165;"Mondal, Ishani and
 Hou, Yufang and
 Jochim, Charles";https://aclanthology.org/2021.findings-acl.165;India, Ireland;"relation extraction; ";validation research;method;scholarly domain;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;gmh: a general multi-hop reasoning model for kg completion;;Knowledge graphs are essential for numerous downstream natural language processing applications, but are typically incomplete with many facts missing. This results in research efforts on multi-hop reasoning task, which can be formulated as a search process and current models typically perform short distance reasoning. However, the long-distance reasoning is also vital with the ability to connect the superficially unrelated entities. To the best of our knowledge, there lacks a general framework that approaches multi-hop reasoning in mixed long-short distance reasoning scenarios. We argue that there are two key issues for a general multi-hop reasoning model: i) where to go, and ii) when to stop. Therefore, we propose a general model which resolves the issues with three modules: 1) the local-global knowledge module to estimate the possible paths, 2) the differentiated action dropout module to explore a diverse set of paths, and 3) the adaptive stopping search module to avoid over searching. The comprehensive results on three datasets demonstrate the superiority of our model with significant improvements against baselines in both short and long distance reasoning scenarios.;ACL;2021;10.18653/v1/2021.emnlp-main.276;"Zhang, Yao and
 Liang, Hongru and
 Jatowt, Adam and
 Lei, Wenqiang and
 Wei, Xin and
 Jiang, Ning and
 Yang, Zhenglu";https://aclanthology.org/2021.emnlp-main.276;Austria, China, Singapore;"link prediction; relation classification";validation research;method;;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1
Conference Paper;benchmarking commonsense knowledge base population with an effective evaluation dataset;;Reasoning over commonsense knowledge bases (CSKB) whose elements are in the form of free-text is an important yet hard task in NLP. While CSKB completion only fills the missing links within the domain of the CSKB, CSKB population is alternatively proposed with the goal of reasoning unseen assertions from external resources. In this task, CSKBs are grounded to a large-scale eventuality (activity, state, and event) graph to discriminate whether novel triples from the eventuality graph are plausible or not. However, existing evaluations on the population task are either not accurate (automatic evaluation with randomly sampled negative examples) or of small scale (human annotation). In this paper, we benchmark the CSKB population task with a new large-scale dataset by first aligning four popular CSKBs, and then presenting a high-quality human-annotated evaluation set to probe neural models{'} commonsense reasoning ability. We also propose a novel inductive commonsense reasoning model that reasons over graphs. Experimental results show that generalizing commonsense reasoning on unseen assertions is inherently a hard task. Models achieving high accuracy during training perform poorly on the evaluation set, with a large gap between human performance. We will make the data publicly available for future contributions. Codes and data are available at https://github.com/HKUST-KnowComp/CSKB-Population.;ACL;2021;10.18653/v1/2021.emnlp-main.705;"Fang, Tianqing and
 Wang, Weiqi and
 Choi, Sehyun and
 Hao, Shibo and
 Zhang, Hongming and
 Song, Yangqiu and
 He, Bin";https://aclanthology.org/2021.emnlp-main.705;China, Hong Kong;"triple classification; entity alignment";validation research;"technique; resource";;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;relation-aware bidirectional path reasoning for commonsense question answering;;Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning. Previous studies utilize pre-trained models on large-scale corpora such as BERT, or perform reasoning on knowledge graphs. However, these methods do not explicitly model the \textit{relations} that connect entities, which are informational and can be used to enhance reasoning. To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.;ACL;2021;10.18653/v1/2021.conll-1.35;"Wang, Junxing and
 Li, Xinyi and
 Tan, Zhen and
 Zhao, Xiang and
 Xiao, Weidong";https://aclanthology.org/2021.conll-1.35;China;question answering;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;unsupervised cross-domain prerequisite chain learning using variational graph autoencoders;;Learning prerequisite chains is an important task for one to pick up knowledge efficiently in both known and unknown domains. For example, one may be an expert in the natural language processing (NLP) domain, but want to determine the best order in which to learn new concepts in an unfamiliar Computer Vision domain (CV). Both domains share some common concepts, such as machine learning basics and deep learning models. In this paper, we solve the task of unsupervised cross-domain concept prerequisite chain learning, using an optimized variational graph autoencoder. Our model learns to transfer concept prerequisite relations from an information-rich domain (source domain) to an information-poor domain (target domain), substantially surpassing other baseline models. In addition, we expand an existing dataset by introducing two new domains{---}-CV and Bioinformatics (BIO). The annotated data and resources as well as the code will be made publicly available.;ACL;2021;10.18653/v1/2021.acl-short.127;"Li, Irene and
 Yan, Vanessa and
 Li, Tianxiao and
 Qu, Rihao and
 Radev, Dragomir";https://aclanthology.org/2021.acl-short.127;United States;"entity linking; entity alignment";validation research;"technique; resource";;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge-enriched event causality identification via latent structure induction networks;;Identifying causal relations of events is an important task in natural language processing area. However, the task is very challenging, because event causality is usually expressed in diverse forms that often lack explicit causal clues. Existing methods cannot handle well the problem, especially in the condition of lacking training data. Nonetheless, humans can make a correct judgement based on their background knowledge, including descriptive knowledge and relational knowledge. Inspired by it, we propose a novel Latent Structure Induction Network (LSIN) to incorporate the external structural knowledge into this task. Specifically, to make use of the descriptive knowledge, we devise a Descriptive Graph Induction module to obtain and encode the graph-structured descriptive knowledge. To leverage the relational knowledge, we propose a Relational Graph Induction module which is able to automatically learn a reasoning structure for event causality reasoning. Experimental results on two widely used datasets indicate that our approach significantly outperforms previous state-of-the-art methods.;ACL;2021;10.18653/v1/2021.acl-long.376;"Cao, Pengfei and
 Zuo, Xinyu and
 Chen, Yubo and
 Liu, Kang and
 Zhao, Jun and
 Chen, Yuguang and
 Peng, Weihua";https://aclanthology.org/2021.acl-long.376;China;augmented language models;validation research;method;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;big green at wnut 2020 shared task-1: relation extraction as contextualized sequence classification;;Relation and event extraction is an important task in natural language processing. We introduce a system which uses contextualized knowledge graph completion to classify relations and events between known entities in a noisy text environment. We report results which show that our system is able to effectively extract relations and events from a dataset of wet lab protocols.;ACL;2020;10.18653/v1/2020.wnut-1.36;"Miller, Chris and
 Vosoughi, Soroush";https://aclanthology.org/2020.wnut-1.36;United States;relation extraction;validation research;technique;;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;cyclegt: unsupervised graph-to-text and text-to-graph generation via cycle training;;Two important tasks at the intersection of knowledge graphs and natural language processing are graph-to-text (G2T) and text-tograph (T2G) conversion. Due to the difficulty and high cost of data collection, the supervised data available in the two fields are usually on the magnitude of tens of thousands, for example, 18K in the WebNLG 2017 dataset after preprocessing, which is far fewer than the millions of data for other tasks such as machine translation. Consequently, deep learning models for G2T and T2G suffer largely from scarce training data. We present CycleGT, an unsupervised training method that can bootstrap from fully non-parallel graph and text data, and iteratively back translate between the two forms. Experiments on WebNLG datasets show that our unsupervised model trained on the same number of data achieves performance on par with several fully supervised models. Further experiments on the non-parallel GenWiki dataset verify that our method performs the best among unsupervised baselines. This validates our framework as an effective approach to overcome the data scarcity problem in the fields of G2T and T2G.;ACL;2020;;"Guo, Qipeng and
 Jin, Zhijing and
 Qiu, Xipeng and
 Zhang, Weinan and
 Wipf, David and
 Zhang, Zheng";https://aclanthology.org/2020.webnlg-1.8;China;"entity extraction; relation extraction; data-to-text generation";validation research;method;;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a survey of embedding models of entities and relationships for knowledge graph completion;;Knowledge graphs (KGs) of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge graphs are typically incomplete, it is useful to perform knowledge graph completion or link prediction, i.e. predict whether a relationship not in the knowledge graph is likely to be true. This paper serves as a comprehensive survey of embedding models of entities and relationships for knowledge graph completion, summarizing up-to-date experimental results on standard benchmark datasets and pointing out potential future research directions.;ACL;2020;10.18653/v1/2020.textgraphs-1.1;Nguyen, Dat Quoc;https://aclanthology.org/2020.textgraphs-1.1;Vietnam;"knowledge graph embedding; link prediction";secondary research;guidelines;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0
Conference Paper;multiple knowledge graphdb (mkgdb);;We present MKGDB, a large-scale graph database created as a combination of multiple taxonomy backbones extracted from 5 existing knowledge graphs, namely: ConceptNet, DBpedia, WebIsAGraph, WordNet and the Wikipedia category hierarchy. MKGDB, thanks the versatility of the Neo4j graph database manager technology, is intended to favour and help the development of open-domain natural language processing applications relying on knowledge bases, such as information extraction, hypernymy discovery, topic clustering, and others. Our resource consists of a large hypernymy graph which counts more than 37 million nodes and more than 81 million hypernymy relations.;ACL;2020;;"Faralli, Stefano and
 Velardi, Paola and
 Yusifli, Farid";https://aclanthology.org/2020.lrec-1.283;Italy;entity alignment;validation research;"method; resource";;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;kore 50\^dywc: an evaluation data set for entity linking based on dbpedia, yago, wikidata, and crunchbase;;A major domain of research in natural language processing is named entity recognition and disambiguation (NERD). One of the main ways of attempting to achieve this goal is through use of Semantic Web technologies and its structured data formats. Due to the nature of structured data, information can be extracted more easily, therewith allowing for the creation of knowledge graphs. In order to properly evaluate a NERD system, gold standard data sets are required. A plethora of different evaluation data sets exists, mostly relying on either Wikipedia or DBpedia. Therefore, we have extended a widely-used gold standard data set, KORE 50, to not only accommodate NERD tasks for DBpedia, but also for YAGO, Wikidata and Crunchbase. As such, our data set, KORE 50{\^{}}DYWC, allows for a broader spectrum of evaluation. Among others, the knowledge graph agnosticity of NERD systems may be evaluated which, to the best of our knowledge, was not possible until now for this number of knowledge graphs.;ACL;2020;;"Noullet, Kristian and
 Mix, Rico and
 F{\""a}rber, Michael";https://aclanthology.org/2020.lrec-1.291;Germany;"entity linking; text analysis";validation research;resource;;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;recurrent event network: autoregressive structure inferenceover temporal knowledge graphs;;Knowledge graph reasoning is a critical task in natural language processing. The task becomes more challenging on temporal knowledge graphs, where each fact is associated with a timestamp. Most existing methods focus on reasoning at past timestamps and they are not able to predict facts happening in the future. This paper proposes Recurrent Event Network (RE-Net), a novel autoregressive architecture for predicting future interactions. The occurrence of a fact (event) is modeled as a probability distribution conditioned on temporal sequences of past knowledge graphs. Specifically, our RE-Net employs a recurrent event encoder to encode past facts, and uses a neighborhood aggregator to model the connection of facts at the same timestamp. Future facts can then be inferred in a sequential manner based on the two modules. We evaluate our proposed method via link prediction at future times on five public datasets. Through extensive experiments, we demonstrate the strength of RE-Net, especially on multi-step inference over future timestamps, and achieve state-of-the-art performance on all five datasets.;ACL;2020;10.18653/v1/2020.emnlp-main.541;"Jin, Woojeong and
 Qu, Meng and
 Jin, Xisen and
 Ren, Xiang";https://aclanthology.org/2020.emnlp-main.541;Canada;"knowledge graph embedding; link prediction";validation research;technique;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;distilling structured knowledge for text-based relational reasoning;;There is an increasing interest in developing text-based relational reasoning systems, which are capable of systematically reasoning about the relationships between entities mentioned in a text. However, there remains a substantial performance gap between NLP models for relational reasoning and models based on graph neural networks (GNNs), which have access to an underlying symbolic representation of the text. In this work, we investigate how the structured knowledge of a GNN can be distilled into various NLP models in order to improve their performance. We first pre-train a GNN on a reasoning task using structured inputs and then incorporate its knowledge into an NLP model (e.g., an LSTM) via knowledge distillation. To overcome the difficulty of cross-modal knowledge transfer, we also employ a contrastive learning based module to align the latent representations of NLP models and the GNN. We test our approach with two state-of-the-art NLP models on 13 different inductive reasoning datasets from the CLUTRR benchmark and obtain significant improvements.;ACL;2020;10.18653/v1/2020.emnlp-main.551;"Dong, Jin and
 Rondeau, Marc-Antoine and
 Hamilton, William L.";https://aclanthology.org/2020.emnlp-main.551;Canada;"augmented language models; natural language inference";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a knowledge-aware sequence-to-tree network for math word problem solving;;With the advancements in natural language processing tasks, math word problem solving has received increasing attention. Previous methods have achieved promising results but ignore background common-sense knowledge not directly provided by the problem. In addition, during generation, they focus on local features while neglecting global information. To incorporate external knowledge and global expression information, we propose a novel knowledge-aware sequence-to-tree (KA-S2T) network in which the entities in the problem sequences and their categories are modeled as an entity graph. Based on this entity graph, a graph attention network is used to capture knowledge-aware problem representations. Further, we use a tree-structured decoder with a state aggregation mechanism to capture the long-distance dependency and global expression information. Experimental results on the Math23K dataset revealed that the KA-S2T model can achieve better performance than previously reported best results.;ACL;2020;10.18653/v1/2020.emnlp-main.579;"Wu, Qinzhuo and
 Zhang, Qi and
 Fu, Jinlan and
 Huang, Xuanjing";https://aclanthology.org/2020.emnlp-main.579;China;"knowledge graph embedding; natural language inference";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;is graph structure necessary for multi-hop question answering;;Recently, attempting to model texts as graph structure and introducing graph neural networks to deal with it has become a trend in many NLP research areas. In this paper, we investigate whether the graph structure is necessary for textual multi-hop reasoning. Our analysis is centered on HotpotQA. We construct a strong baseline model to establish that, with the proper use of pre-trained models, graph structure may not be necessary for textual multi-hop reasoning. We point out that both graph structure and adjacency matrix are task-related prior knowledge, and graph-attention can be considered as a special case of self-attention. Experiments demonstrate that graph-attention or the entire graph structure can be replaced by self-attention or Transformers.;ACL;2020;10.18653/v1/2020.emnlp-main.583;"Shao, Nan and
 Cui, Yiming and
 Liu, Ting and
 Wang, Shijin and
 Hu, Guoping";https://aclanthology.org/2020.emnlp-main.583;China;question answering;solution proposal;guidelines;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;enhancing question answering by injecting ontological knowledge through regularization;;Deep neural networks have demonstrated high performance on many natural language processing (NLP) tasks that can be answered directly from text, and have struggled to solve NLP tasks requiring external (e.g., world) knowledge. In this paper, we present OSCR (Ontology-based Semantic Composition Regularization), a method for injecting task-agnostic knowledge from an Ontology or knowledge graph into a neural network during pre-training. We evaluated the performance of BERT pre-trained on Wikipedia with and without OSCR by measuring the performance when fine-tuning on two question answering tasks involving world knowledge and causal reasoning and one requiring domain (healthcare) knowledge and obtained 33.3{\%}, 18.6{\%}, and 4{\%} improved accuracy compared to pre-training BERT without OSCR.;ACL;2020;10.18653/v1/2020.deelio-1.7;"Goodwin, Travis and
 Demner-Fushman, Dina";https://aclanthology.org/2020.deelio-1.7;United States;"augmented language models; question answering";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;incorporating commonsense knowledge graph in pretrained models for social commonsense tasks;;"Pretrained language models have excelled at many NLP tasks recently; however, their social intelligence is still unsatisfactory. To enable this, machines need to have a more general understanding of our complicated world and develop the ability to perform commonsense reasoning besides fitting the specific downstream tasks. External commonsense knowledge graphs (KGs), such as ConceptNet, provide rich information about words and their relationships. Thus, towards general commonsense learning, we propose two approaches to implicitly and explicitly infuse such KGs into pretrained language models. We demonstrate our proposed methods perform well on SocialIQA, a social commonsense reasoning task, in both limited and full training data regimes.";ACL;2020;10.18653/v1/2020.deelio-1.9;"Chang, Ting-Yun and
 Liu, Yang and
 Gopalakrishnan, Karthik and
 Hedayatnia, Behnam and
 Zhou, Pei and
 Hakkani-Tur, Dilek";https://aclanthology.org/2020.deelio-1.9;Taiwan, United States;"augmented language models; natural language inference";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0
Conference Paper;harnessing cross-lingual features to improve cognate detection for low-resource languages;;"Cognates are variants of the same lexical form across different languages; for example {``}fonema{''} in Spanish and {``}phoneme{''} in English are cognates, both of which mean {``}a unit of sound{''}. The task of automatic detection of cognates among any two languages can help downstream NLP tasks such as Cross-lingual Information Retrieval, Computational Phylogenetics, and Machine Translation. In this paper, we demonstrate the use of cross-lingual word embeddings for detecting cognates among fourteen Indian Languages. Our approach introduces the use of context from a knowledge graph to generate improved feature representations for cognate detection. We, then, evaluate the impact of our cognate detection mechanism on neural machine translation (NMT), as a downstream task. We evaluate our methods to detect cognates on a challenging dataset of twelve Indian languages, namely, Sanskrit, Hindi, Assamese, Oriya, Kannada, Gujarati, Tamil, Telugu, Punjabi, Bengali, Marathi, and Malayalam. Additionally, we create evaluation datasets for two more Indian languages, Konkani and Nepali. We observe an improvement of up to 18{\%} points, in terms of F-score, for cognate detection. Furthermore, we observe that cognates extracted using our method help improve NMT quality by up to 2.76 BLEU. We also release our code, newly constructed datasets and cross-lingual models publicly.";ACL;2020;10.18653/v1/2020.coling-main.119;"Kanojia, Diptesh and
 Dabre, Raj and
 Dewangan, Shubham and
 Bhattacharyya, Pushpak and
 Haffari, Gholamreza and
 Kulkarni, Malhar";https://aclanthology.org/2020.coling-main.119;Australia, India, Japan;text classification;validation research ;technique;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;multi-task learning for knowledge graph completion with pre-trained language models;;As research on utilizing human knowledge in natural language processing has attracted considerable attention in recent years, knowledge graph (KG) completion has come into the spotlight. Recently, a new knowledge graph completion method using a pre-trained language model, such as KG-BERT, is presented and showed high performance. However, its scores in ranking metrics such as Hits@k are still behind state-of-the-art models. We claim that there are two main reasons: 1) failure in sufficiently learning relational information in knowledge graphs, and 2) difficulty in picking out the correct answer from lexically similar candidates. In this paper, we propose an effective multi-task learning method to overcome the limitations of previous works. By combining relation prediction and relevance ranking tasks with our target link prediction, the proposed model can learn more relational properties in KGs and properly perform even when lexical similarity occurs. Experimental results show that we not only largely improve the ranking performances compared to KG-BERT but also achieve the state-of-the-art performances in Mean Rank and Hits@10 on the WN18RR dataset.;ACL;2020;10.18653/v1/2020.coling-main.153;"Kim, Bosung and
 Hong, Taesuk and
 Ko, Youngjoong and
 Seo, Jungyun";https://aclanthology.org/2020.coling-main.153;South Korea;"link prediction; relation classification";validation research ;method;;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;knowledge-enhanced natural language inference based on knowledge graphs;;Natural Language Inference (NLI) is a vital task in natural language processing. It aims to identify the logical relationship between two sentences. Most of the existing approaches make such inference based on semantic knowledge obtained through training corpus. The adoption of background knowledge is rarely seen or limited to a few specific types. In this paper, we propose a novel Knowledge Graph-enhanced NLI (KGNLI) model to leverage the usage of background knowledge stored in knowledge graphs in the field of NLI. KGNLI model consists of three components: a semantic-relation representation module, a knowledge-relation representation module, and a label prediction module. Different from previous methods, various kinds of background knowledge can be flexibly combined in the proposed KGNLI model. Experiments on four benchmarks, SNLI, MultiNLI, SciTail, and BNLI, validate the effectiveness of our model.;ACL;2020;10.18653/v1/2020.coling-main.571;"Wang, Zikang and
 Li, Linjing and
 Zeng, Daniel";https://aclanthology.org/2020.coling-main.571;China;"augmented language models; knowledge graph embedding; natural language inference";validation research ;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;a re-evaluation of knowledge graph completion methods;;Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report performance of several existing methods using our protocol. The reproducible code has been made publicly available.;ACL;2020;10.18653/v1/2020.acl-main.489;"Sun, Zhiqing and
 Vashishth, Shikhar and
 Sanyal, Soumya and
 Talukdar, Partha and
 Yang, Yiming";https://aclanthology.org/2020.acl-main.489;India, United States;"triple classification; knowledge graph embedding";validation research;method;;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;augmenting named entity recognition with commonsense knowledge;;Commonsense can be vital in some applications like Natural Language Understanding (NLU), where it is often required to resolve ambiguity arising from implicit knowledge and underspecification. In spite of the remarkable success of neural network approaches on a variety of Natural Language Processing tasks, many of them struggle to react effectively in cases that require commonsense knowledge. In the present research, we take advantage of the availability of the open multilingual knowledge graph ConceptNet, by using it as an additional external resource in Named Entity Recognition (NER). Our proposed architecture involves BiLSTM layers combined with a CRF layer that was augmented with some features such as pre-trained word embedding layers and dropout layers. Moreover, apart from using word representations, we used also character-based representation to capture the morphological and the orthographic information. Our experiments and evaluations showed an improvement in the overall performance with +2.86 in the F1-measure. Commonsense reasonnig has been employed in other studies and NLP tasks but to the best of our knowledge, there is no study relating the integration of a commonsense knowledge base in NER.;ACL;2019;;"Dekhili, Gaith and
 Le, Tan Ngoc and
 Sadat, Fatiha";https://aclanthology.org/W19-3644;Canada;"augmented language models; entity extraction";solution proposal;technique;;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;scalable, semi-supervised extraction of structured information from scientific literature;;As scientific communities grow and evolve, there is a high demand for improved methods for finding relevant papers, comparing papers on similar topics and studying trends in the research community. All these tasks involve the common problem of extracting structured information from scientific articles. In this paper, we propose a novel, scalable, semi-supervised method for extracting relevant structured information from the vast available raw scientific literature. We extract the fundamental concepts of {``}aim{''}, {''}method{''} and {``}result{''} from scientific articles and use them to construct a knowledge graph. Our algorithm makes use of domain-based word embedding and the bootstrap framework. Our experiments show that our system achieves precision and recall comparable to the state of the art. We also show the domain independence of our algorithm by analyzing the research trends of two distinct communities - computational linguistics and computer vision.;ACL;2019;10.18653/v1/w19-2602;"Agrawal, Kritika and
 Mittal, Aakash and
 Pudi, Vikram";https://aclanthology.org/W19-2602;India;"entity extraction; relation extraction; semantic search";validation research;method;scholarly domain;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;eoann: lexical semantic relation classification using an ensemble of artificial neural networks;;Researchers use wordnets as a knowledge base in many natural language processing tasks and applications, such as question answering, textual entailment, discourse classification, and so forth. Lexico-semantic relations among words or concepts are important parts of knowledge encoded in wordnets. As the use of wordnets becomes extensively widespread, extending the existing ones gets more attention. Manually construction and extension of lexico-semantic relations for WordNets or knowledge graphs are very time-consuming. Using automatic relation extraction methods can speed up this process. In this study, we exploit an ensemble of lstm and convolutional neural networks in a supervised manner to capture lexico-semantic relations which can either be used directly in NLP applications or compose the edges of wordnets. The whole procedure of learning vector space representation of relations is language independent. We used Princeton WordNet 3.1, FarsNet 3.0 (the Persian wordnet), Root09 and EVALution as golden standards to evaluate the predictive performance of our model and the results are comparable on the two languages. Empirical results demonstrate that our model outperforms the state of the art models.;ACL;2019;10.26615/978-954-452-056-4_057;"Hosseini Pour, Rayehe and
 Shamsfard, Mehrnoush";https://aclanthology.org/R19-1057;Iran;relation classification;validation research;technique;;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;graph convolutional network with sequential attention for goal-oriented dialogue systems;;Domain-specific goal-oriented dialogue systems typically require modeling three types of inputs, namely, (i) the knowledge-base associated with the domain, (ii) the history of the conversation, which is a sequence of utterances, and (iii) the current utterance for which the response needs to be generated. While modeling these inputs, current state-of-the-art models such as Mem2Seq typically ignore the rich structure inherent in the knowledge graph and the sentences in the conversation context. Inspired by the recent success of structure-aware Graph Convolutional Networks (GCNs) for various NLP tasks such as machine translation, semantic role labeling, and document dating, we propose a memory-augmented GCN for goal-oriented dialogues. Our model exploits (i) the entity relation graph in a knowledge-base and (ii) the dependency graph associated with an utterance to compute richer representations for words and entities. Further, we take cognizance of the fact that in certain situations, such as when the conversation is in a code-mixed language, dependency parsers may not be available. We show that in such situations we could use the global word co-occurrence graph to enrich the representations of utterances. We experiment with four datasets: (i) the modified DSTC2 dataset, (ii) recently released code-mixed versions of DSTC2 dataset in four languages, (iii) Wizard-of-Oz style CAM676 dataset, and (iv) Wizard-of-Oz style MultiWOZ dataset. On all four datasets our method outperforms existing methods, on a wide range of evaluation metrics.;ACL;2019;10.1162/tacl_a_00284;"Banerjee, Suman and
 Khapra, Mitesh M.";https://aclanthology.org/Q19-1034;India;"conversational interfaces; augmented language models";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;grapal: connecting the dots in scientific literature;;We introduce GrapAL (Graph database of Academic Literature), a versatile tool for exploring and investigating a knowledge base of scientific literature that was semi-automatically constructed using NLP methods. GrapAL fills many informational needs expressed by researchers. At the core of GrapAL is a Neo4j graph database with an intuitive schema and a simple query language. In this paper, we describe the basic elements of GrapAL, how to use it, and several use cases such as finding experts on a given topic for peer reviewing, discovering indirect connections between biomedical entities, and computing citation-based metrics. We open source the demo code to help other researchers develop applications that build on GrapAL.;ACL;2019;10.18653/v1/p19-3025;"Betts, Christine and
 Power, Joanna and
 Ammar, Waleed";https://aclanthology.org/P19-3025;United States;"entity extraction; relation extraction; semantic search";solution proposal;tool;scholarly domain;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;ernie: enhanced language representation with informative entities;;Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.;ACL;2019;10.18653/v1/p19-1139;"Zhang, Zhengyan and
 Han, Xu and
 Liu, Zhiyuan and
 Jiang, Xin and
 Sun, Maosong and
 Liu, Qun";https://aclanthology.org/P19-1139;China;augmented language models;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;incorporating syntactic and semantic information in word embeddings using graph convolutional networks;;Word embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research.;ACL;2019;10.18653/v1/p19-1320;"Vashishth, Shikhar and
 Bhandari, Manik and
 Yadav, Prateek and
 Rai, Piyush and
 Bhattacharyya, Chiranjib and
 Talukdar, Partha";https://aclanthology.org/P19-1320;India;augmented language models;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;scalable micro-planned generation of discourse from structured data;;"We present a framework for generating natural language description from structured data such as tables; the problem comes under the category of data-to-text natural language generation (NLG). Modern data-to-text NLG systems typically use end-to-end statistical and neural architectures that learn from a limited amount of task-specific labeled data, and therefore exhibit limited scalability, domain-adaptability, and interpretability. Unlike these systems, ours is a modular, pipeline-based approach, and does not require task-specific parallel data. Rather, it relies on monolingual corpora and basic off-the-shelf NLP tools. This makes our system more scalable and easily adaptable to newer domains.Our system utilizes a three-staged pipeline that: (i) converts entries in the structured data to canonical form, (ii) generates simple sentences for each atomic entry in the canonicalized representation, and (iii) combines the sentences to produce a coherent, fluent, and adequate paragraph description through sentence compounding and co-reference replacement modules. Experiments on a benchmark mixed-domain data set curated for paragraph description from tables reveals the superiority of our system over existing data-to-text approaches. We also demonstrate the robustness of our system in accepting other popular data sets covering diverse data types such as knowledge graphs and key-value maps.";ACL;2019;10.1162/coli_a_00363;"Laha, Anirban and
 Jain, Parag and
 Mishra, Abhijit and
 Sankaranarayanan, Karthik";https://aclanthology.org/J19-4005;Canada, India, United Kingdom;text generation;validation research;"tool; resource";;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1
Conference Paper;cracking the contextual commonsense code: understanding commonsense reasoning aptitude of deep contextual representations;;Pretrained deep contextual representations have advanced the state-of-the-art on various commonsense NLP tasks, but we lack a concrete understanding of the capability of these models. Thus, we investigate and challenge several aspects of BERT{'}s commonsense representation abilities. First, we probe BERT{'}s ability to classify various object attributes, demonstrating that BERT shows a strong ability in encoding various commonsense features in its embedding space, but is still deficient in many areas. Next, we show that, by augmenting BERT{'}s pretraining data with additional data related to the deficient attributes, we are able to improve performance on a downstream commonsense reasoning task while using a minimal amount of data. Finally, we develop a method of fine-tuning knowledge graphs embeddings alongside BERT and show the continued importance of explicit knowledge graphs.;ACL;2019;10.18653/v1/d19-6001;"Da, Jeff and
 Kasai, Jungo";https://aclanthology.org/D19-6001;United States;"augmented language models; natural language inference";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;pingan smart health and sjtu at coin - shared task: utilizing pre-trained language models and common-sense knowledge in machine reading tasks;;"To solve the shared tasks of COIN: COmmonsense INference in Natural Language Processing) Workshop in , we need explore the impact of knowledge representation in modeling commonsense knowledge to boost performance of machine reading comprehension beyond simple text matching. There are two approaches to represent knowledge in the low-dimensional space. The first is to leverage large-scale unsupervised text corpus to train fixed or contextual language representations. The second approach is to explicitly express knowledge into a knowledge graph (KG), and then fit a model to represent the facts in the KG. We have experimented both (a) improving the fine-tuning of pre-trained language models on a task with a small dataset size, by leveraging datasets of similar tasks; and (b) incorporating the distributional representations of a KG onto the representations of pre-trained language models, via simply concatenation or multi-head attention. We find out that: (a) for task 1, first fine-tuning on larger datasets like RACE (Lai et al., 2017) and SWAG (Zellersetal.,2018), and then fine-tuning on the target task improve the performance significantly; (b) for task 2, we find out the incorporating a KG of commonsense knowledge, WordNet (Miller, 1995) into the Bert model (Devlin et al., 2018) is helpful, however, it will hurts the performace of XLNET (Yangetal.,2019), a more powerful pre-trained model. Our approaches achieve the state-of-the-art results on both shared task{'}s official test data, outperforming all the other submissions.";ACL;2019;10.18653/v1/d19-6011;"Li, Xiepeng and
 Zhang, Zhexi and
 Zhu, Wei and
 Li, Zheng and
 Ni, Yuan and
 Gao, Peng and
 Yan, Junchi and
 Xie, Guotong";https://aclanthology.org/D19-6011;China;"augmented language models; question answering";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;joint semantic and distributional word representations with multi-graph embeddings;;Word embeddings continue to be of great use for NLP researchers and practitioners due to their training speed and easiness of use and distribution. Prior work has shown that the representation of those words can be improved by the use of semantic knowledge-bases. In this paper we propose a novel way of combining those knowledge-bases while the lexical information of co-occurrences of words remains. It is conceptually clear, as it consists in mapping both distributional and semantic information into a multi-graph and modifying existing node embeddings techniques to compute word representations. Our experiments show improved results compared to vanilla word embeddings, retrofitting and concatenation techniques using the same information, on a variety of data-sets of word similarities.;ACL;2019;10.18653/v1/d19-5314;"Daix-Moreux, Pierre and
 Gall{\'e}, Matthias";https://aclanthology.org/D19-5314;France;"augmented language models; knowledge graph embedding";validation research;technique;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;modeling multi-mapping relations for precise cross-lingual entity alignment;;Entity alignment aims to find entities in different knowledge graphs (KGs) that refer to the same real-world object. An effective solution for cross-lingual entity alignment is crucial for many cross-lingual AI and NLP applications. Recently many embedding-based approaches were proposed for cross-lingual entity alignment. However, almost all of them are based on TransE or its variants, which have been demonstrated by many studies to be unsuitable for encoding multi-mapping relations such as 1-N, N-1 and N-N relations, thus these methods obtain low alignment precision. To solve this issue, we propose a new embedding-based framework. Through defining dot product-based functions over embeddings, our model can better capture the semantics of both 1-1 and multi-mapping relations. We calibrate embeddings of different KGs via a small set of pre-aligned seeds. We also propose a weighted negative sampling strategy to generate valuable negative samples during training and we regard prediction as a bidirectional problem in the end. Experimental results (especially with the metric \textit{Hits@1}) on real-world multilingual datasets show that our approach significantly outperforms many other embedding-based approaches with state-of-the-art performance.;ACL;2019;10.18653/v1/d19-1075;"Shi, Xiaofei and
 Xiao, Yanghua";https://aclanthology.org/D19-1075;China;"knowledge graph embedding; entity alignment";validation research;technique;;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;boosting text classification performance on sexist tweets by text augmentation and text generation using a combination of knowledge graphs;;Text classification models have been heavily utilized for a slew of interesting natural language processing problems. Like any other machine learning model, these classifiers are very dependent on the size and quality of the training dataset. Insufficient and imbalanced datasets will lead to poor performance. An interesting solution to poor datasets is to take advantage of the world knowledge in the form of knowledge graphs to improve our training data. In this paper, we use ConceptNet and Wikidata to improve sexist tweet classification by two methods (1) text augmentation and (2) text generation. In our text generation approach, we generate new tweets by replacing words using data acquired from ConceptNet relations in order to increase the size of our training set, this method is very helpful with frustratingly small datasets, preserves the label and increases diversity. In our text augmentation approach, the number of tweets remains the same but their words are augmented (concatenation) with words extracted from their ConceptNet relations and their description extracted from Wikidata. In our text augmentation approach, the number of tweets in each class remains the same but the range of each tweet increases. Our experiments show that our approach improves sexist tweet classification significantly in our entire machine learning models. Our approach can be readily applied to any other small dataset size like hate speech or abusive language and text classification problem using any machine learning model.;ACL;2018;10.18653/v1/w18-5114;"Sharifirad, Sima and
 Jafarpour, Borna and
 Matwin, Stan";https://aclanthology.org/W18-5114;Canada;"text classification; text generation";validation research;method;social media;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;gkr: the graphical knowledge representation for semantic parsing;;This paper describes the first version of an open-source semantic parser that creates graphical representations of sentences to be used for further semantic processing, e.g. for natural language inference, reasoning and semantic similarity. The Graphical Knowledge Representation which is output by the parser is inspired by the Abstract Knowledge Representation, which separates out conceptual and contextual levels of representation that deal respectively with the subject matter of a sentence and its existential commitments. Our representation is a layered graph with each sub-graph holding different kinds of information, including one sub-graph for concepts and one for contexts. Our first evaluation of the system shows an F-score of 85{\%} in accurately representing sentences as semantic graphs.;ACL;2018;10.18653/v1/w18-1304;"Kalouli, Aikaterini-Lida and
 Crouch, Richard";https://aclanthology.org/W18-1304;Germany, United States;semantic parsing;validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;unsupervised abstractive meeting summarization with multi-sentence compression and budgeted submodular maximization;;We introduce a novel graph-based framework for abstractive meeting speech summarization that is fully unsupervised and does not rely on any annotations. Our work combines the strengths of multiple recent approaches while addressing their weaknesses. Moreover, we leverage recent advances in word embeddings and graph degeneracy applied to NLP to take exterior semantic knowledge into account, and to design custom diversity and informativeness measures. Experiments on the AMI and ICSI corpus show that our system improves on the state-of-the-art. Code and data are publicly available, and our system can be interactively tested.;ACL;2018;10.18653/v1/p18-1062;"Shang, Guokan and
 Ding, Wensi and
 Zhang, Zekun and
 Tixier, Antoine and
 Meladianos, Polykarpos and
 Vazirgiannis, Michalis and
 Lorr{\'e}, Jean-Pierre";https://aclanthology.org/P18-1062;France, Greece;"augmented language models; text summarization";validation research;tool;;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
Conference Paper;cl scholar: the acl anthology knowledge graph miner;;We present CL Scholar, the ACL Anthology knowledge graph miner to facilitate high-quality search and exploration of current research progress in the computational linguistics community. In contrast to previous works, periodically crawling, indexing and processing of new incoming articles is completely automated in the current system. CL Scholar utilizes both textual and network information for knowledge graph construction. As an additional novel initiative, CL Scholar supports more than 1200 scholarly natural language queries along with standard keyword-based search on constructed knowledge graph. It answers binary, statistical and list based natural language queries. The current system is deployed at \url{http://cnerg.iitkgp.ac.in/aclakg}. We also provide REST API support along with bulk download facility. Our code and data are available at \url{https://github.com/CLScholar}.;ACL;2018;10.18653/v1/n18-5004;"Singh, Mayank and
 Dogga, Pradeep and
 Patro, Sohan and
 Barnwal, Dhiraj and
 Dutt, Ritam and
 Haldar, Rajarshi and
 Goyal, Pawan and
 Mukherjee, Animesh";https://aclanthology.org/N18-5004;India;"entity extraction; relation extraction; semantic search";solution proposal;tool;scholarly domain;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;t-know: a knowledge graph-based question answering and infor-mation retrieval system for traditional chinese medicine;;T-Know is a knowledge service system based on the constructed knowledge graph of Traditional Chinese Medicine (TCM). Using authorized and anonymized clinical records, medicine clinical guidelines, teaching materials, classic medical books, academic publications, etc., as data resources, the system extracts triples from free texts to build a TCM knowledge graph by our developed natural language processing methods. On the basis of the knowledge graph, a deep learning algorithm is implemented for single-round question understanding and multiple-round dialogue. In addition, the TCM knowledge graph also is used to support human-computer interactive knowledge retrieval by normalizing search keywords to medical terminology.;ACL;2018;;"Liu, Ziqing and
 Peng, Enwei and
 Yan, Shixing and
 Li, Guozheng and
 Hao, Tianyong";https://aclanthology.org/C18-2004;China;"question answering; semantic search";solution proposal;tool;health;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Journal Article;cross-sentence n-ary relation extraction with graph lstms;;Past work in relation extraction has focused on binary relations in single sentences. Recent NLP inroads in high-value domains have sparked interest in the more general setting of extracting n-ary relations that span multiple sentences. In this paper, we explore a general relation extraction framework based on graph long short-term memory networks (graph LSTMs) that can be easily extended to cross-sentence n-ary relation extraction. The graph formulation provides a unified way of exploring different LSTM approaches and incorporating various intra-sentential and inter-sentential dependencies, such as sequential, syntactic, and discourse relations. A robust contextual representation is learned for the entities, which serves as input to the relation classifier. This simplifies handling of relations with arbitrary arity, and enables multi-task learning with related relations. We evaluate this framework in two important precision medicine settings, demonstrating its effectiveness with both conventional supervised learning and distant supervision. Cross-sentence extraction produced larger knowledge bases. and multi-task learning significantly improved extraction accuracy. A thorough analysis of various LSTM approaches yielded useful insight the impact of linguistic analysis on extraction accuracy.;ACL;2017;10.1162/tacl_a_00049;"Peng, Nanyun and
 Poon, Hoifung and
 Quirk, Chris and
 Toutanova, Kristina and
 Yih, Wen-tau";https://aclanthology.org/Q17-1008;United States;"relation extraction; augmented language models";validation research;technique;health;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0
Conference Paper;from natural language to ontology population in the cultural heritage domain a computational linguistics-based approach;;This paper presents an on-going Natural Language Processing (NLP) research based on Lexicon-Grammar (LG) and aimed at improving knowledge management of Cultural Heritage (CH) domain. We intend to demonstrate how our language formalization technique can be applied for both processing and populating a domain ontology. We also use NLP techniques for text extraction and mining to fill information gaps and improve access to cultural resources. The Linguistic Resources (LRs, i.e. electronic dictionaries) we built can be used in the structuring of effective Knowledge Management Systems (KMSs). In order to apply to Parts of Speech (POS) the classes and properties defined by the Conseil Interational des Musees (CIDOC) Conceptual Reference Model (CRM), we use Finite State Transducers/Automata (FSTs/FSA) and their variables built in the form of graphs. FSTs/FSA are also used for analysing corpora in order to retrieve recursive sentence structures, in which combinatorial and semantic constraints identify properties and denote relationship. Besides, FSTs/FSA are also used to match our electronic dictionary entries (ALUs, or Atomic Linguistic Units) to RDF subject, object and predicate (SKOS Core Vocabulary). This matching of linguistic data to RDF and their translation into SPARQL/SERQL path expressions allows the use ALUs to process natural-language queries.;ACL;2014;;"di Buono, Maria Pia and
 Monteleone, Mario";http://www.lrec-conf.org/proceedings/lrec2014/pdf/686_Paper.pdf;Italy;"entity extraction; relation extraction";solution proposal;method;culture;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1
